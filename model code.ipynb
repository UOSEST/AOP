  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "11132/11132 [==============================] - 227s 20ms/step - loss: 0.1322 - acc: 0.9532\n",
      "2784/2784 [==============================] - 5s 2ms/step\n",
      "Epoch 1/1\n",
      "11132/11132 [==============================] - 226s 20ms/step - loss: 0.1412 - acc: 0.9501\n",
      "2784/2784 [==============================] - 5s 2ms/step\n",
      "Epoch 1/1\n",
      "11132/11132 [==============================] - 227s 20ms/step - loss: 0.1357 - acc: 0.9534\n",
      "2784/2784 [==============================] - 5s 2ms/step\n",
      "Epoch 1/1\n",
      "11134/11134 [==============================] - 228s 21ms/step - loss: 0.1270 - acc: 0.9560\n",
      "2782/2782 [==============================] - 5s 2ms/step\n",
      "Epoch 1/1\n",
      "11134/11134 [==============================] - 225s 20ms/step - loss: 0.1272 - acc: 0.9555\n",
      "2782/2782 [==============================] - 5s 2ms/step\n",
      "Results: 98.13% (0.65%)\n",
      "Epoch 1/1\n",
      "11132/11132 [==============================] - 225s 20ms/step - loss: 0.1338 - acc: 0.9519\n",
      "Epoch 1/1\n",
      "11132/11132 [==============================] - 225s 20ms/step - loss: 0.1333 - acc: 0.9558\n",
      "Epoch 1/1\n",
      "11132/11132 [==============================] - 226s 20ms/step - loss: 0.1273 - acc: 0.9557\n",
      "Epoch 1/1\n",
      "11134/11134 [==============================] - 227s 20ms/step - loss: 0.1269 - acc: 0.9562\n",
      "Epoch 1/1\n",
      "11134/11134 [==============================] - 225s 20ms/step - loss: 0.1354 - acc: 0.9526\n",
      "Epoch 1/5\n",
      "13916/13916 [==============================] - 281s 20ms/step - loss: 0.1200 - acc: 0.9606\n",
      "Epoch 2/5\n",
      "13916/13916 [==============================] - 280s 20ms/step - loss: 0.0377 - acc: 0.9909\n",
      "Epoch 3/5\n",
      "13916/13916 [==============================] - 279s 20ms/step - loss: 0.0268 - acc: 0.9931\n",
      "Epoch 4/5\n",
      "13916/13916 [==============================] - 280s 20ms/step - loss: 0.0251 - acc: 0.9937\n",
      "Epoch 5/5\n",
      "13916/13916 [==============================] - 279s 20ms/step - loss: 0.0224 - acc: 0.9948\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline #notebook을 실행한 브라우저에서 바로 그림을 볼 수 있게 해주는 것 \n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem, DataStructs\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#setting the seed for reproducibility\n",
    "#seed = 10110\n",
    "seed = 12061204\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "#load the dataset\n",
    "dataframe = pandas.read_csv(\"./pubchem_data/processed/input/TOX21_NFkB_BLA_agonist_ratio(Input).txt\", sep=\"\\t\")\n",
    "\n",
    "mols = []\n",
    "fps = []\n",
    "\n",
    "#get molecules and then get fingerprints from those\n",
    "for index, row in dataframe.iterrows():\n",
    "    mol = Chem.MolFromSmiles(row['Smiles'])\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2)\n",
    "    mols.append(mol)\n",
    "    fps.append(fp)\n",
    "\n",
    "#Convert the RDKit vectors into numpy arrays\n",
    "#Based on: http://www.rdkit.org/docs/Cookbook.html#using-scikit-learn-with-rdkit\n",
    "np_fps = []\n",
    "for fp in fps:\n",
    "    arr = numpy.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    np_fps.append(arr)\n",
    "\n",
    "np_fps_array = numpy.array(np_fps)\n",
    "\n",
    "#Need to encode my classes\n",
    "#Ligand = 0, not_ligand = 1\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(dataframe['Type'])\n",
    "enc_y = encoder.transform(dataframe['Type'])\n",
    "\n",
    "#Create the machine learning model\n",
    "\n",
    "def create_deep_learning_model():\n",
    "    model = Sequential()\n",
    "    #첫번째 인자 : 출력 뉴런의 수 , input_dim : 입력 뉴런의 수, activation : 활성화 함수.\n",
    "    model.add(Dense(2048, input_dim=2048, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "sm = SMOTE(random_state=12, ratio = 'minority')\n",
    "x_train_res, y_train_res = sm.fit_sample(np_fps_array, enc_y) #결과데이터\n",
    " \n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "#estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5, verbose=0)\n",
    "estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "#results = cross_val_score(estimator, np_fps_array, enc_y, cv=kfold)\n",
    "results = cross_val_score(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "y_pred = cross_val_predict(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "conf_mat = confusion_matrix(y_train_res, y_pred)\n",
    "conf_mat\n",
    "\n",
    "\n",
    "model = create_deep_learning_model()\n",
    "model.fit(x_train_res, y_train_res, epochs=5, batch_size=5)\n",
    "model.save('TOX21_NFkB_BLA_agonist_ratio(Input)_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2278/2278 [==============================] - 58s 25ms/step - loss: 0.0768 - acc: 0.9781\n",
      "570/570 [==============================] - 1s 2ms/step\n",
      "Epoch 1/1\n",
      "2278/2278 [==============================] - 58s 25ms/step - loss: 0.0709 - acc: 0.9723\n",
      "570/570 [==============================] - 1s 2ms/step\n",
      "Epoch 1/1\n",
      "2278/2278 [==============================] - 55s 24ms/step - loss: 0.0799 - acc: 0.9723\n",
      "570/570 [==============================] - 1s 2ms/step\n",
      "Epoch 1/1\n",
      "2278/2278 [==============================] - 57s 25ms/step - loss: 0.0828 - acc: 0.9671\n",
      "570/570 [==============================] - 1s 2ms/step\n",
      "Epoch 1/1\n",
      "2280/2280 [==============================] - 58s 25ms/step - loss: 0.0979 - acc: 0.9671\n",
      "568/568 [==============================] - 1s 3ms/step\n",
      "Results: 99.26% (0.58%)\n",
      "Epoch 1/1\n",
      "2278/2278 [==============================] - 58s 25ms/step - loss: 0.0952 - acc: 0.9636\n",
      "Epoch 1/1\n",
      "2278/2278 [==============================] - 59s 26ms/step - loss: 0.0768 - acc: 0.9732\n",
      "Epoch 1/1\n",
      "2278/2278 [==============================] - 57s 25ms/step - loss: 0.0853 - acc: 0.9715\n",
      "Epoch 1/1\n",
      "2278/2278 [==============================] - 58s 25ms/step - loss: 0.0905 - acc: 0.9750\n",
      "Epoch 1/1\n",
      "2280/2280 [==============================] - 58s 25ms/step - loss: 0.0934 - acc: 0.9706\n",
      "Epoch 1/5\n",
      "2848/2848 [==============================] - 77s 27ms/step - loss: 0.0949 - acc: 0.9747\n",
      "Epoch 2/5\n",
      "2848/2848 [==============================] - 80s 28ms/step - loss: 0.0208 - acc: 0.9951\n",
      "Epoch 3/5\n",
      "2848/2848 [==============================] - 81s 29ms/step - loss: 0.0171 - acc: 0.9975\n",
      "Epoch 4/5\n",
      "2848/2848 [==============================] - 78s 27ms/step - loss: 0.0326 - acc: 0.9940\n",
      "Epoch 5/5\n",
      "2848/2848 [==============================] - 75s 26ms/step - loss: 0.0119 - acc: 0.9972\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline #notebook을 실행한 브라우저에서 바로 그림을 볼 수 있게 해주는 것 \n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem, DataStructs\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#setting the seed for reproducibility\n",
    "#seed = 10110\n",
    "seed = 12061204\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "#load the dataset\n",
    "dataframe = pandas.read_csv(\"./pubchem_data/processed/input/BSK_KF3CT_IL1a_up(Input).txt\", sep=\"\\t\")\n",
    "\n",
    "mols = []\n",
    "fps = []\n",
    "\n",
    "#get molecules and then get fingerprints from those\n",
    "for index, row in dataframe.iterrows():\n",
    "    mol = Chem.MolFromSmiles(row['Smiles'])\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2)\n",
    "    mols.append(mol)\n",
    "    fps.append(fp)\n",
    "\n",
    "#Convert the RDKit vectors into numpy arrays\n",
    "#Based on: http://www.rdkit.org/docs/Cookbook.html#using-scikit-learn-with-rdkit\n",
    "np_fps = []\n",
    "for fp in fps:\n",
    "    arr = numpy.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    np_fps.append(arr)\n",
    "\n",
    "np_fps_array = numpy.array(np_fps)\n",
    "\n",
    "#Need to encode my classes\n",
    "#Ligand = 0, not_ligand = 1\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(dataframe['Type'])\n",
    "enc_y = encoder.transform(dataframe['Type'])\n",
    "\n",
    "#Create the machine learning model\n",
    "\n",
    "def create_deep_learning_model():\n",
    "    model = Sequential()\n",
    "    #첫번째 인자 : 출력 뉴런의 수 , input_dim : 입력 뉴런의 수, activation : 활성화 함수.\n",
    "    model.add(Dense(2048, input_dim=2048, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "sm = SMOTE(random_state=12, ratio = 'minority')\n",
    "x_train_res, y_train_res = sm.fit_sample(np_fps_array, enc_y) #결과데이터\n",
    " \n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "#estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5, verbose=0)\n",
    "estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "#results = cross_val_score(estimator, np_fps_array, enc_y, cv=kfold)\n",
    "results = cross_val_score(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "y_pred = cross_val_predict(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "conf_mat = confusion_matrix(y_train_res, y_pred)\n",
    "conf_mat\n",
    "\n",
    "\n",
    "model = create_deep_learning_model()\n",
    "model.fit(x_train_res, y_train_res, epochs=5, batch_size=5)\n",
    "model.save('BSK_KF3CT_IL1a_up(Input)_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2998/2998 [==============================] - 63s 21ms/step - loss: 0.2237 - acc: 0.9053\n",
      "750/750 [==============================] - 2s 2ms/step\n",
      "Epoch 1/1\n",
      "2998/2998 [==============================] - 62s 21ms/step - loss: 0.2232 - acc: 0.9129\n",
      "750/750 [==============================] - 2s 2ms/step\n",
      "Epoch 1/1\n",
      "2998/2998 [==============================] - 62s 21ms/step - loss: 0.2157 - acc: 0.9176\n",
      "750/750 [==============================] - 2s 2ms/step\n",
      "Epoch 1/1\n",
      "2998/2998 [==============================] - 62s 21ms/step - loss: 0.2191 - acc: 0.9159\n",
      "750/750 [==============================] - 2s 2ms/step\n",
      "Epoch 1/1\n",
      "3000/3000 [==============================] - 63s 21ms/step - loss: 0.2291 - acc: 0.9023\n",
      "748/748 [==============================] - 2s 3ms/step\n",
      "Results: 97.63% (0.62%)\n",
      "Epoch 1/1\n",
      "2998/2998 [==============================] - 63s 21ms/step - loss: 0.2190 - acc: 0.9066\n",
      "Epoch 1/1\n",
      "2998/2998 [==============================] - 63s 21ms/step - loss: 0.2141 - acc: 0.9166\n",
      "Epoch 1/1\n",
      "2998/2998 [==============================] - 63s 21ms/step - loss: 0.2170 - acc: 0.9093\n",
      "Epoch 1/1\n",
      "2998/2998 [==============================] - 63s 21ms/step - loss: 0.2046 - acc: 0.9139\n",
      "Epoch 1/1\n",
      "3000/3000 [==============================] - 63s 21ms/step - loss: 0.2359 - acc: 0.9030\n",
      "Epoch 1/5\n",
      "3748/3748 [==============================] - 78s 21ms/step - loss: 0.1982 - acc: 0.9234\n",
      "Epoch 2/5\n",
      "3748/3748 [==============================] - 76s 20ms/step - loss: 0.0585 - acc: 0.9848\n",
      "Epoch 3/5\n",
      "3748/3748 [==============================] - 76s 20ms/step - loss: 0.0306 - acc: 0.9920\n",
      "Epoch 4/5\n",
      "3748/3748 [==============================] - 78s 21ms/step - loss: 0.0318 - acc: 0.9909\n",
      "Epoch 5/5\n",
      "3748/3748 [==============================] - 77s 20ms/step - loss: 0.0253 - acc: 0.9931\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline #notebook을 실행한 브라우저에서 바로 그림을 볼 수 있게 해주는 것 \n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem, DataStructs\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#setting the seed for reproducibility\n",
    "#seed = 10110\n",
    "seed = 12061204\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "#load the dataset\n",
    "dataframe = pandas.read_csv(\"./pubchem_data/processed/input/NVS_ENZ_hMMP9(Input).txt\", sep=\"\\t\")\n",
    "\n",
    "mols = []\n",
    "fps = []\n",
    "\n",
    "#get molecules and then get fingerprints from those\n",
    "for index, row in dataframe.iterrows():\n",
    "    mol = Chem.MolFromSmiles(row['Smiles'])\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2)\n",
    "    mols.append(mol)\n",
    "    fps.append(fp)\n",
    "\n",
    "#Convert the RDKit vectors into numpy arrays\n",
    "#Based on: http://www.rdkit.org/docs/Cookbook.html#using-scikit-learn-with-rdkit\n",
    "np_fps = []\n",
    "for fp in fps:\n",
    "    arr = numpy.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    np_fps.append(arr)\n",
    "\n",
    "np_fps_array = numpy.array(np_fps)\n",
    "\n",
    "#Need to encode my classes\n",
    "#Ligand = 0, not_ligand = 1\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(dataframe['Type'])\n",
    "enc_y = encoder.transform(dataframe['Type'])\n",
    "\n",
    "#Create the machine learning model\n",
    "\n",
    "def create_deep_learning_model():\n",
    "    model = Sequential()\n",
    "    #첫번째 인자 : 출력 뉴런의 수 , input_dim : 입력 뉴런의 수, activation : 활성화 함수.\n",
    "    model.add(Dense(2048, input_dim=2048, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "sm = SMOTE(random_state=12, ratio = 'minority')\n",
    "x_train_res, y_train_res = sm.fit_sample(np_fps_array, enc_y) #결과데이터\n",
    " \n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "#estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5, verbose=0)\n",
    "estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "#results = cross_val_score(estimator, np_fps_array, enc_y, cv=kfold)\n",
    "results = cross_val_score(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "y_pred = cross_val_predict(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "conf_mat = confusion_matrix(y_train_res, y_pred)\n",
    "conf_mat\n",
    "\n",
    "\n",
    "model = create_deep_learning_model()\n",
    "model.fit(x_train_res, y_train_res, epochs=5, batch_size=5)\n",
    "model.save('NVS_ENZ_hMMP9(Input)_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1706/1706 [==============================] - 37s 22ms/step - loss: 0.1380 - acc: 0.9531\n",
      "428/428 [==============================] - 1s 3ms/step\n",
      "Epoch 1/1\n",
      "1706/1706 [==============================] - 37s 21ms/step - loss: 0.1364 - acc: 0.9531\n",
      "428/428 [==============================] - 1s 3ms/step\n",
      "Epoch 1/1\n",
      "1708/1708 [==============================] - 37s 21ms/step - loss: 0.1376 - acc: 0.9555\n",
      "426/426 [==============================] - 1s 3ms/step\n",
      "Epoch 1/1\n",
      "1708/1708 [==============================] - 37s 21ms/step - loss: 0.1306 - acc: 0.9537\n",
      "426/426 [==============================] - 1s 3ms/step\n",
      "Epoch 1/1\n",
      "1708/1708 [==============================] - 37s 22ms/step - loss: 0.1418 - acc: 0.9391\n",
      "426/426 [==============================] - 1s 3ms/step\n",
      "Results: 99.06% (0.47%)\n",
      "Epoch 1/1\n",
      "1706/1706 [==============================] - 37s 22ms/step - loss: 0.1390 - acc: 0.9560\n",
      "Epoch 1/1\n",
      "1706/1706 [==============================] - 37s 22ms/step - loss: 0.1434 - acc: 0.9508\n",
      "Epoch 1/1\n",
      "1708/1708 [==============================] - 37s 22ms/step - loss: 0.1572 - acc: 0.9520\n",
      "Epoch 1/1\n",
      "1708/1708 [==============================] - 37s 22ms/step - loss: 0.1382 - acc: 0.9485\n",
      "Epoch 1/1\n",
      "1708/1708 [==============================] - 37s 22ms/step - loss: 0.1479 - acc: 0.9450\n",
      "Epoch 1/5\n",
      "2134/2134 [==============================] - 46s 21ms/step - loss: 0.1194 - acc: 0.9569\n",
      "Epoch 2/5\n",
      "2134/2134 [==============================] - 44s 20ms/step - loss: 0.0352 - acc: 0.9892\n",
      "Epoch 3/5\n",
      "2134/2134 [==============================] - 44s 20ms/step - loss: 0.0354 - acc: 0.9934\n",
      "Epoch 4/5\n",
      "2134/2134 [==============================] - 43s 20ms/step - loss: 0.0143 - acc: 0.9958\n",
      "Epoch 5/5\n",
      "2134/2134 [==============================] - 43s 20ms/step - loss: 0.0268 - acc: 0.9930\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline #notebook을 실행한 브라우저에서 바로 그림을 볼 수 있게 해주는 것 \n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem, DataStructs\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#setting the seed for reproducibility\n",
    "#seed = 10110\n",
    "seed = 12061204\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "#load the dataset\n",
    "dataframe = pandas.read_csv(\"./pubchem_data/processed/input/NVS_ENZ_hMMP2(Input).txt\", sep=\"\\t\")\n",
    "\n",
    "mols = []\n",
    "fps = []\n",
    "\n",
    "#get molecules and then get fingerprints from those\n",
    "for index, row in dataframe.iterrows():\n",
    "    mol = Chem.MolFromSmiles(row['Smiles'])\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2)\n",
    "    mols.append(mol)\n",
    "    fps.append(fp)\n",
    "\n",
    "#Convert the RDKit vectors into numpy arrays\n",
    "#Based on: http://www.rdkit.org/docs/Cookbook.html#using-scikit-learn-with-rdkit\n",
    "np_fps = []\n",
    "for fp in fps:\n",
    "    arr = numpy.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    np_fps.append(arr)\n",
    "\n",
    "np_fps_array = numpy.array(np_fps)\n",
    "\n",
    "#Need to encode my classes\n",
    "#Ligand = 0, not_ligand = 1\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(dataframe['Type'])\n",
    "enc_y = encoder.transform(dataframe['Type'])\n",
    "\n",
    "#Create the machine learning model\n",
    "\n",
    "def create_deep_learning_model():\n",
    "    model = Sequential()\n",
    "    #첫번째 인자 : 출력 뉴런의 수 , input_dim : 입력 뉴런의 수, activation : 활성화 함수.\n",
    "    model.add(Dense(2048, input_dim=2048, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "sm = SMOTE(random_state=12, ratio = 'minority')\n",
    "x_train_res, y_train_res = sm.fit_sample(np_fps_array, enc_y) #결과데이터\n",
    " \n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "#estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5, verbose=0)\n",
    "estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "#results = cross_val_score(estimator, np_fps_array, enc_y, cv=kfold)\n",
    "results = cross_val_score(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "y_pred = cross_val_predict(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "conf_mat = confusion_matrix(y_train_res, y_pred)\n",
    "conf_mat\n",
    "\n",
    "\n",
    "model = create_deep_learning_model()\n",
    "model.fit(x_train_res, y_train_res, epochs=5, batch_size=5)\n",
    "model.save('NVS_ENZ_hMMP2(Input)_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2188/2188 [==============================] - 47s 22ms/step - loss: 0.2061 - acc: 0.9141\n",
      "548/548 [==============================] - 2s 3ms/step\n",
      "Epoch 1/1\n",
      "2188/2188 [==============================] - 47s 21ms/step - loss: 0.1999 - acc: 0.9264\n",
      "548/548 [==============================] - 2s 3ms/step\n",
      "Epoch 1/1\n",
      "2188/2188 [==============================] - 47s 22ms/step - loss: 0.2471 - acc: 0.9068\n",
      "548/548 [==============================] - 2s 3ms/step\n",
      "Epoch 1/1\n",
      "2190/2190 [==============================] - 47s 22ms/step - loss: 0.2239 - acc: 0.9137\n",
      "546/546 [==============================] - 2s 3ms/step\n",
      "Epoch 1/1\n",
      "2190/2190 [==============================] - 47s 22ms/step - loss: 0.2177 - acc: 0.9110\n",
      "546/546 [==============================] - 2s 3ms/step\n",
      "Results: 97.33% (0.80%)\n",
      "Epoch 1/1\n",
      "2188/2188 [==============================] - 47s 22ms/step - loss: 0.2163 - acc: 0.9154\n",
      "Epoch 1/1\n",
      "2188/2188 [==============================] - 47s 22ms/step - loss: 0.2108 - acc: 0.9164\n",
      "Epoch 1/1\n",
      "2188/2188 [==============================] - 47s 22ms/step - loss: 0.2341 - acc: 0.9004\n",
      "Epoch 1/1\n",
      "2190/2190 [==============================] - 48s 22ms/step - loss: 0.2202 - acc: 0.9192\n",
      "Epoch 1/1\n",
      "2190/2190 [==============================] - 48s 22ms/step - loss: 0.2086 - acc: 0.9233\n",
      "Epoch 1/5\n",
      "2736/2736 [==============================] - 59s 21ms/step - loss: 0.2039 - acc: 0.9145\n",
      "Epoch 2/5\n",
      "2736/2736 [==============================] - 56s 21ms/step - loss: 0.0494 - acc: 0.9861\n",
      "Epoch 3/5\n",
      "2736/2736 [==============================] - 56s 21ms/step - loss: 0.0403 - acc: 0.9876\n",
      "Epoch 4/5\n",
      "2736/2736 [==============================] - 56s 21ms/step - loss: 0.0553 - acc: 0.9865\n",
      "Epoch 5/5\n",
      "2736/2736 [==============================] - 56s 21ms/step - loss: 0.0197 - acc: 0.9938\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline #notebook을 실행한 브라우저에서 바로 그림을 볼 수 있게 해주는 것 \n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem, DataStructs\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#setting the seed for reproducibility\n",
    "#seed = 10110\n",
    "seed = 12061204\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "#load the dataset\n",
    "dataframe = pandas.read_csv(\"./pubchem_data/processed/input/BSK_LPS_TNFa_up(Input).txt\", sep=\"\\t\")\n",
    "\n",
    "mols = []\n",
    "fps = []\n",
    "\n",
    "#get molecules and then get fingerprints from those\n",
    "for index, row in dataframe.iterrows():\n",
    "    mol = Chem.MolFromSmiles(row['Smiles'])\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2)\n",
    "    mols.append(mol)\n",
    "    fps.append(fp)\n",
    "\n",
    "#Convert the RDKit vectors into numpy arrays\n",
    "#Based on: http://www.rdkit.org/docs/Cookbook.html#using-scikit-learn-with-rdkit\n",
    "np_fps = []\n",
    "for fp in fps:\n",
    "    arr = numpy.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    np_fps.append(arr)\n",
    "\n",
    "np_fps_array = numpy.array(np_fps)\n",
    "\n",
    "#Need to encode my classes\n",
    "#Ligand = 0, not_ligand = 1\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(dataframe['Type'])\n",
    "enc_y = encoder.transform(dataframe['Type'])\n",
    "\n",
    "#Create the machine learning model\n",
    "\n",
    "def create_deep_learning_model():\n",
    "    model = Sequential()\n",
    "    #첫번째 인자 : 출력 뉴런의 수 , input_dim : 입력 뉴런의 수, activation : 활성화 함수.\n",
    "    model.add(Dense(2048, input_dim=2048, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "sm = SMOTE(random_state=12, ratio = 'minority')\n",
    "x_train_res, y_train_res = sm.fit_sample(np_fps_array, enc_y) #결과데이터\n",
    " \n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "#estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5, verbose=0)\n",
    "estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "#results = cross_val_score(estimator, np_fps_array, enc_y, cv=kfold)\n",
    "results = cross_val_score(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "y_pred = cross_val_predict(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "conf_mat = confusion_matrix(y_train_res, y_pred)\n",
    "conf_mat\n",
    "\n",
    "\n",
    "model = create_deep_learning_model()\n",
    "model.fit(x_train_res, y_train_res, epochs=5, batch_size=5)\n",
    "model.save('BSK_LPS_TNFa_up(Input)_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1840/1840 [==============================] - 41s 22ms/step - loss: 0.4670 - acc: 0.7772\n",
      "460/460 [==============================] - 2s 4ms/step\n",
      "Epoch 1/1\n",
      "1840/1840 [==============================] - 40s 22ms/step - loss: 0.4548 - acc: 0.7913\n",
      "460/460 [==============================] - 2s 4ms/step\n",
      "Epoch 1/1\n",
      "1840/1840 [==============================] - 40s 22ms/step - loss: 0.4675 - acc: 0.7777\n",
      "460/460 [==============================] - 2s 4ms/step\n",
      "Epoch 1/1\n",
      "1840/1840 [==============================] - 41s 22ms/step - loss: 0.4308 - acc: 0.8087\n",
      "460/460 [==============================] - 2s 4ms/step\n",
      "Epoch 1/1\n",
      "1840/1840 [==============================] - 42s 23ms/step - loss: 0.4990 - acc: 0.7641\n",
      "460/460 [==============================] - 2s 4ms/step\n",
      "Results: 89.17% (1.24%)\n",
      "Epoch 1/1\n",
      "1840/1840 [==============================] - 41s 22ms/step - loss: 0.4495 - acc: 0.7967\n",
      "Epoch 1/1\n",
      "1840/1840 [==============================] - 41s 22ms/step - loss: 0.4706 - acc: 0.7918\n",
      "Epoch 1/1\n",
      "1840/1840 [==============================] - 41s 22ms/step - loss: 0.4488 - acc: 0.7995\n",
      "Epoch 1/1\n",
      "1840/1840 [==============================] - 41s 22ms/step - loss: 0.4409 - acc: 0.8114\n",
      "Epoch 1/1\n",
      "1840/1840 [==============================] - 41s 22ms/step - loss: 0.4904 - acc: 0.7717\n",
      "Epoch 1/5\n",
      "2300/2300 [==============================] - 51s 22ms/step - loss: 0.4407 - acc: 0.8052\n",
      "Epoch 2/5\n",
      "2300/2300 [==============================] - 47s 21ms/step - loss: 0.1309 - acc: 0.9578\n",
      "Epoch 3/5\n",
      "2300/2300 [==============================] - 48s 21ms/step - loss: 0.0546 - acc: 0.9796\n",
      "Epoch 4/5\n",
      "2300/2300 [==============================] - 47s 21ms/step - loss: 0.0542 - acc: 0.9822 0s - loss: 0.0548 - acc: 0\n",
      "Epoch 5/5\n",
      "2300/2300 [==============================] - 47s 21ms/step - loss: 0.0494 - acc: 0.9809\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline #notebook을 실행한 브라우저에서 바로 그림을 볼 수 있게 해주는 것 \n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem, DataStructs\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#setting the seed for reproducibility\n",
    "#seed = 10110\n",
    "seed = 12061204\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "#load the dataset\n",
    "dataframe = pandas.read_csv(\"./pubchem_data/processed/input/BSK_LPS_TNFa_down(Input).txt\", sep=\"\\t\")\n",
    "\n",
    "mols = []\n",
    "fps = []\n",
    "\n",
    "#get molecules and then get fingerprints from those\n",
    "for index, row in dataframe.iterrows():\n",
    "    mol = Chem.MolFromSmiles(row['Smiles'])\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2)\n",
    "    mols.append(mol)\n",
    "    fps.append(fp)\n",
    "\n",
    "#Convert the RDKit vectors into numpy arrays\n",
    "#Based on: http://www.rdkit.org/docs/Cookbook.html#using-scikit-learn-with-rdkit\n",
    "np_fps = []\n",
    "for fp in fps:\n",
    "    arr = numpy.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    np_fps.append(arr)\n",
    "\n",
    "np_fps_array = numpy.array(np_fps)\n",
    "\n",
    "#Need to encode my classes\n",
    "#Ligand = 0, not_ligand = 1\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(dataframe['Type'])\n",
    "enc_y = encoder.transform(dataframe['Type'])\n",
    "\n",
    "#Create the machine learning model\n",
    "\n",
    "def create_deep_learning_model():\n",
    "    model = Sequential()\n",
    "    #첫번째 인자 : 출력 뉴런의 수 , input_dim : 입력 뉴런의 수, activation : 활성화 함수.\n",
    "    model.add(Dense(2048, input_dim=2048, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "sm = SMOTE(random_state=12, ratio = 'minority')\n",
    "x_train_res, y_train_res = sm.fit_sample(np_fps_array, enc_y) #결과데이터\n",
    " \n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "#estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5, verbose=0)\n",
    "estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "#results = cross_val_score(estimator, np_fps_array, enc_y, cv=kfold)\n",
    "results = cross_val_score(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "y_pred = cross_val_predict(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "conf_mat = confusion_matrix(y_train_res, y_pred)\n",
    "conf_mat\n",
    "\n",
    "\n",
    "model = create_deep_learning_model()\n",
    "model.fit(x_train_res, y_train_res, epochs=5, batch_size=5)\n",
    "model.save('BSK_LPS_TNFa_down(Input)_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2274/2274 [==============================] - 50s 22ms/step - loss: 0.0666 - acc: 0.9807\n",
      "570/570 [==============================] - 2s 4ms/step\n",
      "Epoch 1/1\n",
      "2274/2274 [==============================] - 50s 22ms/step - loss: 0.0672 - acc: 0.9758\n",
      "570/570 [==============================] - 2s 4ms/step\n",
      "Epoch 1/1\n",
      "2276/2276 [==============================] - 50s 22ms/step - loss: 0.0681 - acc: 0.9776\n",
      "568/568 [==============================] - 2s 4ms/step\n",
      "Epoch 1/1\n",
      "2276/2276 [==============================] - 50s 22ms/step - loss: 0.0595 - acc: 0.9785\n",
      "568/568 [==============================] - 2s 4ms/step\n",
      "Epoch 1/1\n",
      "2276/2276 [==============================] - 50s 22ms/step - loss: 0.0515 - acc: 0.9824\n",
      "568/568 [==============================] - 2s 4ms/step\n",
      "Results: 99.51% (0.64%)\n",
      "Epoch 1/1\n",
      "2274/2274 [==============================] - 50s 22ms/step - loss: 0.0675 - acc: 0.9776\n",
      "Epoch 1/1\n",
      "2274/2274 [==============================] - 50s 22ms/step - loss: 0.0499 - acc: 0.9820\n",
      "Epoch 1/1\n",
      "2276/2276 [==============================] - 52s 23ms/step - loss: 0.0717 - acc: 0.9728\n",
      "Epoch 1/1\n",
      "2276/2276 [==============================] - 50s 22ms/step - loss: 0.0568 - acc: 0.9815\n",
      "Epoch 1/1\n",
      "2276/2276 [==============================] - 51s 22ms/step - loss: 0.0711 - acc: 0.9741\n",
      "Epoch 1/5\n",
      "2844/2844 [==============================] - 63s 22ms/step - loss: 0.0535 - acc: 0.9863\n",
      "Epoch 2/5\n",
      "2844/2844 [==============================] - 59s 21ms/step - loss: 0.0186 - acc: 0.9965\n",
      "Epoch 3/5\n",
      "2844/2844 [==============================] - 59s 21ms/step - loss: 0.0118 - acc: 0.9979\n",
      "Epoch 4/5\n",
      "2844/2844 [==============================] - 59s 21ms/step - loss: 0.0083 - acc: 0.9986\n",
      "Epoch 5/5\n",
      "2844/2844 [==============================] - 59s 21ms/step - loss: 0.0062 - acc: 0.9993\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline #notebook을 실행한 브라우저에서 바로 그림을 볼 수 있게 해주는 것 \n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem, DataStructs\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#setting the seed for reproducibility\n",
    "#seed = 10110\n",
    "seed = 12061204\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "#load the dataset\n",
    "dataframe = pandas.read_csv(\"./pubchem_data/processed/input/BSK_LPS_IL1a_up(Input).txt\", sep=\"\\t\")\n",
    "\n",
    "mols = []\n",
    "fps = []\n",
    "\n",
    "#get molecules and then get fingerprints from those\n",
    "for index, row in dataframe.iterrows():\n",
    "    mol = Chem.MolFromSmiles(row['Smiles'])\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2)\n",
    "    mols.append(mol)\n",
    "    fps.append(fp)\n",
    "\n",
    "#Convert the RDKit vectors into numpy arrays\n",
    "#Based on: http://www.rdkit.org/docs/Cookbook.html#using-scikit-learn-with-rdkit\n",
    "np_fps = []\n",
    "for fp in fps:\n",
    "    arr = numpy.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    np_fps.append(arr)\n",
    "\n",
    "np_fps_array = numpy.array(np_fps)\n",
    "\n",
    "#Need to encode my classes\n",
    "#Ligand = 0, not_ligand = 1\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(dataframe['Type'])\n",
    "enc_y = encoder.transform(dataframe['Type'])\n",
    "\n",
    "#Create the machine learning model\n",
    "\n",
    "def create_deep_learning_model():\n",
    "    model = Sequential()\n",
    "    #첫번째 인자 : 출력 뉴런의 수 , input_dim : 입력 뉴런의 수, activation : 활성화 함수.\n",
    "    model.add(Dense(2048, input_dim=2048, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "sm = SMOTE(random_state=12, ratio = 'minority')\n",
    "x_train_res, y_train_res = sm.fit_sample(np_fps_array, enc_y) #결과데이터\n",
    " \n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "#estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5, verbose=0)\n",
    "estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "#results = cross_val_score(estimator, np_fps_array, enc_y, cv=kfold)\n",
    "results = cross_val_score(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "y_pred = cross_val_predict(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "conf_mat = confusion_matrix(y_train_res, y_pred)\n",
    "conf_mat\n",
    "\n",
    "\n",
    "model = create_deep_learning_model()\n",
    "model.fit(x_train_res, y_train_res, epochs=5, batch_size=5)\n",
    "model.save('BSK_LPS_IL1a_up(Input)_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1812/1812 [==============================] - 41s 23ms/step - loss: 0.4825 - acc: 0.7892\n",
      "454/454 [==============================] - 2s 5ms/step\n",
      "Epoch 1/1\n",
      "1812/1812 [==============================] - 41s 23ms/step - loss: 0.4876 - acc: 0.7770\n",
      "454/454 [==============================] - 2s 5ms/step\n",
      "Epoch 1/1\n",
      "1812/1812 [==============================] - 41s 23ms/step - loss: 0.4838 - acc: 0.7544\n",
      "454/454 [==============================] - 2s 5ms/step\n",
      "Epoch 1/1\n",
      "1814/1814 [==============================] - 41s 23ms/step - loss: 0.4783 - acc: 0.7641\n",
      "452/452 [==============================] - 2s 5ms/step\n",
      "Epoch 1/1\n",
      "1814/1814 [==============================] - 41s 23ms/step - loss: 0.4896 - acc: 0.7778\n",
      "452/452 [==============================] - 2s 5ms/step\n",
      "Results: 87.82% (1.44%)\n",
      "Epoch 1/1\n",
      "1812/1812 [==============================] - 42s 23ms/step - loss: 0.4749 - acc: 0.7837\n",
      "Epoch 1/1\n",
      "1812/1812 [==============================] - 43s 24ms/step - loss: 0.4757 - acc: 0.7770\n",
      "Epoch 1/1\n",
      "1812/1812 [==============================] - 42s 23ms/step - loss: 0.5094 - acc: 0.7577\n",
      "Epoch 1/1\n",
      "1814/1814 [==============================] - 42s 23ms/step - loss: 0.4792 - acc: 0.7811\n",
      "Epoch 1/1\n",
      "1814/1814 [==============================] - 42s 23ms/step - loss: 0.4737 - acc: 0.7806\n",
      "Epoch 1/5\n",
      "2266/2266 [==============================] - 52s 23ms/step - loss: 0.4357 - acc: 0.8045\n",
      "Epoch 2/5\n",
      "2266/2266 [==============================] - 47s 21ms/step - loss: 0.1115 - acc: 0.9660\n",
      "Epoch 3/5\n",
      "2266/2266 [==============================] - 48s 21ms/step - loss: 0.0518 - acc: 0.9841\n",
      "Epoch 4/5\n",
      "2266/2266 [==============================] - 48s 21ms/step - loss: 0.0366 - acc: 0.9859\n",
      "Epoch 5/5\n",
      "2266/2266 [==============================] - 48s 21ms/step - loss: 0.0451 - acc: 0.9841\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline #notebook을 실행한 브라우저에서 바로 그림을 볼 수 있게 해주는 것 \n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem, DataStructs\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#setting the seed for reproducibility\n",
    "#seed = 10110\n",
    "seed = 12061204\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "#load the dataset\n",
    "dataframe = pandas.read_csv(\"./pubchem_data/processed/input/BSK_LPS_IL1a_down(Input).txt\", sep=\"\\t\")\n",
    "\n",
    "mols = []\n",
    "fps = []\n",
    "\n",
    "#get molecules and then get fingerprints from those\n",
    "for index, row in dataframe.iterrows():\n",
    "    mol = Chem.MolFromSmiles(row['Smiles'])\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2)\n",
    "    mols.append(mol)\n",
    "    fps.append(fp)\n",
    "\n",
    "#Convert the RDKit vectors into numpy arrays\n",
    "#Based on: http://www.rdkit.org/docs/Cookbook.html#using-scikit-learn-with-rdkit\n",
    "np_fps = []\n",
    "for fp in fps:\n",
    "    arr = numpy.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    np_fps.append(arr)\n",
    "\n",
    "np_fps_array = numpy.array(np_fps)\n",
    "\n",
    "#Need to encode my classes\n",
    "#Ligand = 0, not_ligand = 1\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(dataframe['Type'])\n",
    "enc_y = encoder.transform(dataframe['Type'])\n",
    "\n",
    "#Create the machine learning model\n",
    "\n",
    "def create_deep_learning_model():\n",
    "    model = Sequential()\n",
    "    #첫번째 인자 : 출력 뉴런의 수 , input_dim : 입력 뉴런의 수, activation : 활성화 함수.\n",
    "    model.add(Dense(2048, input_dim=2048, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "sm = SMOTE(random_state=12, ratio = 'minority')\n",
    "x_train_res, y_train_res = sm.fit_sample(np_fps_array, enc_y) #결과데이터\n",
    " \n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "#estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5, verbose=0)\n",
    "estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "#results = cross_val_score(estimator, np_fps_array, enc_y, cv=kfold)\n",
    "results = cross_val_score(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "y_pred = cross_val_predict(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "conf_mat = confusion_matrix(y_train_res, y_pred)\n",
    "conf_mat\n",
    "\n",
    "\n",
    "model = create_deep_learning_model()\n",
    "model.fit(x_train_res, y_train_res, epochs=5, batch_size=5)\n",
    "model.save('BSK_LPS_IL1a_down(Input)_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1840/1840 [==============================] - 43s 23ms/step - loss: 0.4752 - acc: 0.7783\n",
      "460/460 [==============================] - 3s 5ms/step\n",
      "Epoch 1/1\n",
      "1840/1840 [==============================] - 42s 23ms/step - loss: 0.4497 - acc: 0.8038\n",
      "460/460 [==============================] - 3s 5ms/step\n",
      "Epoch 1/1\n",
      "1840/1840 [==============================] - 42s 23ms/step - loss: 0.4730 - acc: 0.7739\n",
      "460/460 [==============================] - 3s 6ms/step\n",
      "Epoch 1/1\n",
      "1840/1840 [==============================] - 43s 23ms/step - loss: 0.4778 - acc: 0.7750\n",
      "460/460 [==============================] - 3s 6ms/step\n",
      "Epoch 1/1\n",
      "1840/1840 [==============================] - 43s 23ms/step - loss: 0.4597 - acc: 0.7886\n",
      "460/460 [==============================] - 3s 6ms/step\n",
      "Results: 88.22% (2.61%)\n",
      "Epoch 1/1\n",
      "1840/1840 [==============================] - 43s 23ms/step - loss: 0.4837 - acc: 0.7793\n",
      "Epoch 1/1\n",
      "1840/1840 [==============================] - 43s 23ms/step - loss: 0.4600 - acc: 0.7913\n",
      "Epoch 1/1\n",
      "1840/1840 [==============================] - 43s 23ms/step - loss: 0.4591 - acc: 0.7973\n",
      "Epoch 1/1\n",
      "1840/1840 [==============================] - 43s 23ms/step - loss: 0.4466 - acc: 0.7967\n",
      "Epoch 1/1\n",
      "1840/1840 [==============================] - 43s 23ms/step - loss: 0.4499 - acc: 0.7935\n",
      "Epoch 1/5\n",
      "2300/2300 [==============================] - 53s 23ms/step - loss: 0.4247 - acc: 0.8070\n",
      "Epoch 2/5\n",
      "2300/2300 [==============================] - 48s 21ms/step - loss: 0.1177 - acc: 0.9635\n",
      "Epoch 3/5\n",
      "2300/2300 [==============================] - 48s 21ms/step - loss: 0.0719 - acc: 0.9765\n",
      "Epoch 4/5\n",
      "2300/2300 [==============================] - 49s 21ms/step - loss: 0.0462 - acc: 0.9822\n",
      "Epoch 5/5\n",
      "2300/2300 [==============================] - 48s 21ms/step - loss: 0.0305 - acc: 0.9865\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline #notebook을 실행한 브라우저에서 바로 그림을 볼 수 있게 해주는 것 \n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem, DataStructs\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#setting the seed for reproducibility\n",
    "#seed = 10110\n",
    "seed = 12061204\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "#load the dataset\n",
    "dataframe = pandas.read_csv(\"./pubchem_data/processed/input/BSK_KF3CT_TGFb1_downInput).txt\", sep=\"\\t\")\n",
    "\n",
    "mols = []\n",
    "fps = []\n",
    "\n",
    "#get molecules and then get fingerprints from those\n",
    "for index, row in dataframe.iterrows():\n",
    "    mol = Chem.MolFromSmiles(row['Smiles'])\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2)\n",
    "    mols.append(mol)\n",
    "    fps.append(fp)\n",
    "\n",
    "#Convert the RDKit vectors into numpy arrays\n",
    "#Based on: http://www.rdkit.org/docs/Cookbook.html#using-scikit-learn-with-rdkit\n",
    "np_fps = []\n",
    "for fp in fps:\n",
    "    arr = numpy.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    np_fps.append(arr)\n",
    "\n",
    "np_fps_array = numpy.array(np_fps)\n",
    "\n",
    "#Need to encode my classes\n",
    "#Ligand = 0, not_ligand = 1\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(dataframe['Type'])\n",
    "enc_y = encoder.transform(dataframe['Type'])\n",
    "\n",
    "#Create the machine learning model\n",
    "\n",
    "def create_deep_learning_model():\n",
    "    model = Sequential()\n",
    "    #첫번째 인자 : 출력 뉴런의 수 , input_dim : 입력 뉴런의 수, activation : 활성화 함수.\n",
    "    model.add(Dense(2048, input_dim=2048, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "sm = SMOTE(random_state=12, ratio = 'minority')\n",
    "x_train_res, y_train_res = sm.fit_sample(np_fps_array, enc_y) #결과데이터\n",
    " \n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "#estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5, verbose=0)\n",
    "estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "#results = cross_val_score(estimator, np_fps_array, enc_y, cv=kfold)\n",
    "results = cross_val_score(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "y_pred = cross_val_predict(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "conf_mat = confusion_matrix(y_train_res, y_pred)\n",
    "conf_mat\n",
    "\n",
    "\n",
    "model = create_deep_learning_model()\n",
    "model.fit(x_train_res, y_train_res, epochs=5, batch_size=5)\n",
    "model.save('BSK_KF3CT_TGFb1_down(Input)_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2302/2302 [==============================] - 53s 23ms/step - loss: 0.0453 - acc: 0.9831\n",
      "576/576 [==============================] - 3s 5ms/step\n",
      "Epoch 1/1\n",
      "2302/2302 [==============================] - 53s 23ms/step - loss: 0.0470 - acc: 0.9848\n",
      "576/576 [==============================] - 3s 6ms/step\n",
      "Epoch 1/1\n",
      "2302/2302 [==============================] - 53s 23ms/step - loss: 0.0578 - acc: 0.9805\n",
      "576/576 [==============================] - 3s 6ms/step\n",
      "Epoch 1/1\n",
      "2302/2302 [==============================] - 53s 23ms/step - loss: 0.0544 - acc: 0.9805\n",
      "576/576 [==============================] - 3s 6ms/step\n",
      "Epoch 1/1\n",
      "2304/2304 [==============================] - 53s 23ms/step - loss: 0.0442 - acc: 0.9835\n",
      "574/574 [==============================] - 3s 6ms/step\n",
      "Results: 99.55% (0.51%)\n",
      "Epoch 1/1\n",
      "2302/2302 [==============================] - 53s 23ms/step - loss: 0.0530 - acc: 0.9852\n",
      "Epoch 1/1\n",
      "2302/2302 [==============================] - 53s 23ms/step - loss: 0.0407 - acc: 0.9891\n",
      "Epoch 1/1\n",
      "2302/2302 [==============================] - 53s 23ms/step - loss: 0.0547 - acc: 0.9874\n",
      "Epoch 1/1\n",
      "2302/2302 [==============================] - 54s 23ms/step - loss: 0.0445 - acc: 0.9822\n",
      "Epoch 1/1\n",
      "2304/2304 [==============================] - 54s 23ms/step - loss: 0.0779 - acc: 0.9770\n",
      "Epoch 1/5\n",
      "2878/2878 [==============================] - 66s 23ms/step - loss: 0.0470 - acc: 0.9889\n",
      "Epoch 2/5\n",
      "2878/2878 [==============================] - 61s 21ms/step - loss: 0.0210 - acc: 0.9962\n",
      "Epoch 3/5\n",
      "2878/2878 [==============================] - 61s 21ms/step - loss: 0.0058 - acc: 0.9990\n",
      "Epoch 4/5\n",
      "2878/2878 [==============================] - 61s 21ms/step - loss: 0.0053 - acc: 0.9993\n",
      "Epoch 5/5\n",
      "2878/2878 [==============================] - 61s 21ms/step - loss: 0.0035 - acc: 0.9990\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline #notebook을 실행한 브라우저에서 바로 그림을 볼 수 있게 해주는 것 \n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem, DataStructs\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#setting the seed for reproducibility\n",
    "#seed = 10110\n",
    "seed = 12061204\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "#load the dataset\n",
    "dataframe = pandas.read_csv(\"./pubchem_data/processed/input/BSK_KF3CT_TGFb1_down(Input).txt\", sep=\"\\t\")\n",
    "\n",
    "mols = []\n",
    "fps = []\n",
    "\n",
    "#get molecules and then get fingerprints from those\n",
    "for index, row in dataframe.iterrows():\n",
    "    mol = Chem.MolFromSmiles(row['Smiles'])\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2)\n",
    "    mols.append(mol)\n",
    "    fps.append(fp)\n",
    "\n",
    "#Convert the RDKit vectors into numpy arrays\n",
    "#Based on: http://www.rdkit.org/docs/Cookbook.html#using-scikit-learn-with-rdkit\n",
    "np_fps = []\n",
    "for fp in fps:\n",
    "    arr = numpy.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    np_fps.append(arr)\n",
    "\n",
    "np_fps_array = numpy.array(np_fps)\n",
    "\n",
    "#Need to encode my classes\n",
    "#Ligand = 0, not_ligand = 1\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(dataframe['Type'])\n",
    "enc_y = encoder.transform(dataframe['Type'])\n",
    "\n",
    "#Create the machine learning model\n",
    "\n",
    "def create_deep_learning_model():\n",
    "    model = Sequential()\n",
    "    #첫번째 인자 : 출력 뉴런의 수 , input_dim : 입력 뉴런의 수, activation : 활성화 함수.\n",
    "    model.add(Dense(2048, input_dim=2048, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "sm = SMOTE(random_state=12, ratio = 'minority')\n",
    "x_train_res, y_train_res = sm.fit_sample(np_fps_array, enc_y) #결과데이터\n",
    " \n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "#estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5, verbose=0)\n",
    "estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "#results = cross_val_score(estimator, np_fps_array, enc_y, cv=kfold)\n",
    "results = cross_val_score(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "y_pred = cross_val_predict(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "conf_mat = confusion_matrix(y_train_res, y_pred)\n",
    "conf_mat\n",
    "\n",
    "\n",
    "model = create_deep_learning_model()\n",
    "model.fit(x_train_res, y_train_res, epochs=5, batch_size=5)\n",
    "model.save('BSK_KF3CT_TGFb1_downInput)_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 6",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-32f6ee5c1357>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[0msm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mratio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'minority'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m \u001b[0mx_train_res\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_res\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp_fps_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menc_y\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#결과데이터\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36mfit_sample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     86\u001b[0m         \"\"\"\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36msample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfit_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\imblearn\\over_sampling\\smote.py\u001b[0m in \u001b[0;36m_sample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'regular'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 594\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sample_regular\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    595\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'borderline1'\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'borderline2'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sample_borderline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\imblearn\\over_sampling\\smote.py\u001b[0m in \u001b[0;36m_sample_regular\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn_k_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_class\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 360\u001b[1;33m             \u001b[0mnns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn_k_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    361\u001b[0m             X_new, y_new = self._make_samples(X_class, class_sample, X_class,\n\u001b[0;32m    362\u001b[0m                                               nns, n_samples, 1.0)\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\neighbors\\base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    345\u001b[0m                 \u001b[1;34m\"Expected n_neighbors <= n_samples, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    346\u001b[0m                 \u001b[1;34m\" but n_samples = %d, n_neighbors = %d\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 347\u001b[1;33m                 \u001b[1;33m(\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    348\u001b[0m             )\n\u001b[0;32m    349\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 6"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline #notebook을 실행한 브라우저에서 바로 그림을 볼 수 있게 해주는 것 \n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem, DataStructs\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#setting the seed for reproducibility\n",
    "#seed = 10110\n",
    "seed = 12061204\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "#load the dataset\n",
    "dataframe = pandas.read_csv(\"./pubchem_data/processed/input/BSK_KF3CT_MMP9_up(Input).txt\", sep=\"\\t\")\n",
    "\n",
    "mols = []\n",
    "fps = []\n",
    "\n",
    "#get molecules and then get fingerprints from those\n",
    "for index, row in dataframe.iterrows():\n",
    "    mol = Chem.MolFromSmiles(row['Smiles'])\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2)\n",
    "    mols.append(mol)\n",
    "    fps.append(fp)\n",
    "\n",
    "#Convert the RDKit vectors into numpy arrays\n",
    "#Based on: http://www.rdkit.org/docs/Cookbook.html#using-scikit-learn-with-rdkit\n",
    "np_fps = []\n",
    "for fp in fps:\n",
    "    arr = numpy.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    np_fps.append(arr)\n",
    "\n",
    "np_fps_array = numpy.array(np_fps)\n",
    "\n",
    "#Need to encode my classes\n",
    "#Ligand = 0, not_ligand = 1\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(dataframe['Type'])\n",
    "enc_y = encoder.transform(dataframe['Type'])\n",
    "\n",
    "#Create the machine learning model\n",
    "\n",
    "def create_deep_learning_model():\n",
    "    model = Sequential()\n",
    "    #첫번째 인자 : 출력 뉴런의 수 , input_dim : 입력 뉴런의 수, activation : 활성화 함수.\n",
    "    model.add(Dense(2048, input_dim=2048, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "sm = SMOTE(random_state=12, ratio = 'minority')\n",
    "x_train_res, y_train_res = sm.fit_sample(np_fps_array, enc_y) #결과데이터\n",
    " \n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "#estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5, verbose=0)\n",
    "estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "#results = cross_val_score(estimator, np_fps_array, enc_y, cv=kfold)\n",
    "results = cross_val_score(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "y_pred = cross_val_predict(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "conf_mat = confusion_matrix(y_train_res, y_pred)\n",
    "conf_mat\n",
    "\n",
    "\n",
    "model = create_deep_learning_model()\n",
    "model.fit(x_train_res, y_train_res, epochs=5, batch_size=5)\n",
    "model.save('BSK_KF3CT_MMP9_up(Input)_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1682/1682 [==============================] - 36s 21ms/step - loss: 0.5363 - acc: 0.7366\n",
      "422/422 [==============================] - 1s 2ms/step\n",
      "Epoch 1/1\n",
      "1682/1682 [==============================] - 36s 21ms/step - loss: 0.5396 - acc: 0.7378\n",
      "422/422 [==============================] - 1s 2ms/step\n",
      "Epoch 1/1\n",
      "1684/1684 [==============================] - 35s 21ms/step - loss: 0.5415 - acc: 0.7262\n",
      "420/420 [==============================] - 1s 3ms/step\n",
      "Epoch 1/1\n",
      "1684/1684 [==============================] - 35s 21ms/step - loss: 0.5544 - acc: 0.7322\n",
      "420/420 [==============================] - 1s 2ms/step\n",
      "Epoch 1/1\n",
      "1684/1684 [==============================] - 34s 20ms/step - loss: 0.5556 - acc: 0.7257\n",
      "420/420 [==============================] - 1s 2ms/step\n",
      "Results: 82.17% (2.01%)\n",
      "Epoch 1/1\n",
      "1682/1682 [==============================] - 34s 20ms/step - loss: 0.5497 - acc: 0.7247\n",
      "Epoch 1/1\n",
      "1682/1682 [==============================] - 34s 20ms/step - loss: 0.5380 - acc: 0.7313\n",
      "Epoch 1/1\n",
      "1684/1684 [==============================] - 34s 20ms/step - loss: 0.5358 - acc: 0.7334\n",
      "Epoch 1/1\n",
      "1684/1684 [==============================] - 34s 20ms/step - loss: 0.5351 - acc: 0.7464\n",
      "Epoch 1/1\n",
      "1684/1684 [==============================] - 35s 21ms/step - loss: 0.5396 - acc: 0.7393\n",
      "Epoch 1/5\n",
      "2104/2104 [==============================] - 42s 20ms/step - loss: 0.5222 - acc: 0.7590\n",
      "Epoch 2/5\n",
      "2104/2104 [==============================] - 41s 20ms/step - loss: 0.1577 - acc: 0.9444\n",
      "Epoch 3/5\n",
      "2104/2104 [==============================] - 41s 20ms/step - loss: 0.0677 - acc: 0.9781\n",
      "Epoch 4/5\n",
      "2104/2104 [==============================] - 41s 20ms/step - loss: 0.0634 - acc: 0.9815\n",
      "Epoch 5/5\n",
      "2104/2104 [==============================] - 41s 20ms/step - loss: 0.0317 - acc: 0.9857\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline #notebook을 실행한 브라우저에서 바로 그림을 볼 수 있게 해주는 것 \n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem, DataStructs\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#setting the seed for reproducibility\n",
    "#seed = 10110\n",
    "seed = 12061204\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "#load the dataset\n",
    "dataframe = pandas.read_csv(\"./pubchem_data/processed/input/BSK_KF3CT_MMP9_down(Input).txt\", sep=\"\\t\")\n",
    "\n",
    "mols = []\n",
    "fps = []\n",
    "\n",
    "#get molecules and then get fingerprints from those\n",
    "for index, row in dataframe.iterrows():\n",
    "    mol = Chem.MolFromSmiles(row['Smiles'])\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2)\n",
    "    mols.append(mol)\n",
    "    fps.append(fp)\n",
    "\n",
    "#Convert the RDKit vectors into numpy arrays\n",
    "#Based on: http://www.rdkit.org/docs/Cookbook.html#using-scikit-learn-with-rdkit\n",
    "np_fps = []\n",
    "for fp in fps:\n",
    "    arr = numpy.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    np_fps.append(arr)\n",
    "\n",
    "np_fps_array = numpy.array(np_fps)\n",
    "\n",
    "#Need to encode my classes\n",
    "#Ligand = 0, not_ligand = 1\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(dataframe['Type'])\n",
    "enc_y = encoder.transform(dataframe['Type'])\n",
    "\n",
    "#Create the machine learning model\n",
    "\n",
    "def create_deep_learning_model():\n",
    "    model = Sequential()\n",
    "    #첫번째 인자 : 출력 뉴런의 수 , input_dim : 입력 뉴런의 수, activation : 활성화 함수.\n",
    "    model.add(Dense(2048, input_dim=2048, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "sm = SMOTE(random_state=12, ratio = 'minority')\n",
    "x_train_res, y_train_res = sm.fit_sample(np_fps_array, enc_y) #결과데이터\n",
    " \n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "#estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5, verbose=0)\n",
    "estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "#results = cross_val_score(estimator, np_fps_array, enc_y, cv=kfold)\n",
    "results = cross_val_score(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "y_pred = cross_val_predict(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "conf_mat = confusion_matrix(y_train_res, y_pred)\n",
    "conf_mat\n",
    "\n",
    "\n",
    "model = create_deep_learning_model()\n",
    "model.fit(x_train_res, y_train_res, epochs=5, batch_size=5)\n",
    "model.save('BSK_KF3CT_MMP9_down(Input)_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline #notebook을 실행한 브라우저에서 바로 그림을 볼 수 있게 해주는 것 \n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem, DataStructs\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#setting the seed for reproducibility\n",
    "#seed = 10110\n",
    "seed = 12061204\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "#load the dataset\n",
    "dataframe = pandas.read_csv(\"./pubchem_data/processed/input/BSK_KF3CT_IL1a_up(Input).txt\", sep=\"\\t\")\n",
    "\n",
    "mols = []\n",
    "fps = []\n",
    "\n",
    "#get molecules and then get fingerprints from those\n",
    "for index, row in dataframe.iterrows():\n",
    "    mol = Chem.MolFromSmiles(row['Smiles'])\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2)\n",
    "    mols.append(mol)\n",
    "    fps.append(fp)\n",
    "\n",
    "#Convert the RDKit vectors into numpy arrays\n",
    "#Based on: http://www.rdkit.org/docs/Cookbook.html#using-scikit-learn-with-rdkit\n",
    "np_fps = []\n",
    "for fp in fps:\n",
    "    arr = numpy.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    np_fps.append(arr)\n",
    "\n",
    "np_fps_array = numpy.array(np_fps)\n",
    "\n",
    "#Need to encode my classes\n",
    "#Ligand = 0, not_ligand = 1\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(dataframe['Type'])\n",
    "enc_y = encoder.transform(dataframe['Type'])\n",
    "\n",
    "#Create the machine learning model\n",
    "\n",
    "def create_deep_learning_model():\n",
    "    model = Sequential()\n",
    "    #첫번째 인자 : 출력 뉴런의 수 , input_dim : 입력 뉴런의 수, activation : 활성화 함수.\n",
    "    model.add(Dense(2048, input_dim=2048, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "sm = SMOTE(random_state=12, ratio = 'minority')\n",
    "x_train_res, y_train_res = sm.fit_sample(np_fps_array, enc_y) #결과데이터\n",
    " \n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "#estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5, verbose=0)\n",
    "estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "#results = cross_val_score(estimator, np_fps_array, enc_y, cv=kfold)\n",
    "results = cross_val_score(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "y_pred = cross_val_predict(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "conf_mat = confusion_matrix(y_train_res, y_pred)\n",
    "conf_mat\n",
    "\n",
    "\n",
    "model = create_deep_learning_model()\n",
    "model.fit(x_train_res, y_train_res, epochs=5, batch_size=5)\n",
    "model.save('BSK_KF3CT_IL1a_up(Input)_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1832/1832 [==============================] - 47s 26ms/step - loss: 0.4600 - acc: 0.7806\n",
      "460/460 [==============================] - 1s 3ms/step\n",
      "Epoch 1/1\n",
      "1834/1834 [==============================] - 47s 26ms/step - loss: 0.4624 - acc: 0.7993\n",
      "458/458 [==============================] - 1s 3ms/step\n",
      "Epoch 1/1\n",
      "1834/1834 [==============================] - 47s 26ms/step - loss: 0.4585 - acc: 0.7928\n",
      "458/458 [==============================] - 1s 3ms/step\n",
      "Epoch 1/1\n",
      "1834/1834 [==============================] - 47s 26ms/step - loss: 0.4583 - acc: 0.7824\n",
      "458/458 [==============================] - 2s 4ms/step\n",
      "Epoch 1/1\n",
      "1834/1834 [==============================] - 47s 26ms/step - loss: 0.4599 - acc: 0.8075\n",
      "458/458 [==============================] - 1s 3ms/step\n",
      "Results: 88.70% (1.94%)\n",
      "Epoch 1/1\n",
      "1832/1832 [==============================] - 47s 26ms/step - loss: 0.4645 - acc: 0.7866\n",
      "Epoch 1/1\n",
      "1834/1834 [==============================] - 48s 26ms/step - loss: 0.4583 - acc: 0.7775\n",
      "Epoch 1/1\n",
      "1834/1834 [==============================] - 48s 26ms/step - loss: 0.4826 - acc: 0.7830\n",
      "Epoch 1/1\n",
      "1834/1834 [==============================] - 48s 26ms/step - loss: 0.4772 - acc: 0.7754\n",
      "Epoch 1/1\n",
      "1834/1834 [==============================] - 48s 26ms/step - loss: 0.4684 - acc: 0.7879\n",
      "Epoch 1/5\n",
      "2292/2292 [==============================] - 59s 26ms/step - loss: 0.4146 - acc: 0.8255\n",
      "Epoch 2/5\n",
      "2292/2292 [==============================] - 56s 24ms/step - loss: 0.1239 - acc: 0.9590\n",
      "Epoch 3/5\n",
      "2292/2292 [==============================] - 56s 25ms/step - loss: 0.0696 - acc: 0.9764\n",
      "Epoch 4/5\n",
      "2292/2292 [==============================] - 56s 24ms/step - loss: 0.0634 - acc: 0.9799\n",
      "Epoch 5/5\n",
      "2292/2292 [==============================] - 56s 24ms/step - loss: 0.0338 - acc: 0.9869\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline #notebook을 실행한 브라우저에서 바로 그림을 볼 수 있게 해주는 것 \n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem, DataStructs\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#setting the seed for reproducibility\n",
    "#seed = 10110\n",
    "seed = 12061204\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "#load the dataset\n",
    "dataframe = pandas.read_csv(\"./pubchem_data/processed/input/BSK_KF3CT_IL1a_down(Input).txt\", sep=\"\\t\")\n",
    "\n",
    "mols = []\n",
    "fps = []\n",
    "\n",
    "#get molecules and then get fingerprints from those\n",
    "for index, row in dataframe.iterrows():\n",
    "    mol = Chem.MolFromSmiles(row['Smiles'])\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2)\n",
    "    mols.append(mol)\n",
    "    fps.append(fp)\n",
    "\n",
    "#Convert the RDKit vectors into numpy arrays\n",
    "#Based on: http://www.rdkit.org/docs/Cookbook.html#using-scikit-learn-with-rdkit\n",
    "np_fps = []\n",
    "for fp in fps:\n",
    "    arr = numpy.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    np_fps.append(arr)\n",
    "\n",
    "np_fps_array = numpy.array(np_fps)\n",
    "\n",
    "#Need to encode my classes\n",
    "#Ligand = 0, not_ligand = 1\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(dataframe['Type'])\n",
    "enc_y = encoder.transform(dataframe['Type'])\n",
    "\n",
    "#Create the machine learning model\n",
    "\n",
    "def create_deep_learning_model():\n",
    "    model = Sequential()\n",
    "    #첫번째 인자 : 출력 뉴런의 수 , input_dim : 입력 뉴런의 수, activation : 활성화 함수.\n",
    "    model.add(Dense(2048, input_dim=2048, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "sm = SMOTE(random_state=12, ratio = 'minority')\n",
    "x_train_res, y_train_res = sm.fit_sample(np_fps_array, enc_y) #결과데이터\n",
    " \n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "#estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5, verbose=0)\n",
    "estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "#results = cross_val_score(estimator, np_fps_array, enc_y, cv=kfold)\n",
    "results = cross_val_score(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "y_pred = cross_val_predict(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "conf_mat = confusion_matrix(y_train_res, y_pred)\n",
    "conf_mat\n",
    "\n",
    "\n",
    "model = create_deep_learning_model()\n",
    "model.fit(x_train_res, y_train_res, epochs=5, batch_size=5)\n",
    "model.save('BSK_KF3CT_IL1a_down(Input).h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2232/2232 [==============================] - 58s 26ms/step - loss: 0.1186 - acc: 0.9570\n",
      "558/558 [==============================] - 2s 4ms/step\n",
      "Epoch 1/1\n",
      "2232/2232 [==============================] - 58s 26ms/step - loss: 0.1196 - acc: 0.9583\n",
      "558/558 [==============================] - 2s 4ms/step\n",
      "Epoch 1/1\n",
      "2232/2232 [==============================] - 58s 26ms/step - loss: 0.1048 - acc: 0.9637\n",
      "558/558 [==============================] - 2s 4ms/step\n",
      "Epoch 1/1\n",
      "2232/2232 [==============================] - 58s 26ms/step - loss: 0.1198 - acc: 0.9574\n",
      "558/558 [==============================] - 2s 4ms/step\n",
      "Epoch 1/1\n",
      "2232/2232 [==============================] - 59s 26ms/step - loss: 0.1189 - acc: 0.9539\n",
      "558/558 [==============================] - 2s 4ms/step\n",
      "Results: 98.78% (1.00%)\n",
      "Epoch 1/1\n",
      "2232/2232 [==============================] - 59s 26ms/step - loss: 0.1200 - acc: 0.9565\n",
      "Epoch 1/1\n",
      "2232/2232 [==============================] - 58s 26ms/step - loss: 0.1334 - acc: 0.9534\n",
      "Epoch 1/1\n",
      "2232/2232 [==============================] - 58s 26ms/step - loss: 0.1185 - acc: 0.9570\n",
      "Epoch 1/1\n",
      "2232/2232 [==============================] - 58s 26ms/step - loss: 0.1173 - acc: 0.9601\n",
      "Epoch 1/1\n",
      "2232/2232 [==============================] - 58s 26ms/step - loss: 0.1308 - acc: 0.9409\n",
      "Epoch 1/5\n",
      "2790/2790 [==============================] - 73s 26ms/step - loss: 0.0974 - acc: 0.9620\n",
      "Epoch 2/5\n",
      "2790/2790 [==============================] - 73s 26ms/step - loss: 0.0335 - acc: 0.9928\n",
      "Epoch 3/5\n",
      "2790/2790 [==============================] - 70s 25ms/step - loss: 0.0171 - acc: 0.9971\n",
      "Epoch 4/5\n",
      "2790/2790 [==============================] - 69s 25ms/step - loss: 0.0322 - acc: 0.9946\n",
      "Epoch 5/5\n",
      "2790/2790 [==============================] - 68s 25ms/step - loss: 0.0194 - acc: 0.9957\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline #notebook을 실행한 브라우저에서 바로 그림을 볼 수 있게 해주는 것 \n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem, DataStructs\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#setting the seed for reproducibility\n",
    "#seed = 10110\n",
    "seed = 12061204\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "#load the dataset\n",
    "dataframe = pandas.read_csv(\"./pubchem_data/processed/input/BSK_CASM3C_IL6_up(Input).txt\", sep=\"\\t\")\n",
    "\n",
    "mols = []\n",
    "fps = []\n",
    "\n",
    "#get molecules and then get fingerprints from those\n",
    "for index, row in dataframe.iterrows():\n",
    "    mol = Chem.MolFromSmiles(row['Smiles'])\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2)\n",
    "    mols.append(mol)\n",
    "    fps.append(fp)\n",
    "\n",
    "#Convert the RDKit vectors into numpy arrays\n",
    "#Based on: http://www.rdkit.org/docs/Cookbook.html#using-scikit-learn-with-rdkit\n",
    "np_fps = []\n",
    "for fp in fps:\n",
    "    arr = numpy.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    np_fps.append(arr)\n",
    "\n",
    "np_fps_array = numpy.array(np_fps)\n",
    "\n",
    "#Need to encode my classes\n",
    "#Ligand = 0, not_ligand = 1\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(dataframe['Type'])\n",
    "enc_y = encoder.transform(dataframe['Type'])\n",
    "\n",
    "#Create the machine learning model\n",
    "\n",
    "def create_deep_learning_model():\n",
    "    model = Sequential()\n",
    "    #첫번째 인자 : 출력 뉴런의 수 , input_dim : 입력 뉴런의 수, activation : 활성화 함수.\n",
    "    model.add(Dense(2048, input_dim=2048, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "sm = SMOTE(random_state=12, ratio = 'minority')\n",
    "x_train_res, y_train_res = sm.fit_sample(np_fps_array, enc_y) #결과데이터\n",
    " \n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "#estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5, verbose=0)\n",
    "estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "#results = cross_val_score(estimator, np_fps_array, enc_y, cv=kfold)\n",
    "results = cross_val_score(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "y_pred = cross_val_predict(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "conf_mat = confusion_matrix(y_train_res, y_pred)\n",
    "conf_mat\n",
    "\n",
    "\n",
    "model = create_deep_learning_model()\n",
    "model.fit(x_train_res, y_train_res, epochs=5, batch_size=5)\n",
    "model.save('BSK_CASM3C_IL6_up(Input).h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1974/1974 [==============================] - 52s 26ms/step - loss: 0.3465 - acc: 0.8480\n",
      "494/494 [==============================] - 2s 4ms/step\n",
      "Epoch 1/1\n",
      "1974/1974 [==============================] - 53s 27ms/step - loss: 0.3498 - acc: 0.8465\n",
      "494/494 [==============================] - 3s 5ms/step\n",
      "Epoch 1/1\n",
      "1974/1974 [==============================] - 56s 28ms/step - loss: 0.3634 - acc: 0.8404\n",
      "494/494 [==============================] - 2s 5ms/step\n",
      "Epoch 1/1\n",
      "1974/1974 [==============================] - 56s 28ms/step - loss: 0.3577 - acc: 0.8389\n",
      "494/494 [==============================] - 2s 5ms/step\n",
      "Epoch 1/1\n",
      "1976/1976 [==============================] - 57s 29ms/step - loss: 0.3578 - acc: 0.8472\n",
      "492/492 [==============================] - 3s 5ms/step\n",
      "Results: 93.96% (0.93%)\n",
      "Epoch 1/1\n",
      "1974/1974 [==============================] - 59s 30ms/step - loss: 0.3582 - acc: 0.8409\n",
      "Epoch 1/1\n",
      "1974/1974 [==============================] - 60s 31ms/step - loss: 0.3786 - acc: 0.8354\n",
      "Epoch 1/1\n",
      "1974/1974 [==============================] - 60s 30ms/step - loss: 0.3632 - acc: 0.8404\n",
      "Epoch 1/1\n",
      "1974/1974 [==============================] - 52s 26ms/step - loss: 0.3621 - acc: 0.8445\n",
      "Epoch 1/1\n",
      "1976/1976 [==============================] - 46s 23ms/step - loss: 0.3801 - acc: 0.8360\n",
      "Epoch 1/5\n",
      "2468/2468 [==============================] - 52s 21ms/step - loss: 0.3331 - acc: 0.8590\n",
      "Epoch 2/5\n",
      "2468/2468 [==============================] - 47s 19ms/step - loss: 0.0841 - acc: 0.9777\n",
      "Epoch 3/5\n",
      "2468/2468 [==============================] - 47s 19ms/step - loss: 0.0581 - acc: 0.9830\n",
      "Epoch 4/5\n",
      "2468/2468 [==============================] - 47s 19ms/step - loss: 0.0404 - acc: 0.9866\n",
      "Epoch 5/5\n",
      "2468/2468 [==============================] - 47s 19ms/step - loss: 0.0466 - acc: 0.9874\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline #notebook을 실행한 브라우저에서 바로 그림을 볼 수 있게 해주는 것 \n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem, DataStructs\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#setting the seed for reproducibility\n",
    "#seed = 10110\n",
    "seed = 12061204\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "#load the dataset\n",
    "dataframe = pandas.read_csv(\"./pubchem_data/processed/input/BSK_CASM3C_IL6_down(Input).txt\", sep=\"\\t\")\n",
    "\n",
    "mols = []\n",
    "fps = []\n",
    "\n",
    "#get molecules and then get fingerprints from those\n",
    "for index, row in dataframe.iterrows():\n",
    "    mol = Chem.MolFromSmiles(row['Smiles'])\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2)\n",
    "    mols.append(mol)\n",
    "    fps.append(fp)\n",
    "\n",
    "#Convert the RDKit vectors into numpy arrays\n",
    "#Based on: http://www.rdkit.org/docs/Cookbook.html#using-scikit-learn-with-rdkit\n",
    "np_fps = []\n",
    "for fp in fps:\n",
    "    arr = numpy.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    np_fps.append(arr)\n",
    "\n",
    "np_fps_array = numpy.array(np_fps)\n",
    "\n",
    "#Need to encode my classes\n",
    "#Ligand = 0, not_ligand = 1\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(dataframe['Type'])\n",
    "enc_y = encoder.transform(dataframe['Type'])\n",
    "\n",
    "#Create the machine learning model\n",
    "\n",
    "def create_deep_learning_model():\n",
    "    model = Sequential()\n",
    "    #첫번째 인자 : 출력 뉴런의 수 , input_dim : 입력 뉴런의 수, activation : 활성화 함수.\n",
    "    model.add(Dense(2048, input_dim=2048, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "sm = SMOTE(random_state=12, ratio = 'minority')\n",
    "x_train_res, y_train_res = sm.fit_sample(np_fps_array, enc_y) #결과데이터\n",
    " \n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "#estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5, verbose=0)\n",
    "estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "#results = cross_val_score(estimator, np_fps_array, enc_y, cv=kfold)\n",
    "results = cross_val_score(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "y_pred = cross_val_predict(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "conf_mat = confusion_matrix(y_train_res, y_pred)\n",
    "conf_mat\n",
    "\n",
    "\n",
    "model = create_deep_learning_model()\n",
    "model.fit(x_train_res, y_train_res, epochs=5, batch_size=5)\n",
    "model.save('BSK_CASM3C_IL6_down(Input).h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-a56a1845bc94>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[0msm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mratio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'minority'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m \u001b[0mx_train_res\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_res\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp_fps_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menc_y\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#결과데이터\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36mfit_sample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     86\u001b[0m         \"\"\"\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36msample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfit_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\imblearn\\over_sampling\\smote.py\u001b[0m in \u001b[0;36m_sample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'regular'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 594\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sample_regular\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    595\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'borderline1'\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'borderline2'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sample_borderline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\imblearn\\over_sampling\\smote.py\u001b[0m in \u001b[0;36m_sample_regular\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn_k_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_class\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 360\u001b[1;33m             \u001b[0mnns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn_k_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    361\u001b[0m             X_new, y_new = self._make_samples(X_class, class_sample, X_class,\n\u001b[0;32m    362\u001b[0m                                               nns, n_samples, 1.0)\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\neighbors\\base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    345\u001b[0m                 \u001b[1;34m\"Expected n_neighbors <= n_samples, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    346\u001b[0m                 \u001b[1;34m\" but n_samples = %d, n_neighbors = %d\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 347\u001b[1;33m                 \u001b[1;33m(\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    348\u001b[0m             )\n\u001b[0;32m    349\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline #notebook을 실행한 브라우저에서 바로 그림을 볼 수 있게 해주는 것 \n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem, DataStructs\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#setting the seed for reproducibility\n",
    "#seed = 10110\n",
    "seed = 12061204\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "#load the dataset\n",
    "dataframe = pandas.read_csv(\"./pubchem_data/processed/input/BSK_BE3C_TGFb1_up(Input).txt\", sep=\"\\t\")\n",
    "\n",
    "mols = []\n",
    "fps = []\n",
    "\n",
    "#get molecules and then get fingerprints from those\n",
    "for index, row in dataframe.iterrows():\n",
    "    mol = Chem.MolFromSmiles(row['Smiles'])\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2)\n",
    "    mols.append(mol)\n",
    "    fps.append(fp)\n",
    "\n",
    "#Convert the RDKit vectors into numpy arrays\n",
    "#Based on: http://www.rdkit.org/docs/Cookbook.html#using-scikit-learn-with-rdkit\n",
    "np_fps = []\n",
    "for fp in fps:\n",
    "    arr = numpy.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    np_fps.append(arr)\n",
    "\n",
    "np_fps_array = numpy.array(np_fps)\n",
    "\n",
    "#Need to encode my classes\n",
    "#Ligand = 0, not_ligand = 1\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(dataframe['Type'])\n",
    "enc_y = encoder.transform(dataframe['Type'])\n",
    "\n",
    "#Create the machine learning model\n",
    "\n",
    "def create_deep_learning_model():\n",
    "    model = Sequential()\n",
    "    #첫번째 인자 : 출력 뉴런의 수 , input_dim : 입력 뉴런의 수, activation : 활성화 함수.\n",
    "    model.add(Dense(2048, input_dim=2048, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "sm = SMOTE(random_state=12, ratio = 'minority')\n",
    "x_train_res, y_train_res = sm.fit_sample(np_fps_array, enc_y) #결과데이터\n",
    " \n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "#estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5, verbose=0)\n",
    "estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "#results = cross_val_score(estimator, np_fps_array, enc_y, cv=kfold)\n",
    "results = cross_val_score(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "y_pred = cross_val_predict(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "conf_mat = confusion_matrix(y_train_res, y_pred)\n",
    "conf_mat\n",
    "\n",
    "\n",
    "model = create_deep_learning_model()\n",
    "model.fit(x_train_res, y_train_res, epochs=5, batch_size=5)\n",
    "model.save('BSK_BE3C_TGFb1_up(Input)_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1942/1942 [==============================] - 44s 23ms/step - loss: 0.4052 - acc: 0.8352\n",
      "486/486 [==============================] - 2s 4ms/step\n",
      "Epoch 1/1\n",
      "1942/1942 [==============================] - 45s 23ms/step - loss: 0.3961 - acc: 0.8337\n",
      "486/486 [==============================] - 2s 3ms/step\n",
      "Epoch 1/1\n",
      "1942/1942 [==============================] - 40s 21ms/step - loss: 0.4062 - acc: 0.8223\n",
      "486/486 [==============================] - 2s 4ms/step\n",
      "Epoch 1/1\n",
      "1942/1942 [==============================] - 41s 21ms/step - loss: 0.3952 - acc: 0.8265\n",
      "486/486 [==============================] - 2s 4ms/step\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 42s 22ms/step - loss: 0.4008 - acc: 0.8292\n",
      "484/484 [==============================] - 2s 5ms/step\n",
      "Results: 91.85% (1.80%)\n",
      "Epoch 1/1\n",
      "1942/1942 [==============================] - 40s 21ms/step - loss: 0.4249 - acc: 0.8090\n",
      "Epoch 1/1\n",
      "1942/1942 [==============================] - 41s 21ms/step - loss: 0.4080 - acc: 0.8229\n",
      "Epoch 1/1\n",
      "1942/1942 [==============================] - 40s 20ms/step - loss: 0.3975 - acc: 0.8275\n",
      "Epoch 1/1\n",
      "1942/1942 [==============================] - 40s 20ms/step - loss: 0.4087 - acc: 0.8126\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 51s 26ms/step - loss: 0.4040 - acc: 0.8230\n",
      "Epoch 1/5\n",
      "2428/2428 [==============================] - 53s 22ms/step - loss: 0.3538 - acc: 0.8439\n",
      "Epoch 2/5\n",
      "2428/2428 [==============================] - 47s 19ms/step - loss: 0.0953 - acc: 0.9699\n",
      "Epoch 3/5\n",
      "2428/2428 [==============================] - 53s 22ms/step - loss: 0.0581 - acc: 0.9815\n",
      "Epoch 4/5\n",
      "2428/2428 [==============================] - 55s 23ms/step - loss: 0.0422 - acc: 0.9860\n",
      "Epoch 5/5\n",
      "2428/2428 [==============================] - 58s 24ms/step - loss: 0.0497 - acc: 0.9811\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline #notebook을 실행한 브라우저에서 바로 그림을 볼 수 있게 해주는 것 \n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem, DataStructs\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#setting the seed for reproducibility\n",
    "#seed = 10110\n",
    "seed = 12061204\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "#load the dataset\n",
    "dataframe = pandas.read_csv(\"./pubchem_data/processed/input/BSK_BE3C_TGFb1_down(Input).txt\", sep=\"\\t\")\n",
    "\n",
    "mols = []\n",
    "fps = []\n",
    "\n",
    "#get molecules and then get fingerprints from those\n",
    "for index, row in dataframe.iterrows():\n",
    "    mol = Chem.MolFromSmiles(row['Smiles'])\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2)\n",
    "    mols.append(mol)\n",
    "    fps.append(fp)\n",
    "\n",
    "#Convert the RDKit vectors into numpy arrays\n",
    "#Based on: http://www.rdkit.org/docs/Cookbook.html#using-scikit-learn-with-rdkit\n",
    "np_fps = []\n",
    "for fp in fps:\n",
    "    arr = numpy.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    np_fps.append(arr)\n",
    "\n",
    "np_fps_array = numpy.array(np_fps)\n",
    "\n",
    "#Need to encode my classes\n",
    "#Ligand = 0, not_ligand = 1\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(dataframe['Type'])\n",
    "enc_y = encoder.transform(dataframe['Type'])\n",
    "\n",
    "#Create the machine learning model\n",
    "\n",
    "def create_deep_learning_model():\n",
    "    model = Sequential()\n",
    "    #첫번째 인자 : 출력 뉴런의 수 , input_dim : 입력 뉴런의 수, activation : 활성화 함수.\n",
    "    model.add(Dense(2048, input_dim=2048, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "sm = SMOTE(random_state=12, ratio = 'minority')\n",
    "x_train_res, y_train_res = sm.fit_sample(np_fps_array, enc_y) #결과데이터\n",
    " \n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "#estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5, verbose=0)\n",
    "estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "#results = cross_val_score(estimator, np_fps_array, enc_y, cv=kfold)\n",
    "results = cross_val_score(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "y_pred = cross_val_predict(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "conf_mat = confusion_matrix(y_train_res, y_pred)\n",
    "conf_mat\n",
    "\n",
    "\n",
    "model = create_deep_learning_model()\n",
    "model.fit(x_train_res, y_train_res, epochs=5, batch_size=5)\n",
    "model.save('BSK_BE3C_TGFb1_down(Input)_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2292/2292 [==============================] - 59s 26ms/step - loss: 0.0594 - acc: 0.9799\n",
      "574/574 [==============================] - 3s 6ms/step\n",
      "Epoch 1/1\n",
      "2292/2292 [==============================] - 59s 26ms/step - loss: 0.0495 - acc: 0.9812\n",
      "574/574 [==============================] - 3s 6ms/step\n",
      "Epoch 1/1\n",
      "2292/2292 [==============================] - 55s 24ms/step - loss: 0.0468 - acc: 0.9825\n",
      "574/574 [==============================] - 2s 3ms/step\n",
      "Epoch 1/1\n",
      "2294/2294 [==============================] - 47s 20ms/step - loss: 0.0593 - acc: 0.9804\n",
      "572/572 [==============================] - 2s 3ms/step\n",
      "Epoch 1/1\n",
      "2294/2294 [==============================] - 48s 21ms/step - loss: 0.0560 - acc: 0.9821\n",
      "572/572 [==============================] - 2s 4ms/step\n",
      "Results: 99.76% (0.18%)\n",
      "Epoch 1/1\n",
      "2292/2292 [==============================] - 47s 21ms/step - loss: 0.0620 - acc: 0.9799\n",
      "Epoch 1/1\n",
      "2292/2292 [==============================] - 47s 20ms/step - loss: 0.0569 - acc: 0.9812\n",
      "Epoch 1/1\n",
      "2292/2292 [==============================] - 47s 21ms/step - loss: 0.0608 - acc: 0.9760\n",
      "Epoch 1/1\n",
      "2294/2294 [==============================] - 47s 21ms/step - loss: 0.0603 - acc: 0.9760\n",
      "Epoch 1/1\n",
      "2294/2294 [==============================] - 47s 21ms/step - loss: 0.0746 - acc: 0.9686\n",
      "Epoch 1/5\n",
      "2866/2866 [==============================] - 61s 21ms/step - loss: 0.0487 - acc: 0.9878\n",
      "Epoch 2/5\n",
      "2866/2866 [==============================] - 60s 21ms/step - loss: 0.0199 - acc: 0.9965\n",
      "Epoch 3/5\n",
      "2866/2866 [==============================] - 59s 21ms/step - loss: 0.0018 - acc: 0.9993\n",
      "Epoch 4/5\n",
      "2866/2866 [==============================] - 59s 20ms/step - loss: 2.4323e-06 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "2866/2866 [==============================] - 59s 20ms/step - loss: 1.8000e-06 - acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline #notebook을 실행한 브라우저에서 바로 그림을 볼 수 있게 해주는 것 \n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem, DataStructs\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#setting the seed for reproducibility\n",
    "#seed = 10110\n",
    "seed = 12061204\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "#load the dataset\n",
    "dataframe = pandas.read_csv(\"./pubchem_data/processed/input/BSK_BE3C_IL1a_up(Input).txt\", sep=\"\\t\")\n",
    "\n",
    "mols = []\n",
    "fps = []\n",
    "\n",
    "#get molecules and then get fingerprints from those\n",
    "for index, row in dataframe.iterrows():\n",
    "    mol = Chem.MolFromSmiles(row['Smiles'])\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2)\n",
    "    mols.append(mol)\n",
    "    fps.append(fp)\n",
    "\n",
    "#Convert the RDKit vectors into numpy arrays\n",
    "#Based on: http://www.rdkit.org/docs/Cookbook.html#using-scikit-learn-with-rdkit\n",
    "np_fps = []\n",
    "for fp in fps:\n",
    "    arr = numpy.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    np_fps.append(arr)\n",
    "\n",
    "np_fps_array = numpy.array(np_fps)\n",
    "\n",
    "#Need to encode my classes\n",
    "#Ligand = 0, not_ligand = 1\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(dataframe['Type'])\n",
    "enc_y = encoder.transform(dataframe['Type'])\n",
    "\n",
    "#Create the machine learning model\n",
    "\n",
    "def create_deep_learning_model():\n",
    "    model = Sequential()\n",
    "    #첫번째 인자 : 출력 뉴런의 수 , input_dim : 입력 뉴런의 수, activation : 활성화 함수.\n",
    "    model.add(Dense(2048, input_dim=2048, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "sm = SMOTE(random_state=12, ratio = 'minority')\n",
    "x_train_res, y_train_res = sm.fit_sample(np_fps_array, enc_y) #결과데이터\n",
    " \n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "#estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5, verbose=0)\n",
    "estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "#results = cross_val_score(estimator, np_fps_array, enc_y, cv=kfold)\n",
    "results = cross_val_score(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "y_pred = cross_val_predict(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "conf_mat = confusion_matrix(y_train_res, y_pred)\n",
    "conf_mat\n",
    "\n",
    "\n",
    "model = create_deep_learning_model()\n",
    "model.fit(x_train_res, y_train_res, epochs=5, batch_size=5)\n",
    "model.save('BSK_BE3C_IL1a_up(Input)_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1876/1876 [==============================] - 42s 22ms/step - loss: 0.4711 - acc: 0.7623\n",
      "470/470 [==============================] - 2s 5ms/step\n",
      "Epoch 1/1\n",
      "1876/1876 [==============================] - 42s 23ms/step - loss: 0.4360 - acc: 0.8065\n",
      "470/470 [==============================] - 2s 4ms/step\n",
      "Epoch 1/1\n",
      "1876/1876 [==============================] - 42s 23ms/step - loss: 0.4493 - acc: 0.8017\n",
      "470/470 [==============================] - 2s 5ms/step\n",
      "Epoch 1/1\n",
      "1878/1878 [==============================] - 43s 23ms/step - loss: 0.4187 - acc: 0.8030\n",
      "468/468 [==============================] - 2s 5ms/step\n",
      "Epoch 1/1\n",
      "1878/1878 [==============================] - 43s 23ms/step - loss: 0.4434 - acc: 0.7881\n",
      "468/468 [==============================] - 2s 5ms/step\n",
      "Results: 91.30% (1.86%)\n",
      "Epoch 1/1\n",
      "1876/1876 [==============================] - 42s 23ms/step - loss: 0.4205 - acc: 0.8081\n",
      "Epoch 1/1\n",
      "1876/1876 [==============================] - 44s 23ms/step - loss: 0.4129 - acc: 0.8124\n",
      "Epoch 1/1\n",
      "1876/1876 [==============================] - 43s 23ms/step - loss: 0.4526 - acc: 0.7921\n",
      "Epoch 1/1\n",
      "1878/1878 [==============================] - 43s 23ms/step - loss: 0.4127 - acc: 0.8259\n",
      "Epoch 1/1\n",
      "1878/1878 [==============================] - 43s 23ms/step - loss: 0.4649 - acc: 0.7796\n",
      "Epoch 1/5\n",
      "2346/2346 [==============================] - 53s 22ms/step - loss: 0.3831 - acc: 0.8355\n",
      "Epoch 2/5\n",
      "2346/2346 [==============================] - 49s 21ms/step - loss: 0.1010 - acc: 0.9625\n",
      "Epoch 3/5\n",
      "2346/2346 [==============================] - 49s 21ms/step - loss: 0.0515 - acc: 0.9825\n",
      "Epoch 4/5\n",
      "2346/2346 [==============================] - 49s 21ms/step - loss: 0.0370 - acc: 0.9868\n",
      "Epoch 5/5\n",
      "2346/2346 [==============================] - 49s 21ms/step - loss: 0.0489 - acc: 0.9855\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline #notebook을 실행한 브라우저에서 바로 그림을 볼 수 있게 해주는 것 \n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem, DataStructs\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#setting the seed for reproducibility\n",
    "#seed = 10110\n",
    "seed = 12061204\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "#load the dataset\n",
    "dataframe = pandas.read_csv(\"./pubchem_data/processed/input/BSK_BE3C_IL1a_down(Input).txt\", sep=\"\\t\")\n",
    "\n",
    "mols = []\n",
    "fps = []\n",
    "\n",
    "#get molecules and then get fingerprints from those\n",
    "for index, row in dataframe.iterrows():\n",
    "    mol = Chem.MolFromSmiles(row['Smiles'])\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2)\n",
    "    mols.append(mol)\n",
    "    fps.append(fp)\n",
    "\n",
    "#Convert the RDKit vectors into numpy arrays\n",
    "#Based on: http://www.rdkit.org/docs/Cookbook.html#using-scikit-learn-with-rdkit\n",
    "np_fps = []\n",
    "for fp in fps:\n",
    "    arr = numpy.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    np_fps.append(arr)\n",
    "\n",
    "np_fps_array = numpy.array(np_fps)\n",
    "\n",
    "#Need to encode my classes\n",
    "#Ligand = 0, not_ligand = 1\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(dataframe['Type'])\n",
    "enc_y = encoder.transform(dataframe['Type'])\n",
    "\n",
    "#Create the machine learning model\n",
    "\n",
    "def create_deep_learning_model():\n",
    "    model = Sequential()\n",
    "    #첫번째 인자 : 출력 뉴런의 수 , input_dim : 입력 뉴런의 수, activation : 활성화 함수.\n",
    "    model.add(Dense(2048, input_dim=2048, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "sm = SMOTE(random_state=12, ratio = 'minority')\n",
    "x_train_res, y_train_res = sm.fit_sample(np_fps_array, enc_y) #결과데이터\n",
    " \n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "#estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5, verbose=0)\n",
    "estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "#results = cross_val_score(estimator, np_fps_array, enc_y, cv=kfold)\n",
    "results = cross_val_score(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "y_pred = cross_val_predict(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "conf_mat = confusion_matrix(y_train_res, y_pred)\n",
    "conf_mat\n",
    "\n",
    "\n",
    "model = create_deep_learning_model()\n",
    "model.fit(x_train_res, y_train_res, epochs=5, batch_size=5)\n",
    "model.save('BSK_BE3C_IL1a_down(Input)_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "5252/5252 [==============================] - 113s 21ms/step - loss: 0.1772 - acc: 0.9408\n",
      "1314/1314 [==============================] - 4s 3ms/step\n",
      "Epoch 1/1\n",
      "5252/5252 [==============================] - 113s 21ms/step - loss: 0.1643 - acc: 0.9375\n",
      "1314/1314 [==============================] - 4s 3ms/step\n",
      "Epoch 1/1\n",
      "5252/5252 [==============================] - 114s 22ms/step - loss: 0.1676 - acc: 0.9383\n",
      "1314/1314 [==============================] - 4s 3ms/step\n",
      "Epoch 1/1\n",
      "5254/5254 [==============================] - 138s 26ms/step - loss: 0.1737 - acc: 0.9319\n",
      "1312/1312 [==============================] - 5s 3ms/step\n",
      "Epoch 1/1\n",
      "5254/5254 [==============================] - 113s 22ms/step - loss: 0.1710 - acc: 0.9370\n",
      "1312/1312 [==============================] - 4s 3ms/step\n",
      "Results: 97.46% (0.99%)\n",
      "Epoch 1/1\n",
      "5252/5252 [==============================] - 116s 22ms/step - loss: 0.1780 - acc: 0.9375\n",
      "Epoch 1/1\n",
      "5252/5252 [==============================] - 149s 28ms/step - loss: 0.1582 - acc: 0.9393\n",
      "Epoch 1/1\n",
      "5252/5252 [==============================] - 117s 22ms/step - loss: 0.1638 - acc: 0.9427\n",
      "Epoch 1/1\n",
      "5254/5254 [==============================] - 124s 24ms/step - loss: 0.1560 - acc: 0.9444\n",
      "Epoch 1/1\n",
      "5254/5254 [==============================] - 126s 24ms/step - loss: 0.1625 - acc: 0.9360\n",
      "Epoch 1/5\n",
      "6566/6566 [==============================] - 145s 22ms/step - loss: 0.1505 - acc: 0.9467\n",
      "Epoch 2/5\n",
      "6566/6566 [==============================] - 136s 21ms/step - loss: 0.0531 - acc: 0.9863\n",
      "Epoch 3/5\n",
      "6566/6566 [==============================] - 136s 21ms/step - loss: 0.0367 - acc: 0.9899\n",
      "Epoch 4/5\n",
      "6566/6566 [==============================] - 135s 21ms/step - loss: 0.0280 - acc: 0.9928\n",
      "Epoch 5/5\n",
      "6566/6566 [==============================] - 134s 20ms/step - loss: 0.0274 - acc: 0.9938\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline #notebook을 실행한 브라우저에서 바로 그림을 볼 수 있게 해주는 것 \n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem, DataStructs\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#setting the seed for reproducibility\n",
    "#seed = 10110\n",
    "seed = 12061204\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "#load the dataset\n",
    "dataframe = pandas.read_csv(\"./pubchem_data/processed/input/ATG_TGFb_CIS_up(Input).txt\", sep=\"\\t\")\n",
    "\n",
    "mols = []\n",
    "fps = []\n",
    "\n",
    "#get molecules and then get fingerprints from those\n",
    "for index, row in dataframe.iterrows():\n",
    "    mol = Chem.MolFromSmiles(row['Smiles'])\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2)\n",
    "    mols.append(mol)\n",
    "    fps.append(fp)\n",
    "\n",
    "#Convert the RDKit vectors into numpy arrays\n",
    "#Based on: http://www.rdkit.org/docs/Cookbook.html#using-scikit-learn-with-rdkit\n",
    "np_fps = []\n",
    "for fp in fps:\n",
    "    arr = numpy.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    np_fps.append(arr)\n",
    "\n",
    "np_fps_array = numpy.array(np_fps)\n",
    "\n",
    "#Need to encode my classes\n",
    "#Ligand = 0, not_ligand = 1\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(dataframe['Type'])\n",
    "enc_y = encoder.transform(dataframe['Type'])\n",
    "\n",
    "#Create the machine learning model\n",
    "\n",
    "def create_deep_learning_model():\n",
    "    model = Sequential()\n",
    "    #첫번째 인자 : 출력 뉴런의 수 , input_dim : 입력 뉴런의 수, activation : 활성화 함수.\n",
    "    model.add(Dense(2048, input_dim=2048, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "sm = SMOTE(random_state=12, ratio = 'minority')\n",
    "x_train_res, y_train_res = sm.fit_sample(np_fps_array, enc_y) #결과데이터\n",
    " \n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "#estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5, verbose=0)\n",
    "estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "#results = cross_val_score(estimator, np_fps_array, enc_y, cv=kfold)\n",
    "results = cross_val_score(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "y_pred = cross_val_predict(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "conf_mat = confusion_matrix(y_train_res, y_pred)\n",
    "conf_mat\n",
    "\n",
    "\n",
    "model = create_deep_learning_model()\n",
    "model.fit(x_train_res, y_train_res, epochs=5, batch_size=5)\n",
    "model.save('ATG_TGFb_CIS_up(Input)_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "5274/5274 [==============================] - 112s 21ms/step - loss: 0.1686 - acc: 0.9378\n",
      "1320/1320 [==============================] - 5s 4ms/step\n",
      "Epoch 1/1\n",
      "5274/5274 [==============================] - 112s 21ms/step - loss: 0.1662 - acc: 0.9374\n",
      "1320/1320 [==============================] - 5s 3ms/step\n",
      "Epoch 1/1\n",
      "5276/5276 [==============================] - 112s 21ms/step - loss: 0.1823 - acc: 0.9318\n",
      "1318/1318 [==============================] - 5s 4ms/step\n",
      "Epoch 1/1\n",
      "5276/5276 [==============================] - 113s 21ms/step - loss: 0.1637 - acc: 0.9405\n",
      "1318/1318 [==============================] - 5s 4ms/step\n",
      "Epoch 1/1\n",
      "5276/5276 [==============================] - 116s 22ms/step - loss: 0.1764 - acc: 0.9329\n",
      "1318/1318 [==============================] - 5s 4ms/step\n",
      "Results: 97.47% (0.89%)\n",
      "Epoch 1/1\n",
      "5274/5274 [==============================] - 115s 22ms/step - loss: 0.1704 - acc: 0.9376\n",
      "Epoch 1/1\n",
      "5274/5274 [==============================] - 114s 22ms/step - loss: 0.1695 - acc: 0.9372\n",
      "Epoch 1/1\n",
      "5276/5276 [==============================] - 113s 21ms/step - loss: 0.1740 - acc: 0.9367\n",
      "Epoch 1/1\n",
      "5276/5276 [==============================] - 113s 22ms/step - loss: 0.1719 - acc: 0.9320\n",
      "Epoch 1/1\n",
      "5276/5276 [==============================] - 113s 21ms/step - loss: 0.1742 - acc: 0.9352\n",
      "Epoch 1/5\n",
      "6594/6594 [==============================] - 141s 21ms/step - loss: 0.1485 - acc: 0.9453\n",
      "Epoch 2/5\n",
      "6594/6594 [==============================] - 136s 21ms/step - loss: 0.0437 - acc: 0.9885\n",
      "Epoch 3/5\n",
      "6594/6594 [==============================] - 136s 21ms/step - loss: 0.0475 - acc: 0.9909\n",
      "Epoch 4/5\n",
      "6594/6594 [==============================] - 136s 21ms/step - loss: 0.0380 - acc: 0.9903\n",
      "Epoch 5/5\n",
      "6594/6594 [==============================] - 136s 21ms/step - loss: 0.0298 - acc: 0.9915\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline #notebook을 실행한 브라우저에서 바로 그림을 볼 수 있게 해주는 것 \n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem, DataStructs\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#setting the seed for reproducibility\n",
    "#seed = 10110\n",
    "seed = 12061204\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "#load the dataset\n",
    "dataframe = pandas.read_csv(\"./pubchem_data/processed/input/ATG_TGFb_CIS_dn(Input).txt\", sep=\"\\t\")\n",
    "\n",
    "mols = []\n",
    "fps = []\n",
    "\n",
    "#get molecules and then get fingerprints from those\n",
    "for index, row in dataframe.iterrows():\n",
    "    mol = Chem.MolFromSmiles(row['Smiles'])\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2)\n",
    "    mols.append(mol)\n",
    "    fps.append(fp)\n",
    "\n",
    "#Convert the RDKit vectors into numpy arrays\n",
    "#Based on: http://www.rdkit.org/docs/Cookbook.html#using-scikit-learn-with-rdkit\n",
    "np_fps = []\n",
    "for fp in fps:\n",
    "    arr = numpy.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    np_fps.append(arr)\n",
    "\n",
    "np_fps_array = numpy.array(np_fps)\n",
    "\n",
    "#Need to encode my classes\n",
    "#Ligand = 0, not_ligand = 1\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(dataframe['Type'])\n",
    "enc_y = encoder.transform(dataframe['Type'])\n",
    "\n",
    "#Create the machine learning model\n",
    "\n",
    "def create_deep_learning_model():\n",
    "    model = Sequential()\n",
    "    #첫번째 인자 : 출력 뉴런의 수 , input_dim : 입력 뉴런의 수, activation : 활성화 함수.\n",
    "    model.add(Dense(2048, input_dim=2048, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "sm = SMOTE(random_state=12, ratio = 'minority')\n",
    "x_train_res, y_train_res = sm.fit_sample(np_fps_array, enc_y) #결과데이터\n",
    " \n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "#estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5, verbose=0)\n",
    "estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "#results = cross_val_score(estimator, np_fps_array, enc_y, cv=kfold)\n",
    "results = cross_val_score(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "y_pred = cross_val_predict(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "conf_mat = confusion_matrix(y_train_res, y_pred)\n",
    "conf_mat\n",
    "\n",
    "\n",
    "model = create_deep_learning_model()\n",
    "model.fit(x_train_res, y_train_res, epochs=5, batch_size=5)\n",
    "model.save('ATG_TGFb_CIS_dn(Input)_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "3970/3970 [==============================] - 87s 22ms/step - loss: 0.5050 - acc: 0.7589\n",
      "994/994 [==============================] - 4s 4ms/step\n",
      "Epoch 1/1\n",
      "3970/3970 [==============================] - 87s 22ms/step - loss: 0.5043 - acc: 0.7599\n",
      "994/994 [==============================] - 4s 4ms/step\n",
      "Epoch 1/1\n",
      "3972/3972 [==============================] - 87s 22ms/step - loss: 0.5147 - acc: 0.7515 2s - lo\n",
      "992/992 [==============================] - 4s 4ms/step\n",
      "Epoch 1/1\n",
      "3972/3972 [==============================] - 87s 22ms/step - loss: 0.4997 - acc: 0.7666\n",
      "992/992 [==============================] - 4s 4ms/step\n",
      "Epoch 1/1\n",
      "3972/3972 [==============================] - 87s 22ms/step - loss: 0.4970 - acc: 0.7729\n",
      "992/992 [==============================] - 4s 4ms/step\n",
      "Results: 85.07% (0.87%)\n",
      "Epoch 1/1\n",
      "3970/3970 [==============================] - 87s 22ms/step - loss: 0.5008 - acc: 0.7645\n",
      "Epoch 1/1\n",
      "3970/3970 [==============================] - 87s 22ms/step - loss: 0.5081 - acc: 0.7584\n",
      "Epoch 1/1\n",
      "3972/3972 [==============================] - 87s 22ms/step - loss: 0.5079 - acc: 0.7651\n",
      "Epoch 1/1\n",
      "3972/3972 [==============================] - 87s 22ms/step - loss: 0.4992 - acc: 0.7669\n",
      "Epoch 1/1\n",
      "3972/3972 [==============================] - 93s 24ms/step - loss: 0.4988 - acc: 0.7676\n",
      "Epoch 1/5\n",
      "4964/4964 [==============================] - 112s 22ms/step - loss: 0.4747 - acc: 0.7814\n",
      "Epoch 2/5\n",
      "4964/4964 [==============================] - 103s 21ms/step - loss: 0.1945 - acc: 0.9301\n",
      "Epoch 3/5\n",
      "4964/4964 [==============================] - 103s 21ms/step - loss: 0.1126 - acc: 0.9605\n",
      "Epoch 4/5\n",
      "4964/4964 [==============================] - 103s 21ms/step - loss: 0.0778 - acc: 0.9736\n",
      "Epoch 5/5\n",
      "4964/4964 [==============================] - 103s 21ms/step - loss: 0.0609 - acc: 0.9744\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline #notebook을 실행한 브라우저에서 바로 그림을 볼 수 있게 해주는 것 \n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem, DataStructs\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#setting the seed for reproducibility\n",
    "#seed = 10110\n",
    "seed = 12061204\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "#load the dataset\n",
    "dataframe = pandas.read_csv(\"./pubchem_data/processed/input/ATG_PPARg_TRANS_up(Input).txt\", sep=\"\\t\")\n",
    "\n",
    "mols = []\n",
    "fps = []\n",
    "\n",
    "#get molecules and then get fingerprints from those\n",
    "for index, row in dataframe.iterrows():\n",
    "    mol = Chem.MolFromSmiles(row['Smiles'])\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2)\n",
    "    mols.append(mol)\n",
    "    fps.append(fp)\n",
    "\n",
    "#Convert the RDKit vectors into numpy arrays\n",
    "#Based on: http://www.rdkit.org/docs/Cookbook.html#using-scikit-learn-with-rdkit\n",
    "np_fps = []\n",
    "for fp in fps:\n",
    "    arr = numpy.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    np_fps.append(arr)\n",
    "\n",
    "np_fps_array = numpy.array(np_fps)\n",
    "\n",
    "#Need to encode my classes\n",
    "#Ligand = 0, not_ligand = 1\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(dataframe['Type'])\n",
    "enc_y = encoder.transform(dataframe['Type'])\n",
    "\n",
    "#Create the machine learning model\n",
    "\n",
    "def create_deep_learning_model():\n",
    "    model = Sequential()\n",
    "    #첫번째 인자 : 출력 뉴런의 수 , input_dim : 입력 뉴런의 수, activation : 활성화 함수.\n",
    "    model.add(Dense(2048, input_dim=2048, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "sm = SMOTE(random_state=12, ratio = 'minority')\n",
    "x_train_res, y_train_res = sm.fit_sample(np_fps_array, enc_y) #결과데이터\n",
    " \n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "#estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5, verbose=0)\n",
    "estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "#results = cross_val_score(estimator, np_fps_array, enc_y, cv=kfold)\n",
    "results = cross_val_score(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "y_pred = cross_val_predict(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "conf_mat = confusion_matrix(y_train_res, y_pred)\n",
    "conf_mat\n",
    "\n",
    "\n",
    "model = create_deep_learning_model()\n",
    "model.fit(x_train_res, y_train_res, epochs=5, batch_size=5)\n",
    "model.save('ATG_PPARg_TRANS_up(Input)_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "5248/5248 [==============================] - 112s 21ms/step - loss: 0.1513 - acc: 0.9476\n",
      "1312/1312 [==============================] - 3s 2ms/step\n",
      "Epoch 1/1\n",
      "5248/5248 [==============================] - 108s 21ms/step - loss: 0.1612 - acc: 0.9358\n",
      "1312/1312 [==============================] - 3s 2ms/step\n",
      "Epoch 1/1\n",
      "5248/5248 [==============================] - 112s 21ms/step - loss: 0.1535 - acc: 0.9413\n",
      "1312/1312 [==============================] - 2s 2ms/step\n",
      "Epoch 1/1\n",
      "5248/5248 [==============================] - 101s 19ms/step - loss: 0.1635 - acc: 0.9392\n",
      "1312/1312 [==============================] - 2s 2ms/step\n",
      "Epoch 1/1\n",
      "5248/5248 [==============================] - 105s 20ms/step - loss: 0.1523 - acc: 0.9451\n",
      "1312/1312 [==============================] - 2s 2ms/step\n",
      "Results: 98.09% (0.33%)\n",
      "Epoch 1/1\n",
      "5248/5248 [==============================] - 112s 21ms/step - loss: 0.1543 - acc: 0.9434\n",
      "Epoch 1/1\n",
      "5248/5248 [==============================] - 113s 22ms/step - loss: 0.1528 - acc: 0.9426\n",
      "Epoch 1/1\n",
      "5248/5248 [==============================] - 111s 21ms/step - loss: 0.1495 - acc: 0.9487\n",
      "Epoch 1/1\n",
      "5248/5248 [==============================] - 107s 20ms/step - loss: 0.1550 - acc: 0.9405\n",
      "Epoch 1/1\n",
      "5248/5248 [==============================] - 109s 21ms/step - loss: 0.1509 - acc: 0.9419\n",
      "Epoch 1/5\n",
      "6560/6560 [==============================] - 129s 20ms/step - loss: 0.1333 - acc: 0.9534\n",
      "Epoch 2/5\n",
      "6560/6560 [==============================] - 128s 20ms/step - loss: 0.0517 - acc: 0.9851\n",
      "Epoch 3/5\n",
      "6560/6560 [==============================] - 127s 19ms/step - loss: 0.0306 - acc: 0.9921\n",
      "Epoch 4/5\n",
      "6560/6560 [==============================] - 127s 19ms/step - loss: 0.0300 - acc: 0.9921\n",
      "Epoch 5/5\n",
      "6560/6560 [==============================] - 127s 19ms/step - loss: 0.0207 - acc: 0.9945\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline #notebook을 실행한 브라우저에서 바로 그림을 볼 수 있게 해주는 것 \n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem, DataStructs\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#setting the seed for reproducibility\n",
    "#seed = 10110\n",
    "seed = 12061204\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "#load the dataset\n",
    "dataframe = pandas.read_csv(\"./pubchem_data/processed/input/ATG_NF_kB_CIS_up(Input).txt\", sep=\"\\t\")\n",
    "\n",
    "mols = []\n",
    "fps = []\n",
    "\n",
    "#get molecules and then get fingerprints from those\n",
    "for index, row in dataframe.iterrows():\n",
    "    mol = Chem.MolFromSmiles(row['Smiles'])\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2)\n",
    "    mols.append(mol)\n",
    "    fps.append(fp)\n",
    "\n",
    "#Convert the RDKit vectors into numpy arrays\n",
    "#Based on: http://www.rdkit.org/docs/Cookbook.html#using-scikit-learn-with-rdkit\n",
    "np_fps = []\n",
    "for fp in fps:\n",
    "    arr = numpy.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    np_fps.append(arr)\n",
    "\n",
    "np_fps_array = numpy.array(np_fps)\n",
    "\n",
    "#Need to encode my classes\n",
    "#Ligand = 0, not_ligand = 1\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(dataframe['Type'])\n",
    "enc_y = encoder.transform(dataframe['Type'])\n",
    "\n",
    "#Create the machine learning model\n",
    "\n",
    "def create_deep_learning_model():\n",
    "    model = Sequential()\n",
    "    #첫번째 인자 : 출력 뉴런의 수 , input_dim : 입력 뉴런의 수, activation : 활성화 함수.\n",
    "    model.add(Dense(2048, input_dim=2048, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "sm = SMOTE(random_state=12, ratio = 'minority')\n",
    "x_train_res, y_train_res = sm.fit_sample(np_fps_array, enc_y) #결과데이터\n",
    " \n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "#estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5, verbose=0)\n",
    "estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "#results = cross_val_score(estimator, np_fps_array, enc_y, cv=kfold)\n",
    "results = cross_val_score(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "y_pred = cross_val_predict(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "conf_mat = confusion_matrix(y_train_res, y_pred)\n",
    "conf_mat\n",
    "\n",
    "\n",
    "model = create_deep_learning_model()\n",
    "model.fit(x_train_res, y_train_res, epochs=5, batch_size=5)\n",
    "model.save('ATG_NF_kB_CIS_up(Input)_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "5024/5024 [==============================] - 101s 20ms/step - loss: 0.2902 - acc: 0.8800\n",
      "1256/1256 [==============================] - 2s 2ms/step\n",
      "Epoch 1/1\n",
      "5024/5024 [==============================] - 103s 20ms/step - loss: 0.2828 - acc: 0.8897\n",
      "1256/1256 [==============================] - 2s 2ms/step\n",
      "Epoch 1/1\n",
      "5024/5024 [==============================] - 107s 21ms/step - loss: 0.2735 - acc: 0.8891\n",
      "1256/1256 [==============================] - 2s 2ms/step\n",
      "Epoch 1/1\n",
      "5024/5024 [==============================] - 103s 20ms/step - loss: 0.2613 - acc: 0.8929\n",
      "1256/1256 [==============================] - 2s 2ms/step\n",
      "Epoch 1/1\n",
      "5024/5024 [==============================] - 108s 22ms/step - loss: 0.2515 - acc: 0.8981\n",
      "1256/1256 [==============================] - 3s 2ms/step\n",
      "Results: 95.67% (0.80%)\n",
      "Epoch 1/1\n",
      "5024/5024 [==============================] - 109s 22ms/step - loss: 0.2820 - acc: 0.8865\n",
      "Epoch 1/1\n",
      "5024/5024 [==============================] - 97s 19ms/step - loss: 0.2677 - acc: 0.8925\n",
      "Epoch 1/1\n",
      "5024/5024 [==============================] - 98s 19ms/step - loss: 0.2711 - acc: 0.8891\n",
      "Epoch 1/1\n",
      "5024/5024 [==============================] - 105s 21ms/step - loss: 0.2758 - acc: 0.8854\n",
      "Epoch 1/1\n",
      "5024/5024 [==============================] - 103s 20ms/step - loss: 0.2769 - acc: 0.8913\n",
      "Epoch 1/5\n",
      "6280/6280 [==============================] - 133s 21ms/step - loss: 0.2418 - acc: 0.9068\n",
      "Epoch 2/5\n",
      "6280/6280 [==============================] - 125s 20ms/step - loss: 0.0606 - acc: 0.9796\n",
      "Epoch 3/5\n",
      "6280/6280 [==============================] - 131s 21ms/step - loss: 0.0449 - acc: 0.9868\n",
      "Epoch 4/5\n",
      "6280/6280 [==============================] - 134s 21ms/step - loss: 0.0399 - acc: 0.9855\n",
      "Epoch 5/5\n",
      "6280/6280 [==============================] - 142s 23ms/step - loss: 0.0331 - acc: 0.9893\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline #notebook을 실행한 브라우저에서 바로 그림을 볼 수 있게 해주는 것 \n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem, DataStructs\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#setting the seed for reproducibility\n",
    "#seed = 10110\n",
    "seed = 12061204\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "#load the dataset\n",
    "dataframe = pandas.read_csv(\"./pubchem_data/processed/input/ATG_NF_kB_CIS_dn(Input).txt\", sep=\"\\t\")\n",
    "\n",
    "mols = []\n",
    "fps = []\n",
    "\n",
    "#get molecules and then get fingerprints from those\n",
    "for index, row in dataframe.iterrows():\n",
    "    mol = Chem.MolFromSmiles(row['Smiles'])\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2)\n",
    "    mols.append(mol)\n",
    "    fps.append(fp)\n",
    "\n",
    "#Convert the RDKit vectors into numpy arrays\n",
    "#Based on: http://www.rdkit.org/docs/Cookbook.html#using-scikit-learn-with-rdkit\n",
    "np_fps = []\n",
    "for fp in fps:\n",
    "    arr = numpy.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    np_fps.append(arr)\n",
    "\n",
    "np_fps_array = numpy.array(np_fps)\n",
    "\n",
    "#Need to encode my classes\n",
    "#Ligand = 0, not_ligand = 1\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(dataframe['Type'])\n",
    "enc_y = encoder.transform(dataframe['Type'])\n",
    "\n",
    "#Create the machine learning model\n",
    "\n",
    "def create_deep_learning_model():\n",
    "    model = Sequential()\n",
    "    #첫번째 인자 : 출력 뉴런의 수 , input_dim : 입력 뉴런의 수, activation : 활성화 함수.\n",
    "    model.add(Dense(2048, input_dim=2048, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "sm = SMOTE(random_state=12, ratio = 'minority')\n",
    "x_train_res, y_train_res = sm.fit_sample(np_fps_array, enc_y) #결과데이터\n",
    " \n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "#estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5, verbose=0)\n",
    "estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "#results = cross_val_score(estimator, np_fps_array, enc_y, cv=kfold)\n",
    "results = cross_val_score(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "y_pred = cross_val_predict(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "conf_mat = confusion_matrix(y_train_res, y_pred)\n",
    "conf_mat\n",
    "\n",
    "\n",
    "model = create_deep_learning_model()\n",
    "model.fit(x_train_res, y_train_res, epochs=5, batch_size=5)\n",
    "model.save('ATG_NF_kB_CIS_dn(Input)_model.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
