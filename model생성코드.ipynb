{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-c10723d6be6c>, line 58)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-c10723d6be6c>\"\u001b[1;36m, line \u001b[1;32m58\u001b[0m\n\u001b[1;33m    dataframe = pandas.read_csv('C:\\/test/Deepchem toxcast_data all/Seperated/'+input_name)\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline #notebook을 실행한 브라우저에서 바로 그림을 볼 수 있게 해주는 것 \n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem, DataStructs\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#setting the seed for reproducibility\n",
    "#seed = 10110\n",
    "seed = 12061204\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "#get list of files\n",
    "import os\n",
    "path_dir = 'C:\\/test/Deepchem toxcast_data all/Seperated'\n",
    "file_list = os.listdir(path_dir)\n",
    "input_files = []\n",
    "i = 0\n",
    "\n",
    "for item in file_list :\n",
    "        input_files.append(item)\n",
    "        #print(item)\n",
    "        \n",
    "for a in input_files :\n",
    "    print(a)\n",
    "    \n",
    "def create_deep_learning_model():\n",
    "    model = Sequential()\n",
    "    #첫번째 인자 : 출력 뉴런의 수 , input_dim : 입력 뉴런의 수, activation : 활성화 함수.\n",
    "    model.add(Dense(2048, input_dim=2048, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model    \n",
    "    \n",
    "#load the dataset\n",
    "def main(input_name):{\n",
    "dataframe = pandas.read_csv('C:\\/test/Deepchem toxcast_data all/Seperated/'+input_name)\n",
    "mols = []\n",
    "fps = []\n",
    "\n",
    "#get molecules and then get fingerprints from those\n",
    "for index, row in dataframe.iterrows():\n",
    "    mol = Chem.MolFromSmiles(row['Smiles'])\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2)\n",
    "    mols.append(mol)\n",
    "    fps.append(fp)\n",
    "\n",
    "#Convert the RDKit vectors into numpy arrays\n",
    "#Based on: http://www.rdkit.org/docs/Cookbook.html#using-scikit-learn-with-rdkit\n",
    "np_fps = []\n",
    "for fp in fps:\n",
    "    arr = numpy.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    np_fps.append(arr)\n",
    "\n",
    "np_fps_array = numpy.array(np_fps)\n",
    "\n",
    "#Need to encode my classes\n",
    "#Ligand = 0, not_ligand = 1\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(dataframe['Type'])\n",
    "enc_y = encoder.transform(dataframe['Type'])\n",
    "\n",
    "#Create the machine learning model\n",
    "\n",
    "sm = SMOTE(random_state=12, ratio = 'minority')\n",
    "x_train_res, y_train_res = sm.fit_sample(np_fps_array, enc_y) #결과데이터\n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "#estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5, verbose=0)\n",
    "estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "#results = cross_val_score(estimator, np_fps_array, enc_y, cv=kfold)\n",
    "results = cross_val_score(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "#https://datascienceschool.net/view-notebook/266d699d748847b3a3aa7b9805b846ae/\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "y_pred = cross_val_predict(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "conf_mat = confusion_matrix(y_train_res, y_pred)\n",
    "conf_mat\n",
    "\n",
    "\n",
    "model = create_deep_learning_model()\n",
    "model.fit(x_train_res, y_train_res, epochs=5, batch_size=5)\n",
    "model.save(\"C:\\/test/ppar-gamma-model/trained_models/models_2\"+input_name+'_model.h5')\n",
    "}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for input_name in input_files :\n",
    "        main(input_name)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of      Unnamed: 0                                             SMILES  Type\n",
      "0             1                     NC1=C(Cl)C(Cl)=NC(C(O)=O)=C1Cl     0\n",
      "1            12                  CCCCOCCOCCOCC1=CC2=C(OCO2)C=C1CCC     0\n",
      "2            73                CC(C)(C1=CC=C(O)C=C1)C1=CC=C(O)C=C1     0\n",
      "3           154              ClC(Cl)C(Cl)(Cl)SN1C(=O)C2CC=CCC2C1=O     1\n",
      "4           271  [Mn++].[Zn++].[S-]C(=S)NCCNC([S-])=S.[S-]C(=S)...     0\n",
      "5           318                                             OB(O)O     0\n",
      "6           343                              CCNC1=NC(N)=NC(Cl)=N1     0\n",
      "7           347  COC(=O)C1=C(N(C)N=C1Cl)S(=O)(=O)NC(=O)NC1=NC(O...     0\n",
      "8           364                  ClC1=CC=CC=C1NC1=NC(Cl)=NC(Cl)=N1     0\n",
      "9           366                         CC(OC1=CC(Cl)=CC=C1)C(O)=O     0\n",
      "10          372  COC(=O)C1=CC=CC=C1S(=O)(=O)NC(=O)N(C)C1=NC(OC)...     0\n",
      "11          374                        CC(C)OC(=O)NC1=CC=CC(Cl)=C1     0\n",
      "12          455                                       COP(N)(=O)SC     0\n",
      "13          502  FC1=CC2=C(C=C1N1C(=O)C3=C(CCCC3)C1=O)N(CC#C)C(...     0\n",
      "14          566           CC(C)C1(C)NC(=NC1=O)C1=NC=C(C)C=C1C(O)=O     0\n",
      "15          576  CS(=O)(=O)C1=CC(=C(C=C1)C(=O)C1C(=O)CCCC1=O)[N...     0\n",
      "16          597   CC(C)=CC1C(C(=O)OCC2=COC(CC3=CC=CC=C3)=C2)C1(C)C     0\n",
      "17          649  C[C@@H](OC1=CC=C(OC2=NC=C(Cl)C=C2F)C=C1)C(=O)O...     0\n",
      "18          914                                              COCCO     0\n",
      "19          951  COC1=C(OC)C=C(C=C1)C(=CC(=O)N1CCOCC1)C1=CC=C(C...     0\n",
      "20         1046  CN1N=C(C)C(C=NOCC2=CC=C(C=C2)C(=O)OC(C)(C)C)=C...     1\n",
      "21         1070                     ClC1=CC=C(CN2CCS\\C2=N/C#N)C=N1     0\n",
      "22         1103     FC(F)C(F)(F)OCC(CN1C=NC=N1)C1=C(Cl)C=C(Cl)C=C1     1\n",
      "23         1120  CCC1=CC=C(C=C1)C(=O)NN(C(=O)C1=CC(C)=CC(C)=C1)...     0\n",
      "24         1166               OC(=O)C1(CC1)C(=O)NC1=CC=C(Cl)C=C1Cl     1\n",
      "25         1172                              CCSC(=O)N(CC)C1CCCCC1     0\n",
      "26         1175                CCCCC(CC)CN1C(=O)C2C3CC(C=C3)C2C1=O     0\n",
      "27         1186  CCOC(=O)[C@H](C)OC1=CC=C(OC2=NC3=C(O2)C=C(Cl)C...     0\n",
      "28         1195                          CNC(=O)OC1=CC=CC=C1OC(C)C     0\n",
      "29         1196     COCC1=CN=C(C2=NC(C)(C(C)C)C(=O)N2)C(=C1)C(O)=O     0\n",
      "..          ...                                                ...   ...\n",
      "276        7700    CC(C)(C)C(O)C(=C/C1=C(Cl)C=C(Cl)C=C1)\\N1C=NC=N1     0\n",
      "277        7706  COC1=CC2=C(C=C1OC)[C@H]1[C@@H](CO2)OC2=C(C=CC3...     1\n",
      "278        7719                  OC(=O)C1=C(Cl)C=CC2=CC(Cl)=CN=C12     0\n",
      "279        7756                    CCCCOC(=O)C1=CC=CC=C1C(=O)OCCCC     0\n",
      "280        7789    C[Si](CN1C=NC=N1)(C1=CC=C(F)C=C1)C1=CC=C(F)C=C1     1\n",
      "281        7814  COC(=O)C1=C(C=CC=C1)S(=O)(=O)NC(=O)NC1=NC(OC(F...     0\n",
      "282        7830                COP(=S)(OC)SCN1N=NC2=C(C=CC=C2)C1=O     0\n",
      "283        7888  CCCCCOC(=O)COC1=C(Cl)C=C(F)C(=C1)N1C(=O)C2=C(C...     0\n",
      "284        7896                    COCC(C)N(C(=O)CCl)C1=C(C)SC=C1C     1\n",
      "285        7905       CCON=C(CC)C1=C(O)CC(CC1=O)C1=C(C)C=C(C)C=C1C     0\n",
      "286        7911                       ClN1C(=O)N(Cl)C(=O)N(Cl)C1=O     0\n",
      "287        7952              CCCCC(CN1C=NC=N1)(C#N)C1=CC=C(Cl)C=C1     0\n",
      "288        8034                          OC1=C(C=CC=C1)C1=CC=CC=C1     1\n",
      "289        8215  COC1=NC(C)=NC(NC(=O)NS(=O)(=O)C2=C(CCC(F)(F)F)...     0\n",
      "290        8231           CC(C1CC1)C(O)(CN1C=NC=N1)C1=CC=C(Cl)C=C1     0\n",
      "291        8251                         CC1=C(OCC(O)=O)C=CC(Cl)=C1     0\n",
      "292        8254                        OC(=O)COC1=C(Cl)C=C(Cl)C=C1     0\n",
      "293        8257                        OC(=O)CCCOC1=CC=C(Cl)C=C1Cl     0\n",
      "294        8265                      COC1=NN(CSP(=S)(OC)OC)C(=O)S1     0\n",
      "295        8301        CC(COC1=CC=C(OC2=CC=CC=C2)C=C1)OC1=NC=CC=C1     0\n",
      "296        8331             CCOP(=S)(OC(C)C)OC1=CN=C(N=C1)C(C)(C)C     0\n",
      "297        8336                CCOP(=O)(OCC)OC1=NC(=NC(C)=C1)C(C)C     0\n",
      "298        8346                                          S=C1NCCN1     0\n",
      "299        8349  CC(C)(C)N1N=CC(SCC2=CC=C(C=C2)C(C)(C)C)=C(Cl)C1=O     1\n",
      "300        8408  CCOC1=NC(NC)=NC(NC(=O)NS(=O)(=O)C2=C(C=CC=C2)C...     0\n",
      "301        8413  CSC(=O)C1=C(N=C(C(C(=O)SC)=C1CC(C)C)C(F)(F)F)C...     1\n",
      "302        8464                         CCOP(=O)(SC(C)CC)N1CCSC1=O     0\n",
      "303        8474      CC1=NC2=NC(=NN2C=C1)S(=O)(=O)NC1=C(F)C=CC=C1F     0\n",
      "304        8484                   NC1=C(Cl)C=C(C=C1Cl)[N+]([O-])=O     0\n",
      "305        8531  [Br-].[Br-].[2H]C1([2H])[N+]2=C(C=CC=C2)C2=[N+...     0\n",
      "\n",
      "[306 rows x 3 columns]>\n",
      "Epoch 1/1\n",
      "410/418 [============================>.] - ETA: 0s - loss: 0.3463 - acc: 0.8634"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-8729c344fc97>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;31m#     for input_name in input_files :\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m         \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'APR_Hepat_Apoptosis_24hr_up(input).csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-8729c344fc97>\u001b[0m in \u001b[0;36mmain\u001b[1;34m(input_name)\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[0mkfold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;31m#results = cross_val_score(estimator, np_fps_array, enc_y, cv=kfold)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train_res\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_res\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkfold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m     \u001b[1;31m#https://datascienceschool.net/view-notebook/266d699d748847b3a3aa7b9805b846ae/\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Results: %.2f%% (%.2f%%)\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[0;32m    340\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                                 pre_dispatch=pre_dispatch)\n\u001b[0m\u001b[0;32m    343\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score)\u001b[0m\n\u001b[0;32m    204\u001b[0m             \u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_train_score\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m             return_times=True)\n\u001b[1;32m--> 206\u001b[1;33m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    623\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[0;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\keras-2.2.2-py3.6.egg\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sample_weight'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 210\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\keras-2.2.2-py3.6.egg\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    150\u001b[0m         \u001b[0mfit_args\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m         \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\keras-2.2.2-py3.6.egg\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1043\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1044\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1045\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1046\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1047\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\keras-2.2.2-py3.6.egg\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\keras-2.2.2-py3.6.egg\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2655\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2657\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2658\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2659\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\keras-2.2.2-py3.6.egg\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2625\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2626\u001b[0m                                 session)\n\u001b[1;32m-> 2627\u001b[1;33m         \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2628\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2629\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1382\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# %matplotlib inline #notebook을 실행한 브라우저에서 바로 그림을 볼 수 있게 해주는 것 \n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem, DataStructs\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#setting the seed for reproducibility\n",
    "#seed = 10110\n",
    "seed = 12061204\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "#폴더의 파일목록 불러오기\n",
    "import os\n",
    "path_dir = 'C:\\/test/Deepchem toxcast_data all/Seperated'\n",
    "file_list = os.listdir(path_dir)\n",
    "input_files = []\n",
    "i = 0\n",
    "\n",
    "for item in file_list :\n",
    "        input_files.append(item)\n",
    "        #print(item)\n",
    "        \n",
    "def create_deep_learning_model():\n",
    "    model = Sequential()\n",
    "    #첫번째 인자 : 출력 뉴런의 수 , input_dim : 입력 뉴런의 수, activation : 활성화 함수.\n",
    "    model.add(Dense(2048, input_dim=2048, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model    \n",
    "\n",
    "def main(input_name):\n",
    "    dataframe = pandas.read_csv('C:\\/test/Deepchem toxcast_data all/Seperated/'+input_name)\n",
    "    print(dataframe.head)\n",
    "    mols = []\n",
    "    fps = []\n",
    "    \n",
    "    for index, row in dataframe.iterrows():\n",
    "        mol = Chem.MolFromSmiles(row['SMILES'])\n",
    "        fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2)\n",
    "        mols.append(mol)\n",
    "        fps.append(fp)\n",
    "    \n",
    "    np_fps = []\n",
    "    for fp in fps:\n",
    "        arr = numpy.zeros((1,))\n",
    "        DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "        np_fps.append(arr)\n",
    "        \n",
    "    np_fps_array = numpy.array(np_fps)\n",
    "    \n",
    "#     my_string = input_name\n",
    "#     Type = my_string.split('(')[0]\n",
    "    enc_y = dataframe['Type']\n",
    "    \n",
    "    sm = SMOTE(random_state=12, ratio = 'minority')\n",
    "    x_train_res, y_train_res = sm.fit_sample(np_fps_array, enc_y) #결과데이터\n",
    "\n",
    "    # evaluate model with standardized dataset\n",
    "    #estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5, verbose=0)\n",
    "    estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5)\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "    #results = cross_val_score(estimator, np_fps_array, enc_y, cv=kfold)\n",
    "    results = cross_val_score(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "    #https://datascienceschool.net/view-notebook/266d699d748847b3a3aa7b9805b846ae/\n",
    "    print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "    y_pred = cross_val_predict(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "    conf_mat = confusion_matrix(y_train_res, y_pred)\n",
    "    conf_mat\n",
    "\n",
    "\n",
    "    model = create_deep_learning_model()\n",
    "    hist = model.fit(x_train_res, y_train_res, epochs=5, batch_size=5)\n",
    "    model.save(\"C:\\/test/ppar-gamma-model/trained_models/models_2/\"+input_name+'_model' + '(' + hist.history['acc'][-1] + ')'+'.h5')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "#     for input_name in input_files :\n",
    "        main('APR_Hepat_Apoptosis_24hr_up(input).csv')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_to_dot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-31b9e58c5de1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pparg_ligand_model.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mSVG\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_to_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'dot'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'svg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model_to_dot' is not defined"
     ]
    }
   ],
   "source": [
    "#모델 가시화--> 아키텍처보기\n",
    "from IPython.display import SVG\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "model = load_model('pparg_ligand_model.h5') \n",
    "\n",
    "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Type'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3077\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3078\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3079\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Type'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-e91d73a39dbf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[0mencoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m \u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Type'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[0menc_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Type'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2686\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2687\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2688\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2690\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2693\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2694\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2695\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2696\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2697\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   2487\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2488\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2489\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2490\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2491\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, item, fastpath)\u001b[0m\n\u001b[0;32m   4113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4114\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4115\u001b[1;33m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4116\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4117\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3078\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3080\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3081\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3082\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Type'"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem, DataStructs\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "import numpy as np\n",
    "from numpy import argmax\n",
    "\n",
    "\n",
    "# 1. 크노엘 데이터의 simled을 fingerfint로 바꾼다.\n",
    "dataframe = pandas.read_csv(\"./pubchem_data/processed/testdata.txt\", sep=\"\\t\")\n",
    "\n",
    "mols = []\n",
    "fps = []\n",
    "\n",
    "#get molecules and then get fingerprints from those\n",
    "for index, row in dataframe.iterrows(): #가져온 데이터를 이용하여 반복문 돌린다.\n",
    "    mol = Chem.MolFromSmiles(row['SMILES']) #http://www.rdkit.org/Python_Docs/rdkit.Chem.rdmolfiles-module.html#MolFromSmiles\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2) #https://rdkit.org/docs/api/rdkit.Chem.rdMolDescriptors-module.html#GetMorganFingerprint\n",
    "    mols.append(mol)\n",
    "    fps.append(fp)\n",
    "\n",
    "#Convert the RDKit vectors into numpy arrays\n",
    "#Based on: http://www.rdkit.org/docs/Cookbook.html#using-scikit-learn-with-rdkit\n",
    "np_fps = []\n",
    "for fp in fps:\n",
    "    arr = numpy.zeros((1,))#크기가 정해져 있고 모든 값이 0인 배열을 생성하려면 zeros 명령을 사용한다. 인수로는 배열을 크기를 뜻하는 정수를 넣는다.\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    np_fps.append(arr)\n",
    "\n",
    "np_fps_array = numpy.array(np_fps)# numpy의 array라는 함수에 리스트를 넣으면 배열로 변환 해 준다.\n",
    "#https://datascienceschool.net/view-notebook/35099ac4aea146c69cc4b3f50aec736f/ 넘파이 배열.\n",
    "\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(dataframe['Type'])\n",
    "enc_y = encoder.transform(dataframe['Type'])\n",
    "\n",
    "# 2. 모델 불러오기\n",
    "from keras.models import load_model\n",
    "model = load_model('pparg_ligand_model.h5') \n",
    "\n",
    "# 3. 모델 사용하기\n",
    "sm = SMOTE(random_state=12, ratio = 'minority')\n",
    "x_train_res, y_train_res = sm.fit_sample(np_fps_array, enc_y)\n",
    "\n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "estimator = KerasClassifier(build_fn=model, nb_epoch=100, batch_size=5, verbose=0)\n",
    "#batch_size =5이니 5개씩 쪼갠다.\n",
    "#estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(estimator, np_fps_array, enc_y, cv=kfold)\n",
    "#results = cross_val_score(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "y_pred = cross_val_predict(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "conf_mat = confusion_matrix(y_train_res, y_pred)\n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/test/Deepchem toxcast_data all/Seperated/ACEA_T47D_80hr_Negative(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ACEA_T47D_80hr_Positive(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/APR_Hepat_Apoptosis_24hr_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/APR_Hepat_Apoptosis_48hr_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/APR_Hepat_CellLoss_24hr_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/APR_Hepat_CellLoss_48hr_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/APR_Hepat_DNADamage_24hr_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/APR_Hepat_DNADamage_48hr_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/APR_Hepat_DNATexture_24hr_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/APR_Hepat_DNATexture_48hr_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/APR_Hepat_MitoFxnI_1hr_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/APR_Hepat_MitoFxnI_24hr_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/APR_Hepat_MitoFxnI_48hr_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/APR_Hepat_NuclearSize_24hr_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/APR_Hepat_NuclearSize_48hr_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/APR_Hepat_Steatosis_24hr_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/APR_Hepat_Steatosis_48hr_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/APR_HepG2_CellCycleArrest_24h_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/APR_HepG2_CellCycleArrest_24h_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/APR_HepG2_CellCycleArrest_72h_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/APR_HepG2_CellLoss_24h_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/APR_HepG2_CellLoss_72h_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/APR_HepG2_MicrotubuleCSK_24h_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/APR_HepG2_MicrotubuleCSK_24h_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/APR_HepG2_MicrotubuleCSK_72h_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/APR_HepG2_MicrotubuleCSK_72h_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/APR_HepG2_MitoMass_24h_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/APR_HepG2_MitoMass_24h_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/APR_HepG2_MitoMass_72h_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/APR_HepG2_MitoMass_72h_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/APR_HepG2_MitoMembPot_1h_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/APR_HepG2_MitoMembPot_24h_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/APR_HepG2_MitoMembPot_72h_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/APR_HepG2_MitoticArrest_24h_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/APR_HepG2_MitoticArrest_72h_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/APR_HepG2_NuclearSize_24h_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/APR_HepG2_NuclearSize_72h_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/APR_HepG2_NuclearSize_72h_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/APR_HepG2_OxidativeStress_24h_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/APR_HepG2_OxidativeStress_72h_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/APR_HepG2_p53Act_24h_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/APR_HepG2_p53Act_72h_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/APR_HepG2_StressKinase_1h_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/APR_HepG2_StressKinase_24h_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/APR_HepG2_StressKinase_72h_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_Ahr_CIS_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_Ahr_CIS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_AP_1_CIS_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_AP_1_CIS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_AP_2_CIS_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_AP_2_CIS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_AR_TRANS_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_AR_TRANS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_BRE_CIS_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_BRE_CIS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_CAR_TRANS_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_CAR_TRANS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_CMV_CIS_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_CMV_CIS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_CRE_CIS_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_CRE_CIS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_C_EBP_CIS_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_C_EBP_CIS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_DR4_LXR_CIS_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_DR4_LXR_CIS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_DR5_CIS_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_DR5_CIS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_E2F_CIS_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_E2F_CIS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_EGR_CIS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_ERa_TRANS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_ERE_CIS_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_ERE_CIS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_ERRa_TRANS_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_ERRg_TRANS_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_ERRg_TRANS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_Ets_CIS_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_Ets_CIS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_E_Box_CIS_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_E_Box_CIS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_FoxA2_CIS_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_FoxA2_CIS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_FoxO_CIS_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_FoxO_CIS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_FXR_TRANS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_GAL4_TRANS_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_GATA_CIS_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_GATA_CIS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_GLI_CIS_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_GLI_CIS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_GRE_CIS_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_GRE_CIS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_GR_TRANS_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_GR_TRANS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_HIF1a_CIS_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_HIF1a_CIS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_HNF4a_TRANS_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_HNF4a_TRANS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_HNF6_CIS_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_HNF6_CIS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_HSE_CIS_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_HSE_CIS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_IR1_CIS_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_IR1_CIS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_ISRE_CIS_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_ISRE_CIS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_LXRa_TRANS_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_LXRa_TRANS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_LXRb_TRANS_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_LXRb_TRANS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_MRE_CIS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_Myb_CIS_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_Myb_CIS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_Myc_CIS_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_Myc_CIS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_M_06_TRANS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_M_19_CIS_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_M_19_TRANS_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_M_19_TRANS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_M_32_CIS_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_M_32_CIS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_M_32_TRANS_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_M_32_TRANS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_M_61_TRANS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_NFI_CIS_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_NFI_CIS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_NF_kB_CIS_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_NF_kB_CIS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_NRF1_CIS_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_NRF1_CIS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_NRF2_ARE_CIS_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_NRF2_ARE_CIS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_NURR1_TRANS_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_NURR1_TRANS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_Oct_MLP_CIS_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_Oct_MLP_CIS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_p53_CIS_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_p53_CIS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_Pax6_CIS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_PBREM_CIS_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_PBREM_CIS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_PPARa_TRANS_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_PPARa_TRANS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_PPARd_TRANS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_PPARg_TRANS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_PPRE_CIS_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_PPRE_CIS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_PXRE_CIS_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_PXRE_CIS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_PXR_TRANS_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_PXR_TRANS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_RARa_TRANS_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_RARa_TRANS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_RARb_TRANS_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_RARb_TRANS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_RARg_TRANS_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_RARg_TRANS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_RORb_TRANS_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_RORE_CIS_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_RORE_CIS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_RORg_TRANS_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_RORg_TRANS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_RXRa_TRANS_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_RXRa_TRANS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_RXRb_TRANS_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_RXRb_TRANS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_Sox_CIS_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_Sox_CIS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_Sp1_CIS_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_Sp1_CIS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_SREBP_CIS_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_SREBP_CIS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_STAT3_CIS_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_STAT3_CIS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_TAL_CIS_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_TAL_CIS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_TA_CIS_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_TA_CIS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_TCF_b_cat_CIS_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_TCF_b_cat_CIS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_TGFb_CIS_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_TGFb_CIS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_THRa1_TRANS_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_THRa1_TRANS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_VDRE_CIS_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_VDRE_CIS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_VDR_TRANS_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_VDR_TRANS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_Xbp1_CIS_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_Xbp1_CIS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/ATG_XTT_Cytotoxicity_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_3C_Eselectin_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_3C_HLADR_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_3C_ICAM1_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_3C_IL8_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_3C_MCP1_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_3C_MIG_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_3C_Proliferation_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_3C_SRB_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_3C_Thrombomodulin_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_3C_Thrombomodulin_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_3C_TissueFactor_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_3C_TissueFactor_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_3C_uPAR_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_3C_VCAM1_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_3C_Vis_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_4H_Eotaxin3_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_4H_MCP1_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_4H_Pselectin_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_4H_Pselectin_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_4H_SRB_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_4H_uPAR_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_4H_uPAR_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_4H_VCAM1_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_4H_VEGFRII_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_BE3C_HLADR_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_BE3C_IL1a_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_BE3C_IP10_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_BE3C_MIG_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_BE3C_MMP1_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_BE3C_MMP1_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_BE3C_PAI1_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_BE3C_SRB_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_BE3C_TGFb1_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_BE3C_tPA_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_BE3C_uPAR_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_BE3C_uPAR_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_BE3C_uPA_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_CASM3C_HLADR_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_CASM3C_IL6_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_CASM3C_IL6_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_CASM3C_IL8_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_CASM3C_LDLR_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_CASM3C_LDLR_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_CASM3C_MCP1_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_CASM3C_MCP1_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_CASM3C_MCSF_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_CASM3C_MCSF_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_CASM3C_MIG_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_CASM3C_Proliferation_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_CASM3C_Proliferation_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_CASM3C_SAA_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_CASM3C_SAA_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_CASM3C_SRB_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_CASM3C_Thrombomodulin_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_CASM3C_Thrombomodulin_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_CASM3C_TissueFactor_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_CASM3C_uPAR_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_CASM3C_uPAR_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_CASM3C_VCAM1_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_CASM3C_VCAM1_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_hDFCGF_CollagenIII_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_hDFCGF_EGFR_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_hDFCGF_EGFR_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_hDFCGF_IL8_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_hDFCGF_IP10_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_hDFCGF_MCSF_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_hDFCGF_MIG_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_hDFCGF_MMP1_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_hDFCGF_MMP1_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_hDFCGF_PAI1_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_hDFCGF_Proliferation_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_hDFCGF_SRB_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_hDFCGF_TIMP1_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_hDFCGF_VCAM1_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_KF3CT_ICAM1_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_KF3CT_IL1a_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_KF3CT_IP10_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_KF3CT_IP10_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_KF3CT_MCP1_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_KF3CT_MCP1_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_KF3CT_MMP9_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_KF3CT_SRB_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_KF3CT_TGFb1_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_KF3CT_TIMP2_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_KF3CT_uPA_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_LPS_CD40_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_LPS_Eselectin_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_LPS_Eselectin_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_LPS_IL1a_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_LPS_IL1a_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_LPS_IL8_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_LPS_IL8_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_LPS_MCP1_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_LPS_MCSF_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_LPS_PGE2_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_LPS_PGE2_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_LPS_SRB_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_LPS_TissueFactor_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_LPS_TissueFactor_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_LPS_TNFa_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_LPS_TNFa_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_LPS_VCAM1_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_SAg_CD38_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_SAg_CD40_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_SAg_CD69_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_SAg_Eselectin_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_SAg_Eselectin_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_SAg_IL8_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_SAg_IL8_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_SAg_MCP1_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_SAg_MIG_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_SAg_PBMCCytotoxicity_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_SAg_PBMCCytotoxicity_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_SAg_Proliferation_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/BSK_SAg_SRB_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/CASN(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/CEETOX_H295R_11DCORT_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/CEETOX_H295R_ANDR_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/CEETOX_H295R_CORTISOL_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/CEETOX_H295R_DOC_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/CEETOX_H295R_DOC_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/CEETOX_H295R_ESTRADIOL_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/CEETOX_H295R_ESTRADIOL_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/CEETOX_H295R_ESTRONE_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/CEETOX_H295R_ESTRONE_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/CEETOX_H295R_OHPREG_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/CEETOX_H295R_OHPROG_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/CEETOX_H295R_OHPROG_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/CEETOX_H295R_PROG_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/CEETOX_H295R_TESTO_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/CLD_ABCB1_48hr(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/CLD_ABCG2_48hr(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/CLD_CYP1A1_24hr(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/CLD_CYP1A1_48hr(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/CLD_CYP1A1_6hr(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/CLD_CYP1A2_24hr(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/CLD_CYP1A2_48hr(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/CLD_CYP1A2_6hr(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/CLD_CYP2B6_24hr(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/CLD_CYP2B6_48hr(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/CLD_CYP2B6_6hr(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/CLD_CYP3A4_24hr(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/CLD_CYP3A4_48hr(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/CLD_CYP3A4_6hr(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/CLD_GSTA2_48hr(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/CLD_SULT2A_24hr(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/CLD_SULT2A_48hr(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/CLD_UGT1A1_24hr(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/CLD_UGT1A1_48hr(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NCCT_HEK293T_CellTiterGLO(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NCCT_QuantiLum_inhib_2_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NCCT_QuantiLum_inhib_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NCCT_TPO_AUR_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NCCT_TPO_GUA_dn(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NHEERL_ZF_144hpf_TERATOSCORE_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_ADME_hCYP19A1(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_ADME_hCYP1A1(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_ADME_hCYP1A2(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_ADME_hCYP2A6(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_ADME_hCYP2B6(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_ADME_hCYP2C19(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_ADME_hCYP2C9(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_ADME_hCYP2D6(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_ADME_hCYP3A4(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_ADME_hCYP4F12(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_ADME_rCYP2C12(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_ENZ_hAChE(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_ENZ_hAMPKa1(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_ENZ_hAurA(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_ENZ_hBACE(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_ENZ_hCASP5(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_ENZ_hCK1D(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_ENZ_hDUSP3(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_ENZ_hElastase(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_ENZ_hES(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_ENZ_hFGFR1(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_ENZ_hGSK3b(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_ENZ_hMMP1(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_ENZ_hMMP13(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_ENZ_hMMP2(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_ENZ_hMMP3(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_ENZ_hMMP7(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_ENZ_hMMP9(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_ENZ_hPDE10(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_ENZ_hPDE4A1(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_ENZ_hPDE5(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_ENZ_hPI3Ka(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_ENZ_hPTEN(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_ENZ_hPTPN11(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_ENZ_hPTPN12(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_ENZ_hPTPN13(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_ENZ_hPTPN9(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_ENZ_hPTPRC(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_ENZ_hSIRT1(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_ENZ_hSIRT2(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_ENZ_hTrkA(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_ENZ_hVEGFR2(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_ENZ_oCOX1(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_ENZ_oCOX2(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_ENZ_rabI2C(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_ENZ_rAChE(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_ENZ_rCNOS(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_ENZ_rMAOAC(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_ENZ_rMAOAP(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_ENZ_rMAOBC(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_ENZ_rMAOBP(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_GPCR_bAdoR_NonSelective(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_GPCR_bDR_NonSelective(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_GPCR_g5HT4(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_GPCR_gH2(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_GPCR_gLTB4(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_GPCR_gLTD4(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_GPCR_gMPeripheral_NonSelective(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_GPCR_gOpiateK(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_GPCR_h5HT2A(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_GPCR_h5HT5A(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_GPCR_h5HT6(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_GPCR_h5HT7(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_GPCR_hAdoRA1(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_GPCR_hAdoRA2a(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_GPCR_hAdra2A(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_GPCR_hAdra2C(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_GPCR_hAdrb1(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_GPCR_hAdrb2(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_GPCR_hAdrb3(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_GPCR_hAT1(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_GPCR_hDRD1(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_GPCR_hDRD2s(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_GPCR_hDRD4.4(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_GPCR_hH1(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_GPCR_hLTB4_BLT1(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_GPCR_hM1(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_GPCR_hM2(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_GPCR_hM3(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_GPCR_hM4(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_GPCR_hNK2(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_GPCR_hOpiate_D1(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_GPCR_hOpiate_mu(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_GPCR_hTXA2(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_GPCR_p5HT2C(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_GPCR_r5HT1_NonSelective(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_GPCR_r5HT_NonSelective(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_GPCR_rabPAF(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_GPCR_rAdra1B(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_GPCR_rAdra1_NonSelective(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_GPCR_rAdra2_NonSelective(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_GPCR_rAdrb_NonSelective(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_GPCR_rmAdra2B(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_GPCR_rNK1(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_GPCR_rNK3(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_GPCR_rOpiate_NonSelective(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_GPCR_rOpiate_NonSelectiveNa(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_GPCR_rSST(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_GPCR_rTRH(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_GPCR_rV1(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_IC_hKhERGCh(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_IC_rCaBTZCHL(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_IC_rCaDHPRCh_L(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_IC_rNaCh_site2(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_LGIC_bGABARa1(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_LGIC_h5HT3(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_LGIC_hNNR_NBungSens(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_LGIC_rGABAR_NonSelective(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_LGIC_rNNR_BungSens(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_MP_hPBR(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_MP_rPBR(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_NR_bER(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_NR_bPR(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_NR_cAR(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_NR_hAR(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_NR_hCAR_Antagonist(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_NR_hER(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_NR_hFXR_Agonist(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_NR_hFXR_Antagonist(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_NR_hGR(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_NR_hPPARa(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_NR_hPPARg(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_NR_hPR(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_NR_hPXR(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_NR_hRARa_Agonist(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_NR_hRAR_Antagonist(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_NR_hTRa_Antagonist(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_NR_mERa(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_NR_rAR(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_NR_rMR(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_OR_gSIGMA_NonSelective(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_TR_gDAT(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_TR_hAdoT(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_TR_hDAT(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_TR_hNET(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_TR_hSERT(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_TR_rNET(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_TR_rSERT(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/NVS_TR_rVMAT2(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/OT_AR_ARELUC_AG_1440(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/OT_AR_ARSRC1_0480(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/OT_AR_ARSRC1_0960(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/OT_ERa_EREGFP_0120(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/OT_ERa_EREGFP_0480(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/OT_ER_ERaERa_0480(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/OT_ER_ERaERa_1440(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/OT_ER_ERaERb_0480(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/OT_ER_ERaERb_1440(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/OT_ER_ERbERb_0480(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/OT_ER_ERbERb_1440(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/OT_FXR_FXRSRC1_0480(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/OT_FXR_FXRSRC1_1440(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/OT_NURR1_NURR1RXRa_0480(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/OT_NURR1_NURR1RXRa_1440(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/SMILES(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/Tanguay_ZF_120hpf_ActivityScore(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/Tanguay_ZF_120hpf_AXIS_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/Tanguay_ZF_120hpf_BRAI_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/Tanguay_ZF_120hpf_CFIN_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/Tanguay_ZF_120hpf_CIRC_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/Tanguay_ZF_120hpf_EYE_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/Tanguay_ZF_120hpf_JAW_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/Tanguay_ZF_120hpf_MORT_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/Tanguay_ZF_120hpf_OTIC_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/Tanguay_ZF_120hpf_PE_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/Tanguay_ZF_120hpf_PFIN_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/Tanguay_ZF_120hpf_PIG_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/Tanguay_ZF_120hpf_SNOU_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/Tanguay_ZF_120hpf_SOMI_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/Tanguay_ZF_120hpf_SWIM_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/Tanguay_ZF_120hpf_TRUN_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/Tanguay_ZF_120hpf_TR_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/Tanguay_ZF_120hpf_YSE_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_AhR_LUC_Agonist(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_ARE_BLA_Agonist_ch1(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_ARE_BLA_Agonist_ch2(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_ARE_BLA_agonist_ratio(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_ARE_BLA_agonist_viability(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_Aromatase_Inhibition(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_AR_BLA_Agonist_ch1(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_AR_BLA_Agonist_ch2(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_AR_BLA_Agonist_ratio(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_AR_BLA_Antagonist_ch1(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_AR_BLA_Antagonist_ch2(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_AR_BLA_Antagonist_ratio(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_AR_BLA_Antagonist_viability(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_AR_LUC_MDAKB2_Agonist(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_AR_LUC_MDAKB2_Antagonist(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_AR_LUC_MDAKB2_Antagonist2(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_AutoFluor_HEK293_Cell_blue(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_AutoFluor_HEK293_Media_blue(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_AutoFluor_HEPG2_Cell_blue(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_AutoFluor_HEPG2_Cell_green(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_AutoFluor_HEPG2_Media_blue(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_AutoFluor_HEPG2_Media_green(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_ELG1_LUC_Agonist(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_ERa_BLA_Agonist_ch1(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_ERa_BLA_Agonist_ch2(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_ERa_BLA_Agonist_ratio(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_ERa_BLA_Antagonist_ch1(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_ERa_BLA_Antagonist_ch2(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_ERa_BLA_Antagonist_ratio(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_ERa_BLA_Antagonist_viability(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_ERa_LUC_BG1_Agonist(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_ERa_LUC_BG1_Antagonist(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_ESRE_BLA_ch1(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_ESRE_BLA_ch2(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_ESRE_BLA_ratio(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_ESRE_BLA_viability(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_FXR_BLA_agonist_ch2(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_FXR_BLA_agonist_ratio(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_FXR_BLA_Antagonist_ch1(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_FXR_BLA_Antagonist_ch2(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_FXR_BLA_antagonist_ratio(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_FXR_BLA_antagonist_viability(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_GR_BLA_Agonist_ch1(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_GR_BLA_Agonist_ch2(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_GR_BLA_Agonist_ratio(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_GR_BLA_Antagonist_ch2(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_GR_BLA_Antagonist_ratio(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_GR_BLA_Antagonist_viability(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_HSE_BLA_agonist_ch1(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_HSE_BLA_agonist_ch2(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_HSE_BLA_agonist_ratio(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_HSE_BLA_agonist_viability(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_MMP_ratio_down(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_MMP_ratio_up(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_MMP_viability(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_NFkB_BLA_agonist_ch1(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_NFkB_BLA_agonist_ch2(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_NFkB_BLA_agonist_ratio(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_NFkB_BLA_agonist_viability(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_p53_BLA_p1_ch1(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_p53_BLA_p1_ch2(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_p53_BLA_p1_ratio(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_p53_BLA_p1_viability(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_p53_BLA_p2_ch1(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_p53_BLA_p2_ch2(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_p53_BLA_p2_ratio(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_p53_BLA_p2_viability(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_p53_BLA_p3_ch1(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_p53_BLA_p3_ch2(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_p53_BLA_p3_ratio(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_p53_BLA_p3_viability(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_p53_BLA_p4_ch1(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_p53_BLA_p4_ch2(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_p53_BLA_p4_ratio(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_p53_BLA_p4_viability(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_p53_BLA_p5_ch1(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_p53_BLA_p5_ch2(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_p53_BLA_p5_ratio(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_p53_BLA_p5_viability(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_PPARd_BLA_agonist_ch1(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_PPARd_BLA_agonist_ch2(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_PPARd_BLA_agonist_ratio(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_PPARd_BLA_Agonist_viability(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_PPARd_BLA_Antagonist_ch1(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_PPARd_BLA_antagonist_ratio(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_PPARd_BLA_antagonist_viability(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_PPARg_BLA_Agonist_ch1(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_PPARg_BLA_Agonist_ch2(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_PPARg_BLA_Agonist_ratio(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_PPARg_BLA_Antagonist_ch1(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_PPARg_BLA_antagonist_ratio(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_PPARg_BLA_antagonist_viability(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_TR_LUC_GH3_Agonist(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_TR_LUC_GH3_Antagonist(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_VDR_BLA_agonist_ch2(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_VDR_BLA_agonist_ratio(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_VDR_BLA_Agonist_viability(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_VDR_BLA_Antagonist_ch1(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_VDR_BLA_antagonist_ratio(input).csv\n",
      "C:/test/Deepchem toxcast_data all/Seperated/TOX21_VDR_BLA_antagonist_viability(input).csv\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Smiles'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(self, series, key)\u001b[0m\n\u001b[0;32m   3123\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3124\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mlibindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value_box\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3125\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.get_value_box\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.get_value_box\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'str' object cannot be interpreted as an integer",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-f8ae37061937>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;31m#get molecules and then get fingerprints from those\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m     \u001b[0mmol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mChem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMolFromSmiles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Smiles'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m     \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAllChem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGetMorganFingerprintAsBitVect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mmols\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    765\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 767\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    768\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(self, series, key)\u001b[0m\n\u001b[0;32m   3130\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3131\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3132\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0me1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3133\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pragma: no cover\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3134\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0me1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(self, series, key)\u001b[0m\n\u001b[0;32m   3116\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3117\u001b[0m             return self._engine.get_value(s, k,\n\u001b[1;32m-> 3118\u001b[1;33m                                           tz=getattr(series.dtype, 'tz', None))\n\u001b[0m\u001b[0;32m   3119\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3120\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minferred_type\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'integer'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'boolean'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Smiles'"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline #notebook을 실행한 브라우저에서 바로 그림을 볼 수 있게 해주는 것 \n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem, DataStructs\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#setting the seed for reproducibility\n",
    "#seed = 10110\n",
    "seed = 12061204\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "import os\n",
    "path_dir = 'C:/test/Deepchem toxcast_data all/Seperated'\n",
    "file_list = os.listdir(path_dir)\n",
    "input_files = []\n",
    "i = 0\n",
    "\n",
    "for item in file_list :\n",
    "        input_files.append(item)\n",
    "        #print(item)\n",
    "    \n",
    "\n",
    "for input_name in input_files : \n",
    "    input_path = \"C:/test/Deepchem toxcast_data all/Seperated/\"+input_name\n",
    "    print(input_path)\n",
    "    \n",
    "#load the dataset\n",
    "\n",
    "dataframe = pandas.read_csv(input_path, sep=\"\\t\")\n",
    "    \n",
    "\n",
    "mols = []\n",
    "fps = []\n",
    "\n",
    "#get molecules and then get fingerprints from those\n",
    "for index, row in dataframe.iterrows():\n",
    "    mol = Chem.MolFromSmiles(row['SMILES'])\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2)\n",
    "    mols.append(mol)\n",
    "    fps.append(fp)\n",
    "\n",
    "#Convert the RDKit vectors into numpy arrays\n",
    "#Based on: http://www.rdkit.org/docs/Cookbook.html#using-scikit-learn-with-rdkit\n",
    "np_fps = []\n",
    "for fp in fps:\n",
    "    arr = numpy.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    np_fps.append(arr)\n",
    "\n",
    "np_fps_array = numpy.array(np_fps)\n",
    "\n",
    "#Need to encode my classes\n",
    "#Ligand = 0, not_ligand = 1\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(dataframe['Type'])\n",
    "enc_y = encoder.transform(dataframe['Type'])\n",
    "\n",
    "#Create the machine learning model\n",
    "\n",
    "def create_deep_learning_model():\n",
    "    model = Sequential()\n",
    "    #첫번째 인자 : 출력 뉴런의 수 , input_dim : 입력 뉴런의 수, activation : 활성화 함수.\n",
    "    model.add(Dense(2048, input_dim=2048, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "sm = SMOTE(random_state=12, ratio = 'minority')\n",
    "x_train_res, y_train_res = sm.fit_sample(np_fps_array, enc_y) #결과데이터\n",
    " \n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "#estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5, verbose=0)\n",
    "estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "#results = cross_val_score(estimator, np_fps_array, enc_y, cv=kfold)\n",
    "results = cross_val_score(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "y_pred = cross_val_predict(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "conf_mat = confusion_matrix(y_train_res, y_pred)\n",
    "conf_mat\n",
    "\n",
    "\n",
    "model = create_deep_learning_model()\n",
    "model.fit(x_train_res, y_train_res, epochs=5, batch_size=5)\n",
    "model.save('TOX21_PPARg_BLA_Agonist_ratio(Input)_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "11132/11132 [==============================] - 227s 20ms/step - loss: 0.1322 - acc: 0.9532\n",
      "2784/2784 [==============================] - 5s 2ms/step\n",
      "Epoch 1/1\n",
      "11132/11132 [==============================] - 226s 20ms/step - loss: 0.1412 - acc: 0.9501\n",
      "2784/2784 [==============================] - 5s 2ms/step\n",
      "Epoch 1/1\n",
      "11132/11132 [==============================] - 227s 20ms/step - loss: 0.1357 - acc: 0.9534\n",
      "2784/2784 [==============================] - 5s 2ms/step\n",
      "Epoch 1/1\n",
      "11134/11134 [==============================] - 228s 21ms/step - loss: 0.1270 - acc: 0.9560\n",
      "2782/2782 [==============================] - 5s 2ms/step\n",
      "Epoch 1/1\n",
      "11134/11134 [==============================] - 225s 20ms/step - loss: 0.1272 - acc: 0.9555\n",
      "2782/2782 [==============================] - 5s 2ms/step\n",
      "Results: 98.13% (0.65%)\n",
      "Epoch 1/1\n",
      "11132/11132 [==============================] - 225s 20ms/step - loss: 0.1338 - acc: 0.9519\n",
      "Epoch 1/1\n",
      "11132/11132 [==============================] - 225s 20ms/step - loss: 0.1333 - acc: 0.9558\n",
      "Epoch 1/1\n",
      "11132/11132 [==============================] - 226s 20ms/step - loss: 0.1273 - acc: 0.9557\n",
      "Epoch 1/1\n",
      "11134/11134 [==============================] - 227s 20ms/step - loss: 0.1269 - acc: 0.9562\n",
      "Epoch 1/1\n",
      "11134/11134 [==============================] - 225s 20ms/step - loss: 0.1354 - acc: 0.9526\n",
      "Epoch 1/5\n",
      "13916/13916 [==============================] - 281s 20ms/step - loss: 0.1200 - acc: 0.9606\n",
      "Epoch 2/5\n",
      "13916/13916 [==============================] - 280s 20ms/step - loss: 0.0377 - acc: 0.9909\n",
      "Epoch 3/5\n",
      "13916/13916 [==============================] - 279s 20ms/step - loss: 0.0268 - acc: 0.9931\n",
      "Epoch 4/5\n",
      "13916/13916 [==============================] - 280s 20ms/step - loss: 0.0251 - acc: 0.9937\n",
      "Epoch 5/5\n",
      "13916/13916 [==============================] - 279s 20ms/step - loss: 0.0224 - acc: 0.9948\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline #notebook을 실행한 브라우저에서 바로 그림을 볼 수 있게 해주는 것 \n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem, DataStructs\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#setting the seed for reproducibility\n",
    "#seed = 10110\n",
    "seed = 12061204\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "#load the dataset\n",
    "dataframe = pandas.read_csv(\"./pubchem_data/processed/input/TOX21_NFkB_BLA_agonist_ratio(Input).txt\", sep=\"\\t\")\n",
    "\n",
    "mols = []\n",
    "fps = []\n",
    "\n",
    "#get molecules and then get fingerprints from those\n",
    "for index, row in dataframe.iterrows():\n",
    "    mol = Chem.MolFromSmiles(row['Smiles'])\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2)\n",
    "    mols.append(mol)\n",
    "    fps.append(fp)\n",
    "\n",
    "#Convert the RDKit vectors into numpy arrays\n",
    "#Based on: http://www.rdkit.org/docs/Cookbook.html#using-scikit-learn-with-rdkit\n",
    "np_fps = []\n",
    "for fp in fps:\n",
    "    arr = numpy.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    np_fps.append(arr)\n",
    "\n",
    "np_fps_array = numpy.array(np_fps)\n",
    "\n",
    "#Need to encode my classes\n",
    "#Ligand = 0, not_ligand = 1\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(dataframe['Type'])\n",
    "enc_y = encoder.transform(dataframe['Type'])\n",
    "\n",
    "#Create the machine learning model\n",
    "\n",
    "def create_deep_learning_model():\n",
    "    model = Sequential()\n",
    "    #첫번째 인자 : 출력 뉴런의 수 , input_dim : 입력 뉴런의 수, activation : 활성화 함수.\n",
    "    model.add(Dense(2048, input_dim=2048, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "sm = SMOTE(random_state=12, ratio = 'minority')\n",
    "x_train_res, y_train_res = sm.fit_sample(np_fps_array, enc_y) #결과데이터\n",
    " \n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "#estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5, verbose=0)\n",
    "estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "#results = cross_val_score(estimator, np_fps_array, enc_y, cv=kfold)\n",
    "results = cross_val_score(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "y_pred = cross_val_predict(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "conf_mat = confusion_matrix(y_train_res, y_pred)\n",
    "conf_mat\n",
    "\n",
    "\n",
    "model = create_deep_learning_model()\n",
    "model.fit(x_train_res, y_train_res, epochs=5, batch_size=5)\n",
    "model.save('TOX21_NFkB_BLA_agonist_ratio(Input)_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2278/2278 [==============================] - 58s 25ms/step - loss: 0.0768 - acc: 0.9781\n",
      "570/570 [==============================] - 1s 2ms/step\n",
      "Epoch 1/1\n",
      "2278/2278 [==============================] - 58s 25ms/step - loss: 0.0709 - acc: 0.9723\n",
      "570/570 [==============================] - 1s 2ms/step\n",
      "Epoch 1/1\n",
      "2278/2278 [==============================] - 55s 24ms/step - loss: 0.0799 - acc: 0.9723\n",
      "570/570 [==============================] - 1s 2ms/step\n",
      "Epoch 1/1\n",
      "2278/2278 [==============================] - 57s 25ms/step - loss: 0.0828 - acc: 0.9671\n",
      "570/570 [==============================] - 1s 2ms/step\n",
      "Epoch 1/1\n",
      "2280/2280 [==============================] - 58s 25ms/step - loss: 0.0979 - acc: 0.9671\n",
      "568/568 [==============================] - 1s 3ms/step\n",
      "Results: 99.26% (0.58%)\n",
      "Epoch 1/1\n",
      "2278/2278 [==============================] - 58s 25ms/step - loss: 0.0952 - acc: 0.9636\n",
      "Epoch 1/1\n",
      "2278/2278 [==============================] - 59s 26ms/step - loss: 0.0768 - acc: 0.9732\n",
      "Epoch 1/1\n",
      "2278/2278 [==============================] - 57s 25ms/step - loss: 0.0853 - acc: 0.9715\n",
      "Epoch 1/1\n",
      "2278/2278 [==============================] - 58s 25ms/step - loss: 0.0905 - acc: 0.9750\n",
      "Epoch 1/1\n",
      "2280/2280 [==============================] - 58s 25ms/step - loss: 0.0934 - acc: 0.9706\n",
      "Epoch 1/5\n",
      "2848/2848 [==============================] - 77s 27ms/step - loss: 0.0949 - acc: 0.9747\n",
      "Epoch 2/5\n",
      "2848/2848 [==============================] - 80s 28ms/step - loss: 0.0208 - acc: 0.9951\n",
      "Epoch 3/5\n",
      "2848/2848 [==============================] - 81s 29ms/step - loss: 0.0171 - acc: 0.9975\n",
      "Epoch 4/5\n",
      "2848/2848 [==============================] - 78s 27ms/step - loss: 0.0326 - acc: 0.9940\n",
      "Epoch 5/5\n",
      "2848/2848 [==============================] - 75s 26ms/step - loss: 0.0119 - acc: 0.9972\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline #notebook을 실행한 브라우저에서 바로 그림을 볼 수 있게 해주는 것 \n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem, DataStructs\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#setting the seed for reproducibility\n",
    "#seed = 10110\n",
    "seed = 12061204\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "#load the dataset\n",
    "dataframe = pandas.read_csv(\"./pubchem_data/processed/input/BSK_KF3CT_IL1a_up(Input).txt\", sep=\"\\t\")\n",
    "\n",
    "mols = []\n",
    "fps = []\n",
    "\n",
    "#get molecules and then get fingerprints from those\n",
    "for index, row in dataframe.iterrows():\n",
    "    mol = Chem.MolFromSmiles(row['Smiles'])\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2)\n",
    "    mols.append(mol)\n",
    "    fps.append(fp)\n",
    "\n",
    "#Convert the RDKit vectors into numpy arrays\n",
    "#Based on: http://www.rdkit.org/docs/Cookbook.html#using-scikit-learn-with-rdkit\n",
    "np_fps = []\n",
    "for fp in fps:\n",
    "    arr = numpy.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    np_fps.append(arr)\n",
    "\n",
    "np_fps_array = numpy.array(np_fps)\n",
    "\n",
    "#Need to encode my classes\n",
    "#Ligand = 0, not_ligand = 1\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(dataframe['Type'])\n",
    "enc_y = encoder.transform(dataframe['Type'])\n",
    "\n",
    "#Create the machine learning model\n",
    "\n",
    "def create_deep_learning_model():\n",
    "    model = Sequential()\n",
    "    #첫번째 인자 : 출력 뉴런의 수 , input_dim : 입력 뉴런의 수, activation : 활성화 함수.\n",
    "    model.add(Dense(2048, input_dim=2048, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "sm = SMOTE(random_state=12, ratio = 'minority')\n",
    "x_train_res, y_train_res = sm.fit_sample(np_fps_array, enc_y) #결과데이터\n",
    " \n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "#estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5, verbose=0)\n",
    "estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "#results = cross_val_score(estimator, np_fps_array, enc_y, cv=kfold)\n",
    "results = cross_val_score(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "y_pred = cross_val_predict(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "conf_mat = confusion_matrix(y_train_res, y_pred)\n",
    "conf_mat\n",
    "\n",
    "\n",
    "model = create_deep_learning_model()\n",
    "model.fit(x_train_res, y_train_res, epochs=5, batch_size=5)\n",
    "model.save('BSK_KF3CT_IL1a_up(Input)_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2998/2998 [==============================] - 63s 21ms/step - loss: 0.2237 - acc: 0.9053\n",
      "750/750 [==============================] - 2s 2ms/step\n",
      "Epoch 1/1\n",
      "2998/2998 [==============================] - 62s 21ms/step - loss: 0.2232 - acc: 0.9129\n",
      "750/750 [==============================] - 2s 2ms/step\n",
      "Epoch 1/1\n",
      "2998/2998 [==============================] - 62s 21ms/step - loss: 0.2157 - acc: 0.9176\n",
      "750/750 [==============================] - 2s 2ms/step\n",
      "Epoch 1/1\n",
      "2998/2998 [==============================] - 62s 21ms/step - loss: 0.2191 - acc: 0.9159\n",
      "750/750 [==============================] - 2s 2ms/step\n",
      "Epoch 1/1\n",
      "3000/3000 [==============================] - 63s 21ms/step - loss: 0.2291 - acc: 0.9023\n",
      "748/748 [==============================] - 2s 3ms/step\n",
      "Results: 97.63% (0.62%)\n",
      "Epoch 1/1\n",
      "2998/2998 [==============================] - 63s 21ms/step - loss: 0.2190 - acc: 0.9066\n",
      "Epoch 1/1\n",
      "2998/2998 [==============================] - 63s 21ms/step - loss: 0.2141 - acc: 0.9166\n",
      "Epoch 1/1\n",
      "2998/2998 [==============================] - 63s 21ms/step - loss: 0.2170 - acc: 0.9093\n",
      "Epoch 1/1\n",
      "2998/2998 [==============================] - 63s 21ms/step - loss: 0.2046 - acc: 0.9139\n",
      "Epoch 1/1\n",
      "3000/3000 [==============================] - 63s 21ms/step - loss: 0.2359 - acc: 0.9030\n",
      "Epoch 1/5\n",
      "3748/3748 [==============================] - 78s 21ms/step - loss: 0.1982 - acc: 0.9234\n",
      "Epoch 2/5\n",
      "3748/3748 [==============================] - 76s 20ms/step - loss: 0.0585 - acc: 0.9848\n",
      "Epoch 3/5\n",
      "3748/3748 [==============================] - 76s 20ms/step - loss: 0.0306 - acc: 0.9920\n",
      "Epoch 4/5\n",
      "3748/3748 [==============================] - 78s 21ms/step - loss: 0.0318 - acc: 0.9909\n",
      "Epoch 5/5\n",
      "3748/3748 [==============================] - 77s 20ms/step - loss: 0.0253 - acc: 0.9931\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline #notebook을 실행한 브라우저에서 바로 그림을 볼 수 있게 해주는 것 \n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem, DataStructs\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#setting the seed for reproducibility\n",
    "#seed = 10110\n",
    "seed = 12061204\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "#load the dataset\n",
    "dataframe = pandas.read_csv(\"./pubchem_data/processed/input/NVS_ENZ_hMMP9(Input).txt\", sep=\"\\t\")\n",
    "\n",
    "mols = []\n",
    "fps = []\n",
    "\n",
    "#get molecules and then get fingerprints from those\n",
    "for index, row in dataframe.iterrows():\n",
    "    mol = Chem.MolFromSmiles(row['Smiles'])\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2)\n",
    "    mols.append(mol)\n",
    "    fps.append(fp)\n",
    "\n",
    "#Convert the RDKit vectors into numpy arrays\n",
    "#Based on: http://www.rdkit.org/docs/Cookbook.html#using-scikit-learn-with-rdkit\n",
    "np_fps = []\n",
    "for fp in fps:\n",
    "    arr = numpy.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    np_fps.append(arr)\n",
    "\n",
    "np_fps_array = numpy.array(np_fps)\n",
    "\n",
    "#Need to encode my classes\n",
    "#Ligand = 0, not_ligand = 1\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(dataframe['Type'])\n",
    "enc_y = encoder.transform(dataframe['Type'])\n",
    "\n",
    "#Create the machine learning model\n",
    "\n",
    "def create_deep_learning_model():\n",
    "    model = Sequential()\n",
    "    #첫번째 인자 : 출력 뉴런의 수 , input_dim : 입력 뉴런의 수, activation : 활성화 함수.\n",
    "    model.add(Dense(2048, input_dim=2048, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "sm = SMOTE(random_state=12, ratio = 'minority')\n",
    "x_train_res, y_train_res = sm.fit_sample(np_fps_array, enc_y) #결과데이터\n",
    " \n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "#estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5, verbose=0)\n",
    "estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "#results = cross_val_score(estimator, np_fps_array, enc_y, cv=kfold)\n",
    "results = cross_val_score(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "y_pred = cross_val_predict(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "conf_mat = confusion_matrix(y_train_res, y_pred)\n",
    "conf_mat\n",
    "\n",
    "\n",
    "model = create_deep_learning_model()\n",
    "model.fit(x_train_res, y_train_res, epochs=5, batch_size=5)\n",
    "model.save('NVS_ENZ_hMMP9(Input)_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1706/1706 [==============================] - 37s 22ms/step - loss: 0.1380 - acc: 0.9531\n",
      "428/428 [==============================] - 1s 3ms/step\n",
      "Epoch 1/1\n",
      "1706/1706 [==============================] - 37s 21ms/step - loss: 0.1364 - acc: 0.9531\n",
      "428/428 [==============================] - 1s 3ms/step\n",
      "Epoch 1/1\n",
      "1708/1708 [==============================] - 37s 21ms/step - loss: 0.1376 - acc: 0.9555\n",
      "426/426 [==============================] - 1s 3ms/step\n",
      "Epoch 1/1\n",
      "1708/1708 [==============================] - 37s 21ms/step - loss: 0.1306 - acc: 0.9537\n",
      "426/426 [==============================] - 1s 3ms/step\n",
      "Epoch 1/1\n",
      "1708/1708 [==============================] - 37s 22ms/step - loss: 0.1418 - acc: 0.9391\n",
      "426/426 [==============================] - 1s 3ms/step\n",
      "Results: 99.06% (0.47%)\n",
      "Epoch 1/1\n",
      "1706/1706 [==============================] - 37s 22ms/step - loss: 0.1390 - acc: 0.9560\n",
      "Epoch 1/1\n",
      "1706/1706 [==============================] - 37s 22ms/step - loss: 0.1434 - acc: 0.9508\n",
      "Epoch 1/1\n",
      "1708/1708 [==============================] - 37s 22ms/step - loss: 0.1572 - acc: 0.9520\n",
      "Epoch 1/1\n",
      "1708/1708 [==============================] - 37s 22ms/step - loss: 0.1382 - acc: 0.9485\n",
      "Epoch 1/1\n",
      "1708/1708 [==============================] - 37s 22ms/step - loss: 0.1479 - acc: 0.9450\n",
      "Epoch 1/5\n",
      "2134/2134 [==============================] - 46s 21ms/step - loss: 0.1194 - acc: 0.9569\n",
      "Epoch 2/5\n",
      "2134/2134 [==============================] - 44s 20ms/step - loss: 0.0352 - acc: 0.9892\n",
      "Epoch 3/5\n",
      "2134/2134 [==============================] - 44s 20ms/step - loss: 0.0354 - acc: 0.9934\n",
      "Epoch 4/5\n",
      "2134/2134 [==============================] - 43s 20ms/step - loss: 0.0143 - acc: 0.9958\n",
      "Epoch 5/5\n",
      "2134/2134 [==============================] - 43s 20ms/step - loss: 0.0268 - acc: 0.9930\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline #notebook을 실행한 브라우저에서 바로 그림을 볼 수 있게 해주는 것 \n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem, DataStructs\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#setting the seed for reproducibility\n",
    "#seed = 10110\n",
    "seed = 12061204\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "#load the dataset\n",
    "dataframe = pandas.read_csv(\"./pubchem_data/processed/input/NVS_ENZ_hMMP2(Input).txt\", sep=\"\\t\")\n",
    "\n",
    "mols = []\n",
    "fps = []\n",
    "\n",
    "#get molecules and then get fingerprints from those\n",
    "for index, row in dataframe.iterrows():\n",
    "    mol = Chem.MolFromSmiles(row['Smiles'])\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2)\n",
    "    mols.append(mol)\n",
    "    fps.append(fp)\n",
    "\n",
    "#Convert the RDKit vectors into numpy arrays\n",
    "#Based on: http://www.rdkit.org/docs/Cookbook.html#using-scikit-learn-with-rdkit\n",
    "np_fps = []\n",
    "for fp in fps:\n",
    "    arr = numpy.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    np_fps.append(arr)\n",
    "\n",
    "np_fps_array = numpy.array(np_fps)\n",
    "\n",
    "#Need to encode my classes\n",
    "#Ligand = 0, not_ligand = 1\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(dataframe['Type'])\n",
    "enc_y = encoder.transform(dataframe['Type'])\n",
    "\n",
    "#Create the machine learning model\n",
    "\n",
    "def create_deep_learning_model():\n",
    "    model = Sequential()\n",
    "    #첫번째 인자 : 출력 뉴런의 수 , input_dim : 입력 뉴런의 수, activation : 활성화 함수.\n",
    "    model.add(Dense(2048, input_dim=2048, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "sm = SMOTE(random_state=12, ratio = 'minority')\n",
    "x_train_res, y_train_res = sm.fit_sample(np_fps_array, enc_y) #결과데이터\n",
    " \n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "#estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5, verbose=0)\n",
    "estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "#results = cross_val_score(estimator, np_fps_array, enc_y, cv=kfold)\n",
    "results = cross_val_score(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "y_pred = cross_val_predict(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "conf_mat = confusion_matrix(y_train_res, y_pred)\n",
    "conf_mat\n",
    "\n",
    "\n",
    "model = create_deep_learning_model()\n",
    "model.fit(x_train_res, y_train_res, epochs=5, batch_size=5)\n",
    "model.save('NVS_ENZ_hMMP2(Input)_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2188/2188 [==============================] - 47s 22ms/step - loss: 0.2061 - acc: 0.9141\n",
      "548/548 [==============================] - 2s 3ms/step\n",
      "Epoch 1/1\n",
      "2188/2188 [==============================] - 47s 21ms/step - loss: 0.1999 - acc: 0.9264\n",
      "548/548 [==============================] - 2s 3ms/step\n",
      "Epoch 1/1\n",
      "2188/2188 [==============================] - 47s 22ms/step - loss: 0.2471 - acc: 0.9068\n",
      "548/548 [==============================] - 2s 3ms/step\n",
      "Epoch 1/1\n",
      "2190/2190 [==============================] - 47s 22ms/step - loss: 0.2239 - acc: 0.9137\n",
      "546/546 [==============================] - 2s 3ms/step\n",
      "Epoch 1/1\n",
      "2190/2190 [==============================] - 47s 22ms/step - loss: 0.2177 - acc: 0.9110\n",
      "546/546 [==============================] - 2s 3ms/step\n",
      "Results: 97.33% (0.80%)\n",
      "Epoch 1/1\n",
      "2188/2188 [==============================] - 47s 22ms/step - loss: 0.2163 - acc: 0.9154\n",
      "Epoch 1/1\n",
      "2188/2188 [==============================] - 47s 22ms/step - loss: 0.2108 - acc: 0.9164\n",
      "Epoch 1/1\n",
      "2188/2188 [==============================] - 47s 22ms/step - loss: 0.2341 - acc: 0.9004\n",
      "Epoch 1/1\n",
      "2190/2190 [==============================] - 48s 22ms/step - loss: 0.2202 - acc: 0.9192\n",
      "Epoch 1/1\n",
      "2190/2190 [==============================] - 48s 22ms/step - loss: 0.2086 - acc: 0.9233\n",
      "Epoch 1/5\n",
      "2736/2736 [==============================] - 59s 21ms/step - loss: 0.2039 - acc: 0.9145\n",
      "Epoch 2/5\n",
      "2736/2736 [==============================] - 56s 21ms/step - loss: 0.0494 - acc: 0.9861\n",
      "Epoch 3/5\n",
      "2736/2736 [==============================] - 56s 21ms/step - loss: 0.0403 - acc: 0.9876\n",
      "Epoch 4/5\n",
      "2736/2736 [==============================] - 56s 21ms/step - loss: 0.0553 - acc: 0.9865\n",
      "Epoch 5/5\n",
      "2736/2736 [==============================] - 56s 21ms/step - loss: 0.0197 - acc: 0.9938\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline #notebook을 실행한 브라우저에서 바로 그림을 볼 수 있게 해주는 것 \n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem, DataStructs\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#setting the seed for reproducibility\n",
    "#seed = 10110\n",
    "seed = 12061204\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "#load the dataset\n",
    "dataframe = pandas.read_csv(\"./pubchem_data/processed/input/BSK_LPS_TNFa_up(Input).txt\", sep=\"\\t\")\n",
    "\n",
    "mols = []\n",
    "fps = []\n",
    "\n",
    "#get molecules and then get fingerprints from those\n",
    "for index, row in dataframe.iterrows():\n",
    "    mol = Chem.MolFromSmiles(row['Smiles'])\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2)\n",
    "    mols.append(mol)\n",
    "    fps.append(fp)\n",
    "\n",
    "#Convert the RDKit vectors into numpy arrays\n",
    "#Based on: http://www.rdkit.org/docs/Cookbook.html#using-scikit-learn-with-rdkit\n",
    "np_fps = []\n",
    "for fp in fps:\n",
    "    arr = numpy.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    np_fps.append(arr)\n",
    "\n",
    "np_fps_array = numpy.array(np_fps)\n",
    "\n",
    "#Need to encode my classes\n",
    "#Ligand = 0, not_ligand = 1\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(dataframe['Type'])\n",
    "enc_y = encoder.transform(dataframe['Type'])\n",
    "\n",
    "#Create the machine learning model\n",
    "\n",
    "def create_deep_learning_model():\n",
    "    model = Sequential()\n",
    "    #첫번째 인자 : 출력 뉴런의 수 , input_dim : 입력 뉴런의 수, activation : 활성화 함수.\n",
    "    model.add(Dense(2048, input_dim=2048, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "sm = SMOTE(random_state=12, ratio = 'minority')\n",
    "x_train_res, y_train_res = sm.fit_sample(np_fps_array, enc_y) #결과데이터\n",
    " \n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "#estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5, verbose=0)\n",
    "estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "#results = cross_val_score(estimator, np_fps_array, enc_y, cv=kfold)\n",
    "results = cross_val_score(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "y_pred = cross_val_predict(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "conf_mat = confusion_matrix(y_train_res, y_pred)\n",
    "conf_mat\n",
    "\n",
    "\n",
    "model = create_deep_learning_model()\n",
    "model.fit(x_train_res, y_train_res, epochs=5, batch_size=5)\n",
    "model.save('BSK_LPS_TNFa_up(Input)_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1840/1840 [==============================] - 41s 22ms/step - loss: 0.4670 - acc: 0.7772\n",
      "460/460 [==============================] - 2s 4ms/step\n",
      "Epoch 1/1\n",
      "1840/1840 [==============================] - 40s 22ms/step - loss: 0.4548 - acc: 0.7913\n",
      "460/460 [==============================] - 2s 4ms/step\n",
      "Epoch 1/1\n",
      "1840/1840 [==============================] - 40s 22ms/step - loss: 0.4675 - acc: 0.7777\n",
      "460/460 [==============================] - 2s 4ms/step\n",
      "Epoch 1/1\n",
      "1840/1840 [==============================] - 41s 22ms/step - loss: 0.4308 - acc: 0.8087\n",
      "460/460 [==============================] - 2s 4ms/step\n",
      "Epoch 1/1\n",
      "1840/1840 [==============================] - 42s 23ms/step - loss: 0.4990 - acc: 0.7641\n",
      "460/460 [==============================] - 2s 4ms/step\n",
      "Results: 89.17% (1.24%)\n",
      "Epoch 1/1\n",
      "1840/1840 [==============================] - 41s 22ms/step - loss: 0.4495 - acc: 0.7967\n",
      "Epoch 1/1\n",
      "1840/1840 [==============================] - 41s 22ms/step - loss: 0.4706 - acc: 0.7918\n",
      "Epoch 1/1\n",
      "1840/1840 [==============================] - 41s 22ms/step - loss: 0.4488 - acc: 0.7995\n",
      "Epoch 1/1\n",
      "1840/1840 [==============================] - 41s 22ms/step - loss: 0.4409 - acc: 0.8114\n",
      "Epoch 1/1\n",
      "1840/1840 [==============================] - 41s 22ms/step - loss: 0.4904 - acc: 0.7717\n",
      "Epoch 1/5\n",
      "2300/2300 [==============================] - 51s 22ms/step - loss: 0.4407 - acc: 0.8052\n",
      "Epoch 2/5\n",
      "2300/2300 [==============================] - 47s 21ms/step - loss: 0.1309 - acc: 0.9578\n",
      "Epoch 3/5\n",
      "2300/2300 [==============================] - 48s 21ms/step - loss: 0.0546 - acc: 0.9796\n",
      "Epoch 4/5\n",
      "2300/2300 [==============================] - 47s 21ms/step - loss: 0.0542 - acc: 0.9822 0s - loss: 0.0548 - acc: 0\n",
      "Epoch 5/5\n",
      "2300/2300 [==============================] - 47s 21ms/step - loss: 0.0494 - acc: 0.9809\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline #notebook을 실행한 브라우저에서 바로 그림을 볼 수 있게 해주는 것 \n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem, DataStructs\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#setting the seed for reproducibility\n",
    "#seed = 10110\n",
    "seed = 12061204\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "#load the dataset\n",
    "dataframe = pandas.read_csv(\"./pubchem_data/processed/input/BSK_LPS_TNFa_down(Input).txt\", sep=\"\\t\")\n",
    "\n",
    "mols = []\n",
    "fps = []\n",
    "\n",
    "#get molecules and then get fingerprints from those\n",
    "for index, row in dataframe.iterrows():\n",
    "    mol = Chem.MolFromSmiles(row['Smiles'])\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2)\n",
    "    mols.append(mol)\n",
    "    fps.append(fp)\n",
    "\n",
    "#Convert the RDKit vectors into numpy arrays\n",
    "#Based on: http://www.rdkit.org/docs/Cookbook.html#using-scikit-learn-with-rdkit\n",
    "np_fps = []\n",
    "for fp in fps:\n",
    "    arr = numpy.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    np_fps.append(arr)\n",
    "\n",
    "np_fps_array = numpy.array(np_fps)\n",
    "\n",
    "#Need to encode my classes\n",
    "#Ligand = 0, not_ligand = 1\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(dataframe['Type'])\n",
    "enc_y = encoder.transform(dataframe['Type'])\n",
    "\n",
    "#Create the machine learning model\n",
    "\n",
    "def create_deep_learning_model():\n",
    "    model = Sequential()\n",
    "    #첫번째 인자 : 출력 뉴런의 수 , input_dim : 입력 뉴런의 수, activation : 활성화 함수.\n",
    "    model.add(Dense(2048, input_dim=2048, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "sm = SMOTE(random_state=12, ratio = 'minority')\n",
    "x_train_res, y_train_res = sm.fit_sample(np_fps_array, enc_y) #결과데이터\n",
    " \n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "#estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5, verbose=0)\n",
    "estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "#results = cross_val_score(estimator, np_fps_array, enc_y, cv=kfold)\n",
    "results = cross_val_score(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "y_pred = cross_val_predict(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "conf_mat = confusion_matrix(y_train_res, y_pred)\n",
    "conf_mat\n",
    "\n",
    "\n",
    "model = create_deep_learning_model()\n",
    "model.fit(x_train_res, y_train_res, epochs=5, batch_size=5)\n",
    "model.save('BSK_LPS_TNFa_down(Input)_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2274/2274 [==============================] - 50s 22ms/step - loss: 0.0666 - acc: 0.9807\n",
      "570/570 [==============================] - 2s 4ms/step\n",
      "Epoch 1/1\n",
      "2274/2274 [==============================] - 50s 22ms/step - loss: 0.0672 - acc: 0.9758\n",
      "570/570 [==============================] - 2s 4ms/step\n",
      "Epoch 1/1\n",
      "2276/2276 [==============================] - 50s 22ms/step - loss: 0.0681 - acc: 0.9776\n",
      "568/568 [==============================] - 2s 4ms/step\n",
      "Epoch 1/1\n",
      "2276/2276 [==============================] - 50s 22ms/step - loss: 0.0595 - acc: 0.9785\n",
      "568/568 [==============================] - 2s 4ms/step\n",
      "Epoch 1/1\n",
      "2276/2276 [==============================] - 50s 22ms/step - loss: 0.0515 - acc: 0.9824\n",
      "568/568 [==============================] - 2s 4ms/step\n",
      "Results: 99.51% (0.64%)\n",
      "Epoch 1/1\n",
      "2274/2274 [==============================] - 50s 22ms/step - loss: 0.0675 - acc: 0.9776\n",
      "Epoch 1/1\n",
      "2274/2274 [==============================] - 50s 22ms/step - loss: 0.0499 - acc: 0.9820\n",
      "Epoch 1/1\n",
      "2276/2276 [==============================] - 52s 23ms/step - loss: 0.0717 - acc: 0.9728\n",
      "Epoch 1/1\n",
      "2276/2276 [==============================] - 50s 22ms/step - loss: 0.0568 - acc: 0.9815\n",
      "Epoch 1/1\n",
      "2276/2276 [==============================] - 51s 22ms/step - loss: 0.0711 - acc: 0.9741\n",
      "Epoch 1/5\n",
      "2844/2844 [==============================] - 63s 22ms/step - loss: 0.0535 - acc: 0.9863\n",
      "Epoch 2/5\n",
      "2844/2844 [==============================] - 59s 21ms/step - loss: 0.0186 - acc: 0.9965\n",
      "Epoch 3/5\n",
      "2844/2844 [==============================] - 59s 21ms/step - loss: 0.0118 - acc: 0.9979\n",
      "Epoch 4/5\n",
      "2844/2844 [==============================] - 59s 21ms/step - loss: 0.0083 - acc: 0.9986\n",
      "Epoch 5/5\n",
      "2844/2844 [==============================] - 59s 21ms/step - loss: 0.0062 - acc: 0.9993\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline #notebook을 실행한 브라우저에서 바로 그림을 볼 수 있게 해주는 것 \n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem, DataStructs\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#setting the seed for reproducibility\n",
    "#seed = 10110\n",
    "seed = 12061204\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "#load the dataset\n",
    "dataframe = pandas.read_csv(\"./pubchem_data/processed/input/BSK_LPS_IL1a_up(Input).txt\", sep=\"\\t\")\n",
    "\n",
    "mols = []\n",
    "fps = []\n",
    "\n",
    "#get molecules and then get fingerprints from those\n",
    "for index, row in dataframe.iterrows():\n",
    "    mol = Chem.MolFromSmiles(row['Smiles'])\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2)\n",
    "    mols.append(mol)\n",
    "    fps.append(fp)\n",
    "\n",
    "#Convert the RDKit vectors into numpy arrays\n",
    "#Based on: http://www.rdkit.org/docs/Cookbook.html#using-scikit-learn-with-rdkit\n",
    "np_fps = []\n",
    "for fp in fps:\n",
    "    arr = numpy.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    np_fps.append(arr)\n",
    "\n",
    "np_fps_array = numpy.array(np_fps)\n",
    "\n",
    "#Need to encode my classes\n",
    "#Ligand = 0, not_ligand = 1\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(dataframe['Type'])\n",
    "enc_y = encoder.transform(dataframe['Type'])\n",
    "\n",
    "#Create the machine learning model\n",
    "\n",
    "def create_deep_learning_model():\n",
    "    model = Sequential()\n",
    "    #첫번째 인자 : 출력 뉴런의 수 , input_dim : 입력 뉴런의 수, activation : 활성화 함수.\n",
    "    model.add(Dense(2048, input_dim=2048, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "sm = SMOTE(random_state=12, ratio = 'minority')\n",
    "x_train_res, y_train_res = sm.fit_sample(np_fps_array, enc_y) #결과데이터\n",
    " \n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "#estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5, verbose=0)\n",
    "estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "#results = cross_val_score(estimator, np_fps_array, enc_y, cv=kfold)\n",
    "results = cross_val_score(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "y_pred = cross_val_predict(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "conf_mat = confusion_matrix(y_train_res, y_pred)\n",
    "conf_mat\n",
    "\n",
    "\n",
    "model = create_deep_learning_model()\n",
    "model.fit(x_train_res, y_train_res, epochs=5, batch_size=5)\n",
    "model.save('BSK_LPS_IL1a_up(Input)_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1812/1812 [==============================] - 41s 23ms/step - loss: 0.4825 - acc: 0.7892\n",
      "454/454 [==============================] - 2s 5ms/step\n",
      "Epoch 1/1\n",
      "1812/1812 [==============================] - 41s 23ms/step - loss: 0.4876 - acc: 0.7770\n",
      "454/454 [==============================] - 2s 5ms/step\n",
      "Epoch 1/1\n",
      "1812/1812 [==============================] - 41s 23ms/step - loss: 0.4838 - acc: 0.7544\n",
      "454/454 [==============================] - 2s 5ms/step\n",
      "Epoch 1/1\n",
      "1814/1814 [==============================] - 41s 23ms/step - loss: 0.4783 - acc: 0.7641\n",
      "452/452 [==============================] - 2s 5ms/step\n",
      "Epoch 1/1\n",
      "1814/1814 [==============================] - 41s 23ms/step - loss: 0.4896 - acc: 0.7778\n",
      "452/452 [==============================] - 2s 5ms/step\n",
      "Results: 87.82% (1.44%)\n",
      "Epoch 1/1\n",
      "1812/1812 [==============================] - 42s 23ms/step - loss: 0.4749 - acc: 0.7837\n",
      "Epoch 1/1\n",
      "1812/1812 [==============================] - 43s 24ms/step - loss: 0.4757 - acc: 0.7770\n",
      "Epoch 1/1\n",
      "1812/1812 [==============================] - 42s 23ms/step - loss: 0.5094 - acc: 0.7577\n",
      "Epoch 1/1\n",
      "1814/1814 [==============================] - 42s 23ms/step - loss: 0.4792 - acc: 0.7811\n",
      "Epoch 1/1\n",
      "1814/1814 [==============================] - 42s 23ms/step - loss: 0.4737 - acc: 0.7806\n",
      "Epoch 1/5\n",
      "2266/2266 [==============================] - 52s 23ms/step - loss: 0.4357 - acc: 0.8045\n",
      "Epoch 2/5\n",
      "2266/2266 [==============================] - 47s 21ms/step - loss: 0.1115 - acc: 0.9660\n",
      "Epoch 3/5\n",
      "2266/2266 [==============================] - 48s 21ms/step - loss: 0.0518 - acc: 0.9841\n",
      "Epoch 4/5\n",
      "2266/2266 [==============================] - 48s 21ms/step - loss: 0.0366 - acc: 0.9859\n",
      "Epoch 5/5\n",
      "2266/2266 [==============================] - 48s 21ms/step - loss: 0.0451 - acc: 0.9841\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline #notebook을 실행한 브라우저에서 바로 그림을 볼 수 있게 해주는 것 \n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem, DataStructs\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#setting the seed for reproducibility\n",
    "#seed = 10110\n",
    "seed = 12061204\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "#load the dataset\n",
    "dataframe = pandas.read_csv(\"./pubchem_data/processed/input/BSK_LPS_IL1a_down(Input).txt\", sep=\"\\t\")\n",
    "\n",
    "mols = []\n",
    "fps = []\n",
    "\n",
    "#get molecules and then get fingerprints from those\n",
    "for index, row in dataframe.iterrows():\n",
    "    mol = Chem.MolFromSmiles(row['Smiles'])\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2)\n",
    "    mols.append(mol)\n",
    "    fps.append(fp)\n",
    "\n",
    "#Convert the RDKit vectors into numpy arrays\n",
    "#Based on: http://www.rdkit.org/docs/Cookbook.html#using-scikit-learn-with-rdkit\n",
    "np_fps = []\n",
    "for fp in fps:\n",
    "    arr = numpy.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    np_fps.append(arr)\n",
    "\n",
    "np_fps_array = numpy.array(np_fps)\n",
    "\n",
    "#Need to encode my classes\n",
    "#Ligand = 0, not_ligand = 1\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(dataframe['Type'])\n",
    "enc_y = encoder.transform(dataframe['Type'])\n",
    "\n",
    "#Create the machine learning model\n",
    "\n",
    "def create_deep_learning_model():\n",
    "    model = Sequential()\n",
    "    #첫번째 인자 : 출력 뉴런의 수 , input_dim : 입력 뉴런의 수, activation : 활성화 함수.\n",
    "    model.add(Dense(2048, input_dim=2048, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "sm = SMOTE(random_state=12, ratio = 'minority')\n",
    "x_train_res, y_train_res = sm.fit_sample(np_fps_array, enc_y) #결과데이터\n",
    " \n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "#estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5, verbose=0)\n",
    "estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "#results = cross_val_score(estimator, np_fps_array, enc_y, cv=kfold)\n",
    "results = cross_val_score(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "y_pred = cross_val_predict(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "conf_mat = confusion_matrix(y_train_res, y_pred)\n",
    "conf_mat\n",
    "\n",
    "\n",
    "model = create_deep_learning_model()\n",
    "model.fit(x_train_res, y_train_res, epochs=5, batch_size=5)\n",
    "model.save('BSK_LPS_IL1a_down(Input)_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1840/1840 [==============================] - 43s 23ms/step - loss: 0.4752 - acc: 0.7783\n",
      "460/460 [==============================] - 3s 5ms/step\n",
      "Epoch 1/1\n",
      "1840/1840 [==============================] - 42s 23ms/step - loss: 0.4497 - acc: 0.8038\n",
      "460/460 [==============================] - 3s 5ms/step\n",
      "Epoch 1/1\n",
      "1840/1840 [==============================] - 42s 23ms/step - loss: 0.4730 - acc: 0.7739\n",
      "460/460 [==============================] - 3s 6ms/step\n",
      "Epoch 1/1\n",
      "1840/1840 [==============================] - 43s 23ms/step - loss: 0.4778 - acc: 0.7750\n",
      "460/460 [==============================] - 3s 6ms/step\n",
      "Epoch 1/1\n",
      "1840/1840 [==============================] - 43s 23ms/step - loss: 0.4597 - acc: 0.7886\n",
      "460/460 [==============================] - 3s 6ms/step\n",
      "Results: 88.22% (2.61%)\n",
      "Epoch 1/1\n",
      "1840/1840 [==============================] - 43s 23ms/step - loss: 0.4837 - acc: 0.7793\n",
      "Epoch 1/1\n",
      "1840/1840 [==============================] - 43s 23ms/step - loss: 0.4600 - acc: 0.7913\n",
      "Epoch 1/1\n",
      "1840/1840 [==============================] - 43s 23ms/step - loss: 0.4591 - acc: 0.7973\n",
      "Epoch 1/1\n",
      "1840/1840 [==============================] - 43s 23ms/step - loss: 0.4466 - acc: 0.7967\n",
      "Epoch 1/1\n",
      "1840/1840 [==============================] - 43s 23ms/step - loss: 0.4499 - acc: 0.7935\n",
      "Epoch 1/5\n",
      "2300/2300 [==============================] - 53s 23ms/step - loss: 0.4247 - acc: 0.8070\n",
      "Epoch 2/5\n",
      "2300/2300 [==============================] - 48s 21ms/step - loss: 0.1177 - acc: 0.9635\n",
      "Epoch 3/5\n",
      "2300/2300 [==============================] - 48s 21ms/step - loss: 0.0719 - acc: 0.9765\n",
      "Epoch 4/5\n",
      "2300/2300 [==============================] - 49s 21ms/step - loss: 0.0462 - acc: 0.9822\n",
      "Epoch 5/5\n",
      "2300/2300 [==============================] - 48s 21ms/step - loss: 0.0305 - acc: 0.9865\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline #notebook을 실행한 브라우저에서 바로 그림을 볼 수 있게 해주는 것 \n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem, DataStructs\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#setting the seed for reproducibility\n",
    "#seed = 10110\n",
    "seed = 12061204\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "#load the dataset\n",
    "dataframe = pandas.read_csv(\"./pubchem_data/processed/input/BSK_KF3CT_TGFb1_downInput).txt\", sep=\"\\t\")\n",
    "\n",
    "mols = []\n",
    "fps = []\n",
    "\n",
    "#get molecules and then get fingerprints from those\n",
    "for index, row in dataframe.iterrows():\n",
    "    mol = Chem.MolFromSmiles(row['Smiles'])\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2)\n",
    "    mols.append(mol)\n",
    "    fps.append(fp)\n",
    "\n",
    "#Convert the RDKit vectors into numpy arrays\n",
    "#Based on: http://www.rdkit.org/docs/Cookbook.html#using-scikit-learn-with-rdkit\n",
    "np_fps = []\n",
    "for fp in fps:\n",
    "    arr = numpy.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    np_fps.append(arr)\n",
    "\n",
    "np_fps_array = numpy.array(np_fps)\n",
    "\n",
    "#Need to encode my classes\n",
    "#Ligand = 0, not_ligand = 1\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(dataframe['Type'])\n",
    "enc_y = encoder.transform(dataframe['Type'])\n",
    "\n",
    "#Create the machine learning model\n",
    "\n",
    "def create_deep_learning_model():\n",
    "    model = Sequential()\n",
    "    #첫번째 인자 : 출력 뉴런의 수 , input_dim : 입력 뉴런의 수, activation : 활성화 함수.\n",
    "    model.add(Dense(2048, input_dim=2048, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "sm = SMOTE(random_state=12, ratio = 'minority')\n",
    "x_train_res, y_train_res = sm.fit_sample(np_fps_array, enc_y) #결과데이터\n",
    " \n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "#estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5, verbose=0)\n",
    "estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "#results = cross_val_score(estimator, np_fps_array, enc_y, cv=kfold)\n",
    "results = cross_val_score(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "y_pred = cross_val_predict(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "conf_mat = confusion_matrix(y_train_res, y_pred)\n",
    "conf_mat\n",
    "\n",
    "\n",
    "model = create_deep_learning_model()\n",
    "model.fit(x_train_res, y_train_res, epochs=5, batch_size=5)\n",
    "model.save('BSK_KF3CT_TGFb1_down(Input)_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2302/2302 [==============================] - 53s 23ms/step - loss: 0.0453 - acc: 0.9831\n",
      "576/576 [==============================] - 3s 5ms/step\n",
      "Epoch 1/1\n",
      "2302/2302 [==============================] - 53s 23ms/step - loss: 0.0470 - acc: 0.9848\n",
      "576/576 [==============================] - 3s 6ms/step\n",
      "Epoch 1/1\n",
      "2302/2302 [==============================] - 53s 23ms/step - loss: 0.0578 - acc: 0.9805\n",
      "576/576 [==============================] - 3s 6ms/step\n",
      "Epoch 1/1\n",
      "2302/2302 [==============================] - 53s 23ms/step - loss: 0.0544 - acc: 0.9805\n",
      "576/576 [==============================] - 3s 6ms/step\n",
      "Epoch 1/1\n",
      "2304/2304 [==============================] - 53s 23ms/step - loss: 0.0442 - acc: 0.9835\n",
      "574/574 [==============================] - 3s 6ms/step\n",
      "Results: 99.55% (0.51%)\n",
      "Epoch 1/1\n",
      "2302/2302 [==============================] - 53s 23ms/step - loss: 0.0530 - acc: 0.9852\n",
      "Epoch 1/1\n",
      "2302/2302 [==============================] - 53s 23ms/step - loss: 0.0407 - acc: 0.9891\n",
      "Epoch 1/1\n",
      "2302/2302 [==============================] - 53s 23ms/step - loss: 0.0547 - acc: 0.9874\n",
      "Epoch 1/1\n",
      "2302/2302 [==============================] - 54s 23ms/step - loss: 0.0445 - acc: 0.9822\n",
      "Epoch 1/1\n",
      "2304/2304 [==============================] - 54s 23ms/step - loss: 0.0779 - acc: 0.9770\n",
      "Epoch 1/5\n",
      "2878/2878 [==============================] - 66s 23ms/step - loss: 0.0470 - acc: 0.9889\n",
      "Epoch 2/5\n",
      "2878/2878 [==============================] - 61s 21ms/step - loss: 0.0210 - acc: 0.9962\n",
      "Epoch 3/5\n",
      "2878/2878 [==============================] - 61s 21ms/step - loss: 0.0058 - acc: 0.9990\n",
      "Epoch 4/5\n",
      "2878/2878 [==============================] - 61s 21ms/step - loss: 0.0053 - acc: 0.9993\n",
      "Epoch 5/5\n",
      "2878/2878 [==============================] - 61s 21ms/step - loss: 0.0035 - acc: 0.9990\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline #notebook을 실행한 브라우저에서 바로 그림을 볼 수 있게 해주는 것 \n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem, DataStructs\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#setting the seed for reproducibility\n",
    "#seed = 10110\n",
    "seed = 12061204\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "#load the dataset\n",
    "dataframe = pandas.read_csv(\"./pubchem_data/processed/input/BSK_KF3CT_TGFb1_down(Input).txt\", sep=\"\\t\")\n",
    "\n",
    "mols = []\n",
    "fps = []\n",
    "\n",
    "#get molecules and then get fingerprints from those\n",
    "for index, row in dataframe.iterrows():\n",
    "    mol = Chem.MolFromSmiles(row['Smiles'])\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2)\n",
    "    mols.append(mol)\n",
    "    fps.append(fp)\n",
    "\n",
    "#Convert the RDKit vectors into numpy arrays\n",
    "#Based on: http://www.rdkit.org/docs/Cookbook.html#using-scikit-learn-with-rdkit\n",
    "np_fps = []\n",
    "for fp in fps:\n",
    "    arr = numpy.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    np_fps.append(arr)\n",
    "\n",
    "np_fps_array = numpy.array(np_fps)\n",
    "\n",
    "#Need to encode my classes\n",
    "#Ligand = 0, not_ligand = 1\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(dataframe['Type'])\n",
    "enc_y = encoder.transform(dataframe['Type'])\n",
    "\n",
    "#Create the machine learning model\n",
    "\n",
    "def create_deep_learning_model():\n",
    "    model = Sequential()\n",
    "    #첫번째 인자 : 출력 뉴런의 수 , input_dim : 입력 뉴런의 수, activation : 활성화 함수.\n",
    "    model.add(Dense(2048, input_dim=2048, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "sm = SMOTE(random_state=12, ratio = 'minority')\n",
    "x_train_res, y_train_res = sm.fit_sample(np_fps_array, enc_y) #결과데이터\n",
    " \n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "#estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5, verbose=0)\n",
    "estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "#results = cross_val_score(estimator, np_fps_array, enc_y, cv=kfold)\n",
    "results = cross_val_score(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "y_pred = cross_val_predict(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "conf_mat = confusion_matrix(y_train_res, y_pred)\n",
    "conf_mat\n",
    "\n",
    "\n",
    "model = create_deep_learning_model()\n",
    "model.fit(x_train_res, y_train_res, epochs=5, batch_size=5)\n",
    "model.save('BSK_KF3CT_TGFb1_downInput)_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 6",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-32f6ee5c1357>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[0msm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mratio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'minority'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m \u001b[0mx_train_res\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_res\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp_fps_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menc_y\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#결과데이터\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36mfit_sample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     86\u001b[0m         \"\"\"\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36msample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfit_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\imblearn\\over_sampling\\smote.py\u001b[0m in \u001b[0;36m_sample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'regular'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 594\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sample_regular\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    595\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'borderline1'\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'borderline2'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sample_borderline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\imblearn\\over_sampling\\smote.py\u001b[0m in \u001b[0;36m_sample_regular\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn_k_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_class\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 360\u001b[1;33m             \u001b[0mnns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn_k_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    361\u001b[0m             X_new, y_new = self._make_samples(X_class, class_sample, X_class,\n\u001b[0;32m    362\u001b[0m                                               nns, n_samples, 1.0)\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\neighbors\\base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    345\u001b[0m                 \u001b[1;34m\"Expected n_neighbors <= n_samples, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    346\u001b[0m                 \u001b[1;34m\" but n_samples = %d, n_neighbors = %d\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 347\u001b[1;33m                 \u001b[1;33m(\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    348\u001b[0m             )\n\u001b[0;32m    349\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 6"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline #notebook을 실행한 브라우저에서 바로 그림을 볼 수 있게 해주는 것 \n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem, DataStructs\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#setting the seed for reproducibility\n",
    "#seed = 10110\n",
    "seed = 12061204\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "#load the dataset\n",
    "dataframe = pandas.read_csv(\"./pubchem_data/processed/input/BSK_KF3CT_MMP9_up(Input).txt\", sep=\"\\t\")\n",
    "\n",
    "mols = []\n",
    "fps = []\n",
    "\n",
    "#get molecules and then get fingerprints from those\n",
    "for index, row in dataframe.iterrows():\n",
    "    mol = Chem.MolFromSmiles(row['Smiles'])\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2)\n",
    "    mols.append(mol)\n",
    "    fps.append(fp)\n",
    "\n",
    "#Convert the RDKit vectors into numpy arrays\n",
    "#Based on: http://www.rdkit.org/docs/Cookbook.html#using-scikit-learn-with-rdkit\n",
    "np_fps = []\n",
    "for fp in fps:\n",
    "    arr = numpy.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    np_fps.append(arr)\n",
    "\n",
    "np_fps_array = numpy.array(np_fps)\n",
    "\n",
    "#Need to encode my classes\n",
    "#Ligand = 0, not_ligand = 1\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(dataframe['Type'])\n",
    "enc_y = encoder.transform(dataframe['Type'])\n",
    "\n",
    "#Create the machine learning model\n",
    "\n",
    "def create_deep_learning_model():\n",
    "    model = Sequential()\n",
    "    #첫번째 인자 : 출력 뉴런의 수 , input_dim : 입력 뉴런의 수, activation : 활성화 함수.\n",
    "    model.add(Dense(2048, input_dim=2048, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "sm = SMOTE(random_state=12, ratio = 'minority')\n",
    "x_train_res, y_train_res = sm.fit_sample(np_fps_array, enc_y) #결과데이터\n",
    " \n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "#estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5, verbose=0)\n",
    "estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "#results = cross_val_score(estimator, np_fps_array, enc_y, cv=kfold)\n",
    "results = cross_val_score(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "y_pred = cross_val_predict(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "conf_mat = confusion_matrix(y_train_res, y_pred)\n",
    "conf_mat\n",
    "\n",
    "\n",
    "model = create_deep_learning_model()\n",
    "model.fit(x_train_res, y_train_res, epochs=5, batch_size=5)\n",
    "model.save('BSK_KF3CT_MMP9_up(Input)_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1682/1682 [==============================] - 36s 21ms/step - loss: 0.5363 - acc: 0.7366\n",
      "422/422 [==============================] - 1s 2ms/step\n",
      "Epoch 1/1\n",
      "1682/1682 [==============================] - 36s 21ms/step - loss: 0.5396 - acc: 0.7378\n",
      "422/422 [==============================] - 1s 2ms/step\n",
      "Epoch 1/1\n",
      "1684/1684 [==============================] - 35s 21ms/step - loss: 0.5415 - acc: 0.7262\n",
      "420/420 [==============================] - 1s 3ms/step\n",
      "Epoch 1/1\n",
      "1684/1684 [==============================] - 35s 21ms/step - loss: 0.5544 - acc: 0.7322\n",
      "420/420 [==============================] - 1s 2ms/step\n",
      "Epoch 1/1\n",
      "1684/1684 [==============================] - 34s 20ms/step - loss: 0.5556 - acc: 0.7257\n",
      "420/420 [==============================] - 1s 2ms/step\n",
      "Results: 82.17% (2.01%)\n",
      "Epoch 1/1\n",
      "1682/1682 [==============================] - 34s 20ms/step - loss: 0.5497 - acc: 0.7247\n",
      "Epoch 1/1\n",
      "1682/1682 [==============================] - 34s 20ms/step - loss: 0.5380 - acc: 0.7313\n",
      "Epoch 1/1\n",
      "1684/1684 [==============================] - 34s 20ms/step - loss: 0.5358 - acc: 0.7334\n",
      "Epoch 1/1\n",
      "1684/1684 [==============================] - 34s 20ms/step - loss: 0.5351 - acc: 0.7464\n",
      "Epoch 1/1\n",
      "1684/1684 [==============================] - 35s 21ms/step - loss: 0.5396 - acc: 0.7393\n",
      "Epoch 1/5\n",
      "2104/2104 [==============================] - 42s 20ms/step - loss: 0.5222 - acc: 0.7590\n",
      "Epoch 2/5\n",
      "2104/2104 [==============================] - 41s 20ms/step - loss: 0.1577 - acc: 0.9444\n",
      "Epoch 3/5\n",
      "2104/2104 [==============================] - 41s 20ms/step - loss: 0.0677 - acc: 0.9781\n",
      "Epoch 4/5\n",
      "2104/2104 [==============================] - 41s 20ms/step - loss: 0.0634 - acc: 0.9815\n",
      "Epoch 5/5\n",
      "2104/2104 [==============================] - 41s 20ms/step - loss: 0.0317 - acc: 0.9857\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline #notebook을 실행한 브라우저에서 바로 그림을 볼 수 있게 해주는 것 \n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem, DataStructs\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#setting the seed for reproducibility\n",
    "#seed = 10110\n",
    "seed = 12061204\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "#load the dataset\n",
    "dataframe = pandas.read_csv(\"./pubchem_data/processed/input/BSK_KF3CT_MMP9_down(Input).txt\", sep=\"\\t\")\n",
    "\n",
    "mols = []\n",
    "fps = []\n",
    "\n",
    "#get molecules and then get fingerprints from those\n",
    "for index, row in dataframe.iterrows():\n",
    "    mol = Chem.MolFromSmiles(row['Smiles'])\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2)\n",
    "    mols.append(mol)\n",
    "    fps.append(fp)\n",
    "\n",
    "#Convert the RDKit vectors into numpy arrays\n",
    "#Based on: http://www.rdkit.org/docs/Cookbook.html#using-scikit-learn-with-rdkit\n",
    "np_fps = []\n",
    "for fp in fps:\n",
    "    arr = numpy.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    np_fps.append(arr)\n",
    "\n",
    "np_fps_array = numpy.array(np_fps)\n",
    "\n",
    "#Need to encode my classes\n",
    "#Ligand = 0, not_ligand = 1\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(dataframe['Type'])\n",
    "enc_y = encoder.transform(dataframe['Type'])\n",
    "\n",
    "#Create the machine learning model\n",
    "\n",
    "def create_deep_learning_model():\n",
    "    model = Sequential()\n",
    "    #첫번째 인자 : 출력 뉴런의 수 , input_dim : 입력 뉴런의 수, activation : 활성화 함수.\n",
    "    model.add(Dense(2048, input_dim=2048, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "sm = SMOTE(random_state=12, ratio = 'minority')\n",
    "x_train_res, y_train_res = sm.fit_sample(np_fps_array, enc_y) #결과데이터\n",
    " \n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "#estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5, verbose=0)\n",
    "estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "#results = cross_val_score(estimator, np_fps_array, enc_y, cv=kfold)\n",
    "results = cross_val_score(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "y_pred = cross_val_predict(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "conf_mat = confusion_matrix(y_train_res, y_pred)\n",
    "conf_mat\n",
    "\n",
    "\n",
    "model = create_deep_learning_model()\n",
    "model.fit(x_train_res, y_train_res, epochs=5, batch_size=5)\n",
    "model.save('BSK_KF3CT_MMP9_down(Input)_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline #notebook을 실행한 브라우저에서 바로 그림을 볼 수 있게 해주는 것 \n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem, DataStructs\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#setting the seed for reproducibility\n",
    "#seed = 10110\n",
    "seed = 12061204\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "#load the dataset\n",
    "dataframe = pandas.read_csv(\"./pubchem_data/processed/input/BSK_KF3CT_IL1a_up(Input).txt\", sep=\"\\t\")\n",
    "\n",
    "mols = []\n",
    "fps = []\n",
    "\n",
    "#get molecules and then get fingerprints from those\n",
    "for index, row in dataframe.iterrows():\n",
    "    mol = Chem.MolFromSmiles(row['Smiles'])\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2)\n",
    "    mols.append(mol)\n",
    "    fps.append(fp)\n",
    "\n",
    "#Convert the RDKit vectors into numpy arrays\n",
    "#Based on: http://www.rdkit.org/docs/Cookbook.html#using-scikit-learn-with-rdkit\n",
    "np_fps = []\n",
    "for fp in fps:\n",
    "    arr = numpy.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    np_fps.append(arr)\n",
    "\n",
    "np_fps_array = numpy.array(np_fps)\n",
    "\n",
    "#Need to encode my classes\n",
    "#Ligand = 0, not_ligand = 1\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(dataframe['Type'])\n",
    "enc_y = encoder.transform(dataframe['Type'])\n",
    "\n",
    "#Create the machine learning model\n",
    "\n",
    "def create_deep_learning_model():\n",
    "    model = Sequential()\n",
    "    #첫번째 인자 : 출력 뉴런의 수 , input_dim : 입력 뉴런의 수, activation : 활성화 함수.\n",
    "    model.add(Dense(2048, input_dim=2048, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "sm = SMOTE(random_state=12, ratio = 'minority')\n",
    "x_train_res, y_train_res = sm.fit_sample(np_fps_array, enc_y) #결과데이터\n",
    " \n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "#estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5, verbose=0)\n",
    "estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "#results = cross_val_score(estimator, np_fps_array, enc_y, cv=kfold)\n",
    "results = cross_val_score(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "y_pred = cross_val_predict(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "conf_mat = confusion_matrix(y_train_res, y_pred)\n",
    "conf_mat\n",
    "\n",
    "\n",
    "model = create_deep_learning_model()\n",
    "model.fit(x_train_res, y_train_res, epochs=5, batch_size=5)\n",
    "model.save('BSK_KF3CT_IL1a_up(Input)_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1832/1832 [==============================] - 47s 26ms/step - loss: 0.4600 - acc: 0.7806\n",
      "460/460 [==============================] - 1s 3ms/step\n",
      "Epoch 1/1\n",
      "1834/1834 [==============================] - 47s 26ms/step - loss: 0.4624 - acc: 0.7993\n",
      "458/458 [==============================] - 1s 3ms/step\n",
      "Epoch 1/1\n",
      "1834/1834 [==============================] - 47s 26ms/step - loss: 0.4585 - acc: 0.7928\n",
      "458/458 [==============================] - 1s 3ms/step\n",
      "Epoch 1/1\n",
      "1834/1834 [==============================] - 47s 26ms/step - loss: 0.4583 - acc: 0.7824\n",
      "458/458 [==============================] - 2s 4ms/step\n",
      "Epoch 1/1\n",
      "1834/1834 [==============================] - 47s 26ms/step - loss: 0.4599 - acc: 0.8075\n",
      "458/458 [==============================] - 1s 3ms/step\n",
      "Results: 88.70% (1.94%)\n",
      "Epoch 1/1\n",
      "1832/1832 [==============================] - 47s 26ms/step - loss: 0.4645 - acc: 0.7866\n",
      "Epoch 1/1\n",
      "1834/1834 [==============================] - 48s 26ms/step - loss: 0.4583 - acc: 0.7775\n",
      "Epoch 1/1\n",
      "1834/1834 [==============================] - 48s 26ms/step - loss: 0.4826 - acc: 0.7830\n",
      "Epoch 1/1\n",
      "1834/1834 [==============================] - 48s 26ms/step - loss: 0.4772 - acc: 0.7754\n",
      "Epoch 1/1\n",
      "1834/1834 [==============================] - 48s 26ms/step - loss: 0.4684 - acc: 0.7879\n",
      "Epoch 1/5\n",
      "2292/2292 [==============================] - 59s 26ms/step - loss: 0.4146 - acc: 0.8255\n",
      "Epoch 2/5\n",
      "2292/2292 [==============================] - 56s 24ms/step - loss: 0.1239 - acc: 0.9590\n",
      "Epoch 3/5\n",
      "2292/2292 [==============================] - 56s 25ms/step - loss: 0.0696 - acc: 0.9764\n",
      "Epoch 4/5\n",
      "2292/2292 [==============================] - 56s 24ms/step - loss: 0.0634 - acc: 0.9799\n",
      "Epoch 5/5\n",
      "2292/2292 [==============================] - 56s 24ms/step - loss: 0.0338 - acc: 0.9869\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline #notebook을 실행한 브라우저에서 바로 그림을 볼 수 있게 해주는 것 \n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem, DataStructs\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#setting the seed for reproducibility\n",
    "#seed = 10110\n",
    "seed = 12061204\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "#load the dataset\n",
    "dataframe = pandas.read_csv(\"./pubchem_data/processed/input/BSK_KF3CT_IL1a_down(Input).txt\", sep=\"\\t\")\n",
    "\n",
    "mols = []\n",
    "fps = []\n",
    "\n",
    "#get molecules and then get fingerprints from those\n",
    "for index, row in dataframe.iterrows():\n",
    "    mol = Chem.MolFromSmiles(row['Smiles'])\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2)\n",
    "    mols.append(mol)\n",
    "    fps.append(fp)\n",
    "\n",
    "#Convert the RDKit vectors into numpy arrays\n",
    "#Based on: http://www.rdkit.org/docs/Cookbook.html#using-scikit-learn-with-rdkit\n",
    "np_fps = []\n",
    "for fp in fps:\n",
    "    arr = numpy.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    np_fps.append(arr)\n",
    "\n",
    "np_fps_array = numpy.array(np_fps)\n",
    "\n",
    "#Need to encode my classes\n",
    "#Ligand = 0, not_ligand = 1\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(dataframe['Type'])\n",
    "enc_y = encoder.transform(dataframe['Type'])\n",
    "\n",
    "#Create the machine learning model\n",
    "\n",
    "def create_deep_learning_model():\n",
    "    model = Sequential()\n",
    "    #첫번째 인자 : 출력 뉴런의 수 , input_dim : 입력 뉴런의 수, activation : 활성화 함수.\n",
    "    model.add(Dense(2048, input_dim=2048, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "sm = SMOTE(random_state=12, ratio = 'minority')\n",
    "x_train_res, y_train_res = sm.fit_sample(np_fps_array, enc_y) #결과데이터\n",
    " \n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "#estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5, verbose=0)\n",
    "estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "#results = cross_val_score(estimator, np_fps_array, enc_y, cv=kfold)\n",
    "results = cross_val_score(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "y_pred = cross_val_predict(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "conf_mat = confusion_matrix(y_train_res, y_pred)\n",
    "conf_mat\n",
    "\n",
    "\n",
    "model = create_deep_learning_model()\n",
    "model.fit(x_train_res, y_train_res, epochs=5, batch_size=5)\n",
    "model.save('BSK_KF3CT_IL1a_down(Input).h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2232/2232 [==============================] - 58s 26ms/step - loss: 0.1186 - acc: 0.9570\n",
      "558/558 [==============================] - 2s 4ms/step\n",
      "Epoch 1/1\n",
      "2232/2232 [==============================] - 58s 26ms/step - loss: 0.1196 - acc: 0.9583\n",
      "558/558 [==============================] - 2s 4ms/step\n",
      "Epoch 1/1\n",
      "2232/2232 [==============================] - 58s 26ms/step - loss: 0.1048 - acc: 0.9637\n",
      "558/558 [==============================] - 2s 4ms/step\n",
      "Epoch 1/1\n",
      "2232/2232 [==============================] - 58s 26ms/step - loss: 0.1198 - acc: 0.9574\n",
      "558/558 [==============================] - 2s 4ms/step\n",
      "Epoch 1/1\n",
      "2232/2232 [==============================] - 59s 26ms/step - loss: 0.1189 - acc: 0.9539\n",
      "558/558 [==============================] - 2s 4ms/step\n",
      "Results: 98.78% (1.00%)\n",
      "Epoch 1/1\n",
      "2232/2232 [==============================] - 59s 26ms/step - loss: 0.1200 - acc: 0.9565\n",
      "Epoch 1/1\n",
      "2232/2232 [==============================] - 58s 26ms/step - loss: 0.1334 - acc: 0.9534\n",
      "Epoch 1/1\n",
      "2232/2232 [==============================] - 58s 26ms/step - loss: 0.1185 - acc: 0.9570\n",
      "Epoch 1/1\n",
      "2232/2232 [==============================] - 58s 26ms/step - loss: 0.1173 - acc: 0.9601\n",
      "Epoch 1/1\n",
      "2232/2232 [==============================] - 58s 26ms/step - loss: 0.1308 - acc: 0.9409\n",
      "Epoch 1/5\n",
      "2790/2790 [==============================] - 73s 26ms/step - loss: 0.0974 - acc: 0.9620\n",
      "Epoch 2/5\n",
      "2790/2790 [==============================] - 73s 26ms/step - loss: 0.0335 - acc: 0.9928\n",
      "Epoch 3/5\n",
      "2790/2790 [==============================] - 70s 25ms/step - loss: 0.0171 - acc: 0.9971\n",
      "Epoch 4/5\n",
      "2790/2790 [==============================] - 69s 25ms/step - loss: 0.0322 - acc: 0.9946\n",
      "Epoch 5/5\n",
      "2790/2790 [==============================] - 68s 25ms/step - loss: 0.0194 - acc: 0.9957\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline #notebook을 실행한 브라우저에서 바로 그림을 볼 수 있게 해주는 것 \n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem, DataStructs\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#setting the seed for reproducibility\n",
    "#seed = 10110\n",
    "seed = 12061204\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "#load the dataset\n",
    "dataframe = pandas.read_csv(\"./pubchem_data/processed/input/BSK_CASM3C_IL6_up(Input).txt\", sep=\"\\t\")\n",
    "\n",
    "mols = []\n",
    "fps = []\n",
    "\n",
    "#get molecules and then get fingerprints from those\n",
    "for index, row in dataframe.iterrows():\n",
    "    mol = Chem.MolFromSmiles(row['Smiles'])\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2)\n",
    "    mols.append(mol)\n",
    "    fps.append(fp)\n",
    "\n",
    "#Convert the RDKit vectors into numpy arrays\n",
    "#Based on: http://www.rdkit.org/docs/Cookbook.html#using-scikit-learn-with-rdkit\n",
    "np_fps = []\n",
    "for fp in fps:\n",
    "    arr = numpy.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    np_fps.append(arr)\n",
    "\n",
    "np_fps_array = numpy.array(np_fps)\n",
    "\n",
    "#Need to encode my classes\n",
    "#Ligand = 0, not_ligand = 1\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(dataframe['Type'])\n",
    "enc_y = encoder.transform(dataframe['Type'])\n",
    "\n",
    "#Create the machine learning model\n",
    "\n",
    "def create_deep_learning_model():\n",
    "    model = Sequential()\n",
    "    #첫번째 인자 : 출력 뉴런의 수 , input_dim : 입력 뉴런의 수, activation : 활성화 함수.\n",
    "    model.add(Dense(2048, input_dim=2048, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "sm = SMOTE(random_state=12, ratio = 'minority')\n",
    "x_train_res, y_train_res = sm.fit_sample(np_fps_array, enc_y) #결과데이터\n",
    " \n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "#estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5, verbose=0)\n",
    "estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "#results = cross_val_score(estimator, np_fps_array, enc_y, cv=kfold)\n",
    "results = cross_val_score(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "y_pred = cross_val_predict(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "conf_mat = confusion_matrix(y_train_res, y_pred)\n",
    "conf_mat\n",
    "\n",
    "\n",
    "model = create_deep_learning_model()\n",
    "model.fit(x_train_res, y_train_res, epochs=5, batch_size=5)\n",
    "model.save('BSK_CASM3C_IL6_up(Input).h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1974/1974 [==============================] - 52s 26ms/step - loss: 0.3465 - acc: 0.8480\n",
      "494/494 [==============================] - 2s 4ms/step\n",
      "Epoch 1/1\n",
      "1974/1974 [==============================] - 53s 27ms/step - loss: 0.3498 - acc: 0.8465\n",
      "494/494 [==============================] - 3s 5ms/step\n",
      "Epoch 1/1\n",
      "1974/1974 [==============================] - 56s 28ms/step - loss: 0.3634 - acc: 0.8404\n",
      "494/494 [==============================] - 2s 5ms/step\n",
      "Epoch 1/1\n",
      "1974/1974 [==============================] - 56s 28ms/step - loss: 0.3577 - acc: 0.8389\n",
      "494/494 [==============================] - 2s 5ms/step\n",
      "Epoch 1/1\n",
      "1976/1976 [==============================] - 57s 29ms/step - loss: 0.3578 - acc: 0.8472\n",
      "492/492 [==============================] - 3s 5ms/step\n",
      "Results: 93.96% (0.93%)\n",
      "Epoch 1/1\n",
      "1974/1974 [==============================] - 59s 30ms/step - loss: 0.3582 - acc: 0.8409\n",
      "Epoch 1/1\n",
      "1974/1974 [==============================] - 60s 31ms/step - loss: 0.3786 - acc: 0.8354\n",
      "Epoch 1/1\n",
      "1974/1974 [==============================] - 60s 30ms/step - loss: 0.3632 - acc: 0.8404\n",
      "Epoch 1/1\n",
      "1974/1974 [==============================] - 52s 26ms/step - loss: 0.3621 - acc: 0.8445\n",
      "Epoch 1/1\n",
      "1976/1976 [==============================] - 46s 23ms/step - loss: 0.3801 - acc: 0.8360\n",
      "Epoch 1/5\n",
      "2468/2468 [==============================] - 52s 21ms/step - loss: 0.3331 - acc: 0.8590\n",
      "Epoch 2/5\n",
      "2468/2468 [==============================] - 47s 19ms/step - loss: 0.0841 - acc: 0.9777\n",
      "Epoch 3/5\n",
      "2468/2468 [==============================] - 47s 19ms/step - loss: 0.0581 - acc: 0.9830\n",
      "Epoch 4/5\n",
      "2468/2468 [==============================] - 47s 19ms/step - loss: 0.0404 - acc: 0.9866\n",
      "Epoch 5/5\n",
      "2468/2468 [==============================] - 47s 19ms/step - loss: 0.0466 - acc: 0.9874\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline #notebook을 실행한 브라우저에서 바로 그림을 볼 수 있게 해주는 것 \n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem, DataStructs\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#setting the seed for reproducibility\n",
    "#seed = 10110\n",
    "seed = 12061204\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "#load the dataset\n",
    "dataframe = pandas.read_csv(\"./pubchem_data/processed/input/BSK_CASM3C_IL6_down(Input).txt\", sep=\"\\t\")\n",
    "\n",
    "mols = []\n",
    "fps = []\n",
    "\n",
    "#get molecules and then get fingerprints from those\n",
    "for index, row in dataframe.iterrows():\n",
    "    mol = Chem.MolFromSmiles(row['Smiles'])\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2)\n",
    "    mols.append(mol)\n",
    "    fps.append(fp)\n",
    "\n",
    "#Convert the RDKit vectors into numpy arrays\n",
    "#Based on: http://www.rdkit.org/docs/Cookbook.html#using-scikit-learn-with-rdkit\n",
    "np_fps = []\n",
    "for fp in fps:\n",
    "    arr = numpy.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    np_fps.append(arr)\n",
    "\n",
    "np_fps_array = numpy.array(np_fps)\n",
    "\n",
    "#Need to encode my classes\n",
    "#Ligand = 0, not_ligand = 1\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(dataframe['Type'])\n",
    "enc_y = encoder.transform(dataframe['Type'])\n",
    "\n",
    "#Create the machine learning model\n",
    "\n",
    "def create_deep_learning_model():\n",
    "    model = Sequential()\n",
    "    #첫번째 인자 : 출력 뉴런의 수 , input_dim : 입력 뉴런의 수, activation : 활성화 함수.\n",
    "    model.add(Dense(2048, input_dim=2048, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "sm = SMOTE(random_state=12, ratio = 'minority')\n",
    "x_train_res, y_train_res = sm.fit_sample(np_fps_array, enc_y) #결과데이터\n",
    " \n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "#estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5, verbose=0)\n",
    "estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "#results = cross_val_score(estimator, np_fps_array, enc_y, cv=kfold)\n",
    "results = cross_val_score(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "y_pred = cross_val_predict(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "conf_mat = confusion_matrix(y_train_res, y_pred)\n",
    "conf_mat\n",
    "\n",
    "\n",
    "model = create_deep_learning_model()\n",
    "model.fit(x_train_res, y_train_res, epochs=5, batch_size=5)\n",
    "model.save('BSK_CASM3C_IL6_down(Input).h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-a56a1845bc94>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[0msm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mratio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'minority'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m \u001b[0mx_train_res\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_res\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp_fps_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menc_y\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#결과데이터\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36mfit_sample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     86\u001b[0m         \"\"\"\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36msample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfit_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\imblearn\\over_sampling\\smote.py\u001b[0m in \u001b[0;36m_sample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'regular'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 594\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sample_regular\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    595\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'borderline1'\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'borderline2'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sample_borderline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\imblearn\\over_sampling\\smote.py\u001b[0m in \u001b[0;36m_sample_regular\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn_k_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_class\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 360\u001b[1;33m             \u001b[0mnns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn_k_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    361\u001b[0m             X_new, y_new = self._make_samples(X_class, class_sample, X_class,\n\u001b[0;32m    362\u001b[0m                                               nns, n_samples, 1.0)\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\neighbors\\base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    345\u001b[0m                 \u001b[1;34m\"Expected n_neighbors <= n_samples, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    346\u001b[0m                 \u001b[1;34m\" but n_samples = %d, n_neighbors = %d\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 347\u001b[1;33m                 \u001b[1;33m(\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    348\u001b[0m             )\n\u001b[0;32m    349\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected n_neighbors <= n_samples,  but n_samples = 5, n_neighbors = 6"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline #notebook을 실행한 브라우저에서 바로 그림을 볼 수 있게 해주는 것 \n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem, DataStructs\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#setting the seed for reproducibility\n",
    "#seed = 10110\n",
    "seed = 12061204\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "#load the dataset\n",
    "dataframe = pandas.read_csv(\"./pubchem_data/processed/input/BSK_BE3C_TGFb1_up(Input).txt\", sep=\"\\t\")\n",
    "\n",
    "mols = []\n",
    "fps = []\n",
    "\n",
    "#get molecules and then get fingerprints from those\n",
    "for index, row in dataframe.iterrows():\n",
    "    mol = Chem.MolFromSmiles(row['Smiles'])\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2)\n",
    "    mols.append(mol)\n",
    "    fps.append(fp)\n",
    "\n",
    "#Convert the RDKit vectors into numpy arrays\n",
    "#Based on: http://www.rdkit.org/docs/Cookbook.html#using-scikit-learn-with-rdkit\n",
    "np_fps = []\n",
    "for fp in fps:\n",
    "    arr = numpy.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    np_fps.append(arr)\n",
    "\n",
    "np_fps_array = numpy.array(np_fps)\n",
    "\n",
    "#Need to encode my classes\n",
    "#Ligand = 0, not_ligand = 1\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(dataframe['Type'])\n",
    "enc_y = encoder.transform(dataframe['Type'])\n",
    "\n",
    "#Create the machine learning model\n",
    "\n",
    "def create_deep_learning_model():\n",
    "    model = Sequential()\n",
    "    #첫번째 인자 : 출력 뉴런의 수 , input_dim : 입력 뉴런의 수, activation : 활성화 함수.\n",
    "    model.add(Dense(2048, input_dim=2048, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "sm = SMOTE(random_state=12, ratio = 'minority')\n",
    "x_train_res, y_train_res = sm.fit_sample(np_fps_array, enc_y) #결과데이터\n",
    " \n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "#estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5, verbose=0)\n",
    "estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "#results = cross_val_score(estimator, np_fps_array, enc_y, cv=kfold)\n",
    "results = cross_val_score(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "y_pred = cross_val_predict(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "conf_mat = confusion_matrix(y_train_res, y_pred)\n",
    "conf_mat\n",
    "\n",
    "\n",
    "model = create_deep_learning_model()\n",
    "model.fit(x_train_res, y_train_res, epochs=5, batch_size=5)\n",
    "model.save('BSK_BE3C_TGFb1_up(Input)_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1942/1942 [==============================] - 44s 23ms/step - loss: 0.4052 - acc: 0.8352\n",
      "486/486 [==============================] - 2s 4ms/step\n",
      "Epoch 1/1\n",
      "1942/1942 [==============================] - 45s 23ms/step - loss: 0.3961 - acc: 0.8337\n",
      "486/486 [==============================] - 2s 3ms/step\n",
      "Epoch 1/1\n",
      "1942/1942 [==============================] - 40s 21ms/step - loss: 0.4062 - acc: 0.8223\n",
      "486/486 [==============================] - 2s 4ms/step\n",
      "Epoch 1/1\n",
      "1942/1942 [==============================] - 41s 21ms/step - loss: 0.3952 - acc: 0.8265\n",
      "486/486 [==============================] - 2s 4ms/step\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 42s 22ms/step - loss: 0.4008 - acc: 0.8292\n",
      "484/484 [==============================] - 2s 5ms/step\n",
      "Results: 91.85% (1.80%)\n",
      "Epoch 1/1\n",
      "1942/1942 [==============================] - 40s 21ms/step - loss: 0.4249 - acc: 0.8090\n",
      "Epoch 1/1\n",
      "1942/1942 [==============================] - 41s 21ms/step - loss: 0.4080 - acc: 0.8229\n",
      "Epoch 1/1\n",
      "1942/1942 [==============================] - 40s 20ms/step - loss: 0.3975 - acc: 0.8275\n",
      "Epoch 1/1\n",
      "1942/1942 [==============================] - 40s 20ms/step - loss: 0.4087 - acc: 0.8126\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 51s 26ms/step - loss: 0.4040 - acc: 0.8230\n",
      "Epoch 1/5\n",
      "2428/2428 [==============================] - 53s 22ms/step - loss: 0.3538 - acc: 0.8439\n",
      "Epoch 2/5\n",
      "2428/2428 [==============================] - 47s 19ms/step - loss: 0.0953 - acc: 0.9699\n",
      "Epoch 3/5\n",
      "2428/2428 [==============================] - 53s 22ms/step - loss: 0.0581 - acc: 0.9815\n",
      "Epoch 4/5\n",
      "2428/2428 [==============================] - 55s 23ms/step - loss: 0.0422 - acc: 0.9860\n",
      "Epoch 5/5\n",
      "2428/2428 [==============================] - 58s 24ms/step - loss: 0.0497 - acc: 0.9811\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline #notebook을 실행한 브라우저에서 바로 그림을 볼 수 있게 해주는 것 \n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem, DataStructs\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#setting the seed for reproducibility\n",
    "#seed = 10110\n",
    "seed = 12061204\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "#load the dataset\n",
    "dataframe = pandas.read_csv(\"./pubchem_data/processed/input/BSK_BE3C_TGFb1_down(Input).txt\", sep=\"\\t\")\n",
    "\n",
    "mols = []\n",
    "fps = []\n",
    "\n",
    "#get molecules and then get fingerprints from those\n",
    "for index, row in dataframe.iterrows():\n",
    "    mol = Chem.MolFromSmiles(row['Smiles'])\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2)\n",
    "    mols.append(mol)\n",
    "    fps.append(fp)\n",
    "\n",
    "#Convert the RDKit vectors into numpy arrays\n",
    "#Based on: http://www.rdkit.org/docs/Cookbook.html#using-scikit-learn-with-rdkit\n",
    "np_fps = []\n",
    "for fp in fps:\n",
    "    arr = numpy.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    np_fps.append(arr)\n",
    "\n",
    "np_fps_array = numpy.array(np_fps)\n",
    "\n",
    "#Need to encode my classes\n",
    "#Ligand = 0, not_ligand = 1\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(dataframe['Type'])\n",
    "enc_y = encoder.transform(dataframe['Type'])\n",
    "\n",
    "#Create the machine learning model\n",
    "\n",
    "def create_deep_learning_model():\n",
    "    model = Sequential()\n",
    "    #첫번째 인자 : 출력 뉴런의 수 , input_dim : 입력 뉴런의 수, activation : 활성화 함수.\n",
    "    model.add(Dense(2048, input_dim=2048, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "sm = SMOTE(random_state=12, ratio = 'minority')\n",
    "x_train_res, y_train_res = sm.fit_sample(np_fps_array, enc_y) #결과데이터\n",
    " \n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "#estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5, verbose=0)\n",
    "estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "#results = cross_val_score(estimator, np_fps_array, enc_y, cv=kfold)\n",
    "results = cross_val_score(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "y_pred = cross_val_predict(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "conf_mat = confusion_matrix(y_train_res, y_pred)\n",
    "conf_mat\n",
    "\n",
    "\n",
    "model = create_deep_learning_model()\n",
    "model.fit(x_train_res, y_train_res, epochs=5, batch_size=5)\n",
    "model.save('BSK_BE3C_TGFb1_down(Input)_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2292/2292 [==============================] - 59s 26ms/step - loss: 0.0594 - acc: 0.9799\n",
      "574/574 [==============================] - 3s 6ms/step\n",
      "Epoch 1/1\n",
      "2292/2292 [==============================] - 59s 26ms/step - loss: 0.0495 - acc: 0.9812\n",
      "574/574 [==============================] - 3s 6ms/step\n",
      "Epoch 1/1\n",
      "2292/2292 [==============================] - 55s 24ms/step - loss: 0.0468 - acc: 0.9825\n",
      "574/574 [==============================] - 2s 3ms/step\n",
      "Epoch 1/1\n",
      "2294/2294 [==============================] - 47s 20ms/step - loss: 0.0593 - acc: 0.9804\n",
      "572/572 [==============================] - 2s 3ms/step\n",
      "Epoch 1/1\n",
      "2294/2294 [==============================] - 48s 21ms/step - loss: 0.0560 - acc: 0.9821\n",
      "572/572 [==============================] - 2s 4ms/step\n",
      "Results: 99.76% (0.18%)\n",
      "Epoch 1/1\n",
      "2292/2292 [==============================] - 47s 21ms/step - loss: 0.0620 - acc: 0.9799\n",
      "Epoch 1/1\n",
      "2292/2292 [==============================] - 47s 20ms/step - loss: 0.0569 - acc: 0.9812\n",
      "Epoch 1/1\n",
      "2292/2292 [==============================] - 47s 21ms/step - loss: 0.0608 - acc: 0.9760\n",
      "Epoch 1/1\n",
      "2294/2294 [==============================] - 47s 21ms/step - loss: 0.0603 - acc: 0.9760\n",
      "Epoch 1/1\n",
      "2294/2294 [==============================] - 47s 21ms/step - loss: 0.0746 - acc: 0.9686\n",
      "Epoch 1/5\n",
      "2866/2866 [==============================] - 61s 21ms/step - loss: 0.0487 - acc: 0.9878\n",
      "Epoch 2/5\n",
      "2866/2866 [==============================] - 60s 21ms/step - loss: 0.0199 - acc: 0.9965\n",
      "Epoch 3/5\n",
      "2866/2866 [==============================] - 59s 21ms/step - loss: 0.0018 - acc: 0.9993\n",
      "Epoch 4/5\n",
      "2866/2866 [==============================] - 59s 20ms/step - loss: 2.4323e-06 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "2866/2866 [==============================] - 59s 20ms/step - loss: 1.8000e-06 - acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline #notebook을 실행한 브라우저에서 바로 그림을 볼 수 있게 해주는 것 \n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem, DataStructs\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#setting the seed for reproducibility\n",
    "#seed = 10110\n",
    "seed = 12061204\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "#load the dataset\n",
    "dataframe = pandas.read_csv(\"./pubchem_data/processed/input/BSK_BE3C_IL1a_up(Input).txt\", sep=\"\\t\")\n",
    "\n",
    "mols = []\n",
    "fps = []\n",
    "\n",
    "#get molecules and then get fingerprints from those\n",
    "for index, row in dataframe.iterrows():\n",
    "    mol = Chem.MolFromSmiles(row['Smiles'])\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2)\n",
    "    mols.append(mol)\n",
    "    fps.append(fp)\n",
    "\n",
    "#Convert the RDKit vectors into numpy arrays\n",
    "#Based on: http://www.rdkit.org/docs/Cookbook.html#using-scikit-learn-with-rdkit\n",
    "np_fps = []\n",
    "for fp in fps:\n",
    "    arr = numpy.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    np_fps.append(arr)\n",
    "\n",
    "np_fps_array = numpy.array(np_fps)\n",
    "\n",
    "#Need to encode my classes\n",
    "#Ligand = 0, not_ligand = 1\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(dataframe['Type'])\n",
    "enc_y = encoder.transform(dataframe['Type'])\n",
    "\n",
    "#Create the machine learning model\n",
    "\n",
    "def create_deep_learning_model():\n",
    "    model = Sequential()\n",
    "    #첫번째 인자 : 출력 뉴런의 수 , input_dim : 입력 뉴런의 수, activation : 활성화 함수.\n",
    "    model.add(Dense(2048, input_dim=2048, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "sm = SMOTE(random_state=12, ratio = 'minority')\n",
    "x_train_res, y_train_res = sm.fit_sample(np_fps_array, enc_y) #결과데이터\n",
    " \n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "#estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5, verbose=0)\n",
    "estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "#results = cross_val_score(estimator, np_fps_array, enc_y, cv=kfold)\n",
    "results = cross_val_score(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "y_pred = cross_val_predict(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "conf_mat = confusion_matrix(y_train_res, y_pred)\n",
    "conf_mat\n",
    "\n",
    "\n",
    "model = create_deep_learning_model()\n",
    "model.fit(x_train_res, y_train_res, epochs=5, batch_size=5)\n",
    "model.save('BSK_BE3C_IL1a_up(Input)_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1876/1876 [==============================] - 42s 22ms/step - loss: 0.4711 - acc: 0.7623\n",
      "470/470 [==============================] - 2s 5ms/step\n",
      "Epoch 1/1\n",
      "1876/1876 [==============================] - 42s 23ms/step - loss: 0.4360 - acc: 0.8065\n",
      "470/470 [==============================] - 2s 4ms/step\n",
      "Epoch 1/1\n",
      "1876/1876 [==============================] - 42s 23ms/step - loss: 0.4493 - acc: 0.8017\n",
      "470/470 [==============================] - 2s 5ms/step\n",
      "Epoch 1/1\n",
      "1878/1878 [==============================] - 43s 23ms/step - loss: 0.4187 - acc: 0.8030\n",
      "468/468 [==============================] - 2s 5ms/step\n",
      "Epoch 1/1\n",
      "1878/1878 [==============================] - 43s 23ms/step - loss: 0.4434 - acc: 0.7881\n",
      "468/468 [==============================] - 2s 5ms/step\n",
      "Results: 91.30% (1.86%)\n",
      "Epoch 1/1\n",
      "1876/1876 [==============================] - 42s 23ms/step - loss: 0.4205 - acc: 0.8081\n",
      "Epoch 1/1\n",
      "1876/1876 [==============================] - 44s 23ms/step - loss: 0.4129 - acc: 0.8124\n",
      "Epoch 1/1\n",
      "1876/1876 [==============================] - 43s 23ms/step - loss: 0.4526 - acc: 0.7921\n",
      "Epoch 1/1\n",
      "1878/1878 [==============================] - 43s 23ms/step - loss: 0.4127 - acc: 0.8259\n",
      "Epoch 1/1\n",
      "1878/1878 [==============================] - 43s 23ms/step - loss: 0.4649 - acc: 0.7796\n",
      "Epoch 1/5\n",
      "2346/2346 [==============================] - 53s 22ms/step - loss: 0.3831 - acc: 0.8355\n",
      "Epoch 2/5\n",
      "2346/2346 [==============================] - 49s 21ms/step - loss: 0.1010 - acc: 0.9625\n",
      "Epoch 3/5\n",
      "2346/2346 [==============================] - 49s 21ms/step - loss: 0.0515 - acc: 0.9825\n",
      "Epoch 4/5\n",
      "2346/2346 [==============================] - 49s 21ms/step - loss: 0.0370 - acc: 0.9868\n",
      "Epoch 5/5\n",
      "2346/2346 [==============================] - 49s 21ms/step - loss: 0.0489 - acc: 0.9855\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline #notebook을 실행한 브라우저에서 바로 그림을 볼 수 있게 해주는 것 \n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem, DataStructs\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#setting the seed for reproducibility\n",
    "#seed = 10110\n",
    "seed = 12061204\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "#load the dataset\n",
    "dataframe = pandas.read_csv(\"./pubchem_data/processed/input/BSK_BE3C_IL1a_down(Input).txt\", sep=\"\\t\")\n",
    "\n",
    "mols = []\n",
    "fps = []\n",
    "\n",
    "#get molecules and then get fingerprints from those\n",
    "for index, row in dataframe.iterrows():\n",
    "    mol = Chem.MolFromSmiles(row['Smiles'])\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2)\n",
    "    mols.append(mol)\n",
    "    fps.append(fp)\n",
    "\n",
    "#Convert the RDKit vectors into numpy arrays\n",
    "#Based on: http://www.rdkit.org/docs/Cookbook.html#using-scikit-learn-with-rdkit\n",
    "np_fps = []\n",
    "for fp in fps:\n",
    "    arr = numpy.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    np_fps.append(arr)\n",
    "\n",
    "np_fps_array = numpy.array(np_fps)\n",
    "\n",
    "#Need to encode my classes\n",
    "#Ligand = 0, not_ligand = 1\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(dataframe['Type'])\n",
    "enc_y = encoder.transform(dataframe['Type'])\n",
    "\n",
    "#Create the machine learning model\n",
    "\n",
    "def create_deep_learning_model():\n",
    "    model = Sequential()\n",
    "    #첫번째 인자 : 출력 뉴런의 수 , input_dim : 입력 뉴런의 수, activation : 활성화 함수.\n",
    "    model.add(Dense(2048, input_dim=2048, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "sm = SMOTE(random_state=12, ratio = 'minority')\n",
    "x_train_res, y_train_res = sm.fit_sample(np_fps_array, enc_y) #결과데이터\n",
    " \n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "#estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5, verbose=0)\n",
    "estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "#results = cross_val_score(estimator, np_fps_array, enc_y, cv=kfold)\n",
    "results = cross_val_score(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "y_pred = cross_val_predict(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "conf_mat = confusion_matrix(y_train_res, y_pred)\n",
    "conf_mat\n",
    "\n",
    "\n",
    "model = create_deep_learning_model()\n",
    "model.fit(x_train_res, y_train_res, epochs=5, batch_size=5)\n",
    "model.save('BSK_BE3C_IL1a_down(Input)_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "5252/5252 [==============================] - 113s 21ms/step - loss: 0.1772 - acc: 0.9408\n",
      "1314/1314 [==============================] - 4s 3ms/step\n",
      "Epoch 1/1\n",
      "5252/5252 [==============================] - 113s 21ms/step - loss: 0.1643 - acc: 0.9375\n",
      "1314/1314 [==============================] - 4s 3ms/step\n",
      "Epoch 1/1\n",
      "5252/5252 [==============================] - 114s 22ms/step - loss: 0.1676 - acc: 0.9383\n",
      "1314/1314 [==============================] - 4s 3ms/step\n",
      "Epoch 1/1\n",
      "5254/5254 [==============================] - 138s 26ms/step - loss: 0.1737 - acc: 0.9319\n",
      "1312/1312 [==============================] - 5s 3ms/step\n",
      "Epoch 1/1\n",
      "5254/5254 [==============================] - 113s 22ms/step - loss: 0.1710 - acc: 0.9370\n",
      "1312/1312 [==============================] - 4s 3ms/step\n",
      "Results: 97.46% (0.99%)\n",
      "Epoch 1/1\n",
      "5252/5252 [==============================] - 116s 22ms/step - loss: 0.1780 - acc: 0.9375\n",
      "Epoch 1/1\n",
      "5252/5252 [==============================] - 149s 28ms/step - loss: 0.1582 - acc: 0.9393\n",
      "Epoch 1/1\n",
      "5252/5252 [==============================] - 117s 22ms/step - loss: 0.1638 - acc: 0.9427\n",
      "Epoch 1/1\n",
      "5254/5254 [==============================] - 124s 24ms/step - loss: 0.1560 - acc: 0.9444\n",
      "Epoch 1/1\n",
      "5254/5254 [==============================] - 126s 24ms/step - loss: 0.1625 - acc: 0.9360\n",
      "Epoch 1/5\n",
      "6566/6566 [==============================] - 145s 22ms/step - loss: 0.1505 - acc: 0.9467\n",
      "Epoch 2/5\n",
      "6566/6566 [==============================] - 136s 21ms/step - loss: 0.0531 - acc: 0.9863\n",
      "Epoch 3/5\n",
      "6566/6566 [==============================] - 136s 21ms/step - loss: 0.0367 - acc: 0.9899\n",
      "Epoch 4/5\n",
      "6566/6566 [==============================] - 135s 21ms/step - loss: 0.0280 - acc: 0.9928\n",
      "Epoch 5/5\n",
      "6566/6566 [==============================] - 134s 20ms/step - loss: 0.0274 - acc: 0.9938\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline #notebook을 실행한 브라우저에서 바로 그림을 볼 수 있게 해주는 것 \n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem, DataStructs\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#setting the seed for reproducibility\n",
    "#seed = 10110\n",
    "seed = 12061204\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "#load the dataset\n",
    "dataframe = pandas.read_csv(\"./pubchem_data/processed/input/ATG_TGFb_CIS_up(Input).txt\", sep=\"\\t\")\n",
    "\n",
    "mols = []\n",
    "fps = []\n",
    "\n",
    "#get molecules and then get fingerprints from those\n",
    "for index, row in dataframe.iterrows():\n",
    "    mol = Chem.MolFromSmiles(row['Smiles'])\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2)\n",
    "    mols.append(mol)\n",
    "    fps.append(fp)\n",
    "\n",
    "#Convert the RDKit vectors into numpy arrays\n",
    "#Based on: http://www.rdkit.org/docs/Cookbook.html#using-scikit-learn-with-rdkit\n",
    "np_fps = []\n",
    "for fp in fps:\n",
    "    arr = numpy.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    np_fps.append(arr)\n",
    "\n",
    "np_fps_array = numpy.array(np_fps)\n",
    "\n",
    "#Need to encode my classes\n",
    "#Ligand = 0, not_ligand = 1\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(dataframe['Type'])\n",
    "enc_y = encoder.transform(dataframe['Type'])\n",
    "\n",
    "#Create the machine learning model\n",
    "\n",
    "def create_deep_learning_model():\n",
    "    model = Sequential()\n",
    "    #첫번째 인자 : 출력 뉴런의 수 , input_dim : 입력 뉴런의 수, activation : 활성화 함수.\n",
    "    model.add(Dense(2048, input_dim=2048, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "sm = SMOTE(random_state=12, ratio = 'minority')\n",
    "x_train_res, y_train_res = sm.fit_sample(np_fps_array, enc_y) #결과데이터\n",
    " \n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "#estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5, verbose=0)\n",
    "estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "#results = cross_val_score(estimator, np_fps_array, enc_y, cv=kfold)\n",
    "results = cross_val_score(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "y_pred = cross_val_predict(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "conf_mat = confusion_matrix(y_train_res, y_pred)\n",
    "conf_mat\n",
    "\n",
    "\n",
    "model = create_deep_learning_model()\n",
    "model.fit(x_train_res, y_train_res, epochs=5, batch_size=5)\n",
    "model.save('ATG_TGFb_CIS_up(Input)_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "5274/5274 [==============================] - 112s 21ms/step - loss: 0.1686 - acc: 0.9378\n",
      "1320/1320 [==============================] - 5s 4ms/step\n",
      "Epoch 1/1\n",
      "5274/5274 [==============================] - 112s 21ms/step - loss: 0.1662 - acc: 0.9374\n",
      "1320/1320 [==============================] - 5s 3ms/step\n",
      "Epoch 1/1\n",
      "5276/5276 [==============================] - 112s 21ms/step - loss: 0.1823 - acc: 0.9318\n",
      "1318/1318 [==============================] - 5s 4ms/step\n",
      "Epoch 1/1\n",
      "5276/5276 [==============================] - 113s 21ms/step - loss: 0.1637 - acc: 0.9405\n",
      "1318/1318 [==============================] - 5s 4ms/step\n",
      "Epoch 1/1\n",
      "5276/5276 [==============================] - 116s 22ms/step - loss: 0.1764 - acc: 0.9329\n",
      "1318/1318 [==============================] - 5s 4ms/step\n",
      "Results: 97.47% (0.89%)\n",
      "Epoch 1/1\n",
      "5274/5274 [==============================] - 115s 22ms/step - loss: 0.1704 - acc: 0.9376\n",
      "Epoch 1/1\n",
      "5274/5274 [==============================] - 114s 22ms/step - loss: 0.1695 - acc: 0.9372\n",
      "Epoch 1/1\n",
      "5276/5276 [==============================] - 113s 21ms/step - loss: 0.1740 - acc: 0.9367\n",
      "Epoch 1/1\n",
      "5276/5276 [==============================] - 113s 22ms/step - loss: 0.1719 - acc: 0.9320\n",
      "Epoch 1/1\n",
      "5276/5276 [==============================] - 113s 21ms/step - loss: 0.1742 - acc: 0.9352\n",
      "Epoch 1/5\n",
      "6594/6594 [==============================] - 141s 21ms/step - loss: 0.1485 - acc: 0.9453\n",
      "Epoch 2/5\n",
      "6594/6594 [==============================] - 136s 21ms/step - loss: 0.0437 - acc: 0.9885\n",
      "Epoch 3/5\n",
      "6594/6594 [==============================] - 136s 21ms/step - loss: 0.0475 - acc: 0.9909\n",
      "Epoch 4/5\n",
      "6594/6594 [==============================] - 136s 21ms/step - loss: 0.0380 - acc: 0.9903\n",
      "Epoch 5/5\n",
      "6594/6594 [==============================] - 136s 21ms/step - loss: 0.0298 - acc: 0.9915\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline #notebook을 실행한 브라우저에서 바로 그림을 볼 수 있게 해주는 것 \n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem, DataStructs\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#setting the seed for reproducibility\n",
    "#seed = 10110\n",
    "seed = 12061204\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "#load the dataset\n",
    "dataframe = pandas.read_csv(\"./pubchem_data/processed/input/ATG_TGFb_CIS_dn(Input).txt\", sep=\"\\t\")\n",
    "\n",
    "mols = []\n",
    "fps = []\n",
    "\n",
    "#get molecules and then get fingerprints from those\n",
    "for index, row in dataframe.iterrows():\n",
    "    mol = Chem.MolFromSmiles(row['Smiles'])\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2)\n",
    "    mols.append(mol)\n",
    "    fps.append(fp)\n",
    "\n",
    "#Convert the RDKit vectors into numpy arrays\n",
    "#Based on: http://www.rdkit.org/docs/Cookbook.html#using-scikit-learn-with-rdkit\n",
    "np_fps = []\n",
    "for fp in fps:\n",
    "    arr = numpy.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    np_fps.append(arr)\n",
    "\n",
    "np_fps_array = numpy.array(np_fps)\n",
    "\n",
    "#Need to encode my classes\n",
    "#Ligand = 0, not_ligand = 1\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(dataframe['Type'])\n",
    "enc_y = encoder.transform(dataframe['Type'])\n",
    "\n",
    "#Create the machine learning model\n",
    "\n",
    "def create_deep_learning_model():\n",
    "    model = Sequential()\n",
    "    #첫번째 인자 : 출력 뉴런의 수 , input_dim : 입력 뉴런의 수, activation : 활성화 함수.\n",
    "    model.add(Dense(2048, input_dim=2048, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "sm = SMOTE(random_state=12, ratio = 'minority')\n",
    "x_train_res, y_train_res = sm.fit_sample(np_fps_array, enc_y) #결과데이터\n",
    " \n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "#estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5, verbose=0)\n",
    "estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "#results = cross_val_score(estimator, np_fps_array, enc_y, cv=kfold)\n",
    "results = cross_val_score(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "y_pred = cross_val_predict(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "conf_mat = confusion_matrix(y_train_res, y_pred)\n",
    "conf_mat\n",
    "\n",
    "\n",
    "model = create_deep_learning_model()\n",
    "model.fit(x_train_res, y_train_res, epochs=5, batch_size=5)\n",
    "model.save('ATG_TGFb_CIS_dn(Input)_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "3970/3970 [==============================] - 87s 22ms/step - loss: 0.5050 - acc: 0.7589\n",
      "994/994 [==============================] - 4s 4ms/step\n",
      "Epoch 1/1\n",
      "3970/3970 [==============================] - 87s 22ms/step - loss: 0.5043 - acc: 0.7599\n",
      "994/994 [==============================] - 4s 4ms/step\n",
      "Epoch 1/1\n",
      "3972/3972 [==============================] - 87s 22ms/step - loss: 0.5147 - acc: 0.7515 2s - lo\n",
      "992/992 [==============================] - 4s 4ms/step\n",
      "Epoch 1/1\n",
      "3972/3972 [==============================] - 87s 22ms/step - loss: 0.4997 - acc: 0.7666\n",
      "992/992 [==============================] - 4s 4ms/step\n",
      "Epoch 1/1\n",
      "3972/3972 [==============================] - 87s 22ms/step - loss: 0.4970 - acc: 0.7729\n",
      "992/992 [==============================] - 4s 4ms/step\n",
      "Results: 85.07% (0.87%)\n",
      "Epoch 1/1\n",
      "3970/3970 [==============================] - 87s 22ms/step - loss: 0.5008 - acc: 0.7645\n",
      "Epoch 1/1\n",
      "3970/3970 [==============================] - 87s 22ms/step - loss: 0.5081 - acc: 0.7584\n",
      "Epoch 1/1\n",
      "3972/3972 [==============================] - 87s 22ms/step - loss: 0.5079 - acc: 0.7651\n",
      "Epoch 1/1\n",
      "3972/3972 [==============================] - 87s 22ms/step - loss: 0.4992 - acc: 0.7669\n",
      "Epoch 1/1\n",
      "3972/3972 [==============================] - 93s 24ms/step - loss: 0.4988 - acc: 0.7676\n",
      "Epoch 1/5\n",
      "4964/4964 [==============================] - 112s 22ms/step - loss: 0.4747 - acc: 0.7814\n",
      "Epoch 2/5\n",
      "4964/4964 [==============================] - 103s 21ms/step - loss: 0.1945 - acc: 0.9301\n",
      "Epoch 3/5\n",
      "4964/4964 [==============================] - 103s 21ms/step - loss: 0.1126 - acc: 0.9605\n",
      "Epoch 4/5\n",
      "4964/4964 [==============================] - 103s 21ms/step - loss: 0.0778 - acc: 0.9736\n",
      "Epoch 5/5\n",
      "4964/4964 [==============================] - 103s 21ms/step - loss: 0.0609 - acc: 0.9744\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline #notebook을 실행한 브라우저에서 바로 그림을 볼 수 있게 해주는 것 \n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem, DataStructs\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#setting the seed for reproducibility\n",
    "#seed = 10110\n",
    "seed = 12061204\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "#load the dataset\n",
    "dataframe = pandas.read_csv(\"./pubchem_data/processed/input/ATG_PPARg_TRANS_up(Input).txt\", sep=\"\\t\")\n",
    "\n",
    "mols = []\n",
    "fps = []\n",
    "\n",
    "#get molecules and then get fingerprints from those\n",
    "for index, row in dataframe.iterrows():\n",
    "    mol = Chem.MolFromSmiles(row['Smiles'])\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2)\n",
    "    mols.append(mol)\n",
    "    fps.append(fp)\n",
    "\n",
    "#Convert the RDKit vectors into numpy arrays\n",
    "#Based on: http://www.rdkit.org/docs/Cookbook.html#using-scikit-learn-with-rdkit\n",
    "np_fps = []\n",
    "for fp in fps:\n",
    "    arr = numpy.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    np_fps.append(arr)\n",
    "\n",
    "np_fps_array = numpy.array(np_fps)\n",
    "\n",
    "#Need to encode my classes\n",
    "#Ligand = 0, not_ligand = 1\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(dataframe['Type'])\n",
    "enc_y = encoder.transform(dataframe['Type'])\n",
    "\n",
    "#Create the machine learning model\n",
    "\n",
    "def create_deep_learning_model():\n",
    "    model = Sequential()\n",
    "    #첫번째 인자 : 출력 뉴런의 수 , input_dim : 입력 뉴런의 수, activation : 활성화 함수.\n",
    "    model.add(Dense(2048, input_dim=2048, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "sm = SMOTE(random_state=12, ratio = 'minority')\n",
    "x_train_res, y_train_res = sm.fit_sample(np_fps_array, enc_y) #결과데이터\n",
    " \n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "#estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5, verbose=0)\n",
    "estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "#results = cross_val_score(estimator, np_fps_array, enc_y, cv=kfold)\n",
    "results = cross_val_score(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "y_pred = cross_val_predict(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "conf_mat = confusion_matrix(y_train_res, y_pred)\n",
    "conf_mat\n",
    "\n",
    "\n",
    "model = create_deep_learning_model()\n",
    "model.fit(x_train_res, y_train_res, epochs=5, batch_size=5)\n",
    "model.save('ATG_PPARg_TRANS_up(Input)_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "5248/5248 [==============================] - 112s 21ms/step - loss: 0.1513 - acc: 0.9476\n",
      "1312/1312 [==============================] - 3s 2ms/step\n",
      "Epoch 1/1\n",
      "5248/5248 [==============================] - 108s 21ms/step - loss: 0.1612 - acc: 0.9358\n",
      "1312/1312 [==============================] - 3s 2ms/step\n",
      "Epoch 1/1\n",
      "5248/5248 [==============================] - 112s 21ms/step - loss: 0.1535 - acc: 0.9413\n",
      "1312/1312 [==============================] - 2s 2ms/step\n",
      "Epoch 1/1\n",
      "5248/5248 [==============================] - 101s 19ms/step - loss: 0.1635 - acc: 0.9392\n",
      "1312/1312 [==============================] - 2s 2ms/step\n",
      "Epoch 1/1\n",
      "5248/5248 [==============================] - 105s 20ms/step - loss: 0.1523 - acc: 0.9451\n",
      "1312/1312 [==============================] - 2s 2ms/step\n",
      "Results: 98.09% (0.33%)\n",
      "Epoch 1/1\n",
      "5248/5248 [==============================] - 112s 21ms/step - loss: 0.1543 - acc: 0.9434\n",
      "Epoch 1/1\n",
      "5248/5248 [==============================] - 113s 22ms/step - loss: 0.1528 - acc: 0.9426\n",
      "Epoch 1/1\n",
      "5248/5248 [==============================] - 111s 21ms/step - loss: 0.1495 - acc: 0.9487\n",
      "Epoch 1/1\n",
      "5248/5248 [==============================] - 107s 20ms/step - loss: 0.1550 - acc: 0.9405\n",
      "Epoch 1/1\n",
      "5248/5248 [==============================] - 109s 21ms/step - loss: 0.1509 - acc: 0.9419\n",
      "Epoch 1/5\n",
      "6560/6560 [==============================] - 129s 20ms/step - loss: 0.1333 - acc: 0.9534\n",
      "Epoch 2/5\n",
      "6560/6560 [==============================] - 128s 20ms/step - loss: 0.0517 - acc: 0.9851\n",
      "Epoch 3/5\n",
      "6560/6560 [==============================] - 127s 19ms/step - loss: 0.0306 - acc: 0.9921\n",
      "Epoch 4/5\n",
      "6560/6560 [==============================] - 127s 19ms/step - loss: 0.0300 - acc: 0.9921\n",
      "Epoch 5/5\n",
      "6560/6560 [==============================] - 127s 19ms/step - loss: 0.0207 - acc: 0.9945\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline #notebook을 실행한 브라우저에서 바로 그림을 볼 수 있게 해주는 것 \n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem, DataStructs\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#setting the seed for reproducibility\n",
    "#seed = 10110\n",
    "seed = 12061204\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "#load the dataset\n",
    "dataframe = pandas.read_csv(\"./pubchem_data/processed/input/ATG_NF_kB_CIS_up(Input).txt\", sep=\"\\t\")\n",
    "\n",
    "mols = []\n",
    "fps = []\n",
    "\n",
    "#get molecules and then get fingerprints from those\n",
    "for index, row in dataframe.iterrows():\n",
    "    mol = Chem.MolFromSmiles(row['Smiles'])\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2)\n",
    "    mols.append(mol)\n",
    "    fps.append(fp)\n",
    "\n",
    "#Convert the RDKit vectors into numpy arrays\n",
    "#Based on: http://www.rdkit.org/docs/Cookbook.html#using-scikit-learn-with-rdkit\n",
    "np_fps = []\n",
    "for fp in fps:\n",
    "    arr = numpy.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    np_fps.append(arr)\n",
    "\n",
    "np_fps_array = numpy.array(np_fps)\n",
    "\n",
    "#Need to encode my classes\n",
    "#Ligand = 0, not_ligand = 1\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(dataframe['Type'])\n",
    "enc_y = encoder.transform(dataframe['Type'])\n",
    "\n",
    "#Create the machine learning model\n",
    "\n",
    "def create_deep_learning_model():\n",
    "    model = Sequential()\n",
    "    #첫번째 인자 : 출력 뉴런의 수 , input_dim : 입력 뉴런의 수, activation : 활성화 함수.\n",
    "    model.add(Dense(2048, input_dim=2048, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "sm = SMOTE(random_state=12, ratio = 'minority')\n",
    "x_train_res, y_train_res = sm.fit_sample(np_fps_array, enc_y) #결과데이터\n",
    " \n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "#estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5, verbose=0)\n",
    "estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "#results = cross_val_score(estimator, np_fps_array, enc_y, cv=kfold)\n",
    "results = cross_val_score(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "y_pred = cross_val_predict(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "conf_mat = confusion_matrix(y_train_res, y_pred)\n",
    "conf_mat\n",
    "\n",
    "\n",
    "model = create_deep_learning_model()\n",
    "model.fit(x_train_res, y_train_res, epochs=5, batch_size=5)\n",
    "model.save('ATG_NF_kB_CIS_up(Input)_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "5024/5024 [==============================] - 101s 20ms/step - loss: 0.2902 - acc: 0.8800\n",
      "1256/1256 [==============================] - 2s 2ms/step\n",
      "Epoch 1/1\n",
      "5024/5024 [==============================] - 103s 20ms/step - loss: 0.2828 - acc: 0.8897\n",
      "1256/1256 [==============================] - 2s 2ms/step\n",
      "Epoch 1/1\n",
      "5024/5024 [==============================] - 107s 21ms/step - loss: 0.2735 - acc: 0.8891\n",
      "1256/1256 [==============================] - 2s 2ms/step\n",
      "Epoch 1/1\n",
      "5024/5024 [==============================] - 103s 20ms/step - loss: 0.2613 - acc: 0.8929\n",
      "1256/1256 [==============================] - 2s 2ms/step\n",
      "Epoch 1/1\n",
      "5024/5024 [==============================] - 108s 22ms/step - loss: 0.2515 - acc: 0.8981\n",
      "1256/1256 [==============================] - 3s 2ms/step\n",
      "Results: 95.67% (0.80%)\n",
      "Epoch 1/1\n",
      "5024/5024 [==============================] - 109s 22ms/step - loss: 0.2820 - acc: 0.8865\n",
      "Epoch 1/1\n",
      "5024/5024 [==============================] - 97s 19ms/step - loss: 0.2677 - acc: 0.8925\n",
      "Epoch 1/1\n",
      "5024/5024 [==============================] - 98s 19ms/step - loss: 0.2711 - acc: 0.8891\n",
      "Epoch 1/1\n",
      "5024/5024 [==============================] - 105s 21ms/step - loss: 0.2758 - acc: 0.8854\n",
      "Epoch 1/1\n",
      "5024/5024 [==============================] - 103s 20ms/step - loss: 0.2769 - acc: 0.8913\n",
      "Epoch 1/5\n",
      "6280/6280 [==============================] - 133s 21ms/step - loss: 0.2418 - acc: 0.9068\n",
      "Epoch 2/5\n",
      "6280/6280 [==============================] - 125s 20ms/step - loss: 0.0606 - acc: 0.9796\n",
      "Epoch 3/5\n",
      "6280/6280 [==============================] - 131s 21ms/step - loss: 0.0449 - acc: 0.9868\n",
      "Epoch 4/5\n",
      "6280/6280 [==============================] - 134s 21ms/step - loss: 0.0399 - acc: 0.9855\n",
      "Epoch 5/5\n",
      "6280/6280 [==============================] - 142s 23ms/step - loss: 0.0331 - acc: 0.9893\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline #notebook을 실행한 브라우저에서 바로 그림을 볼 수 있게 해주는 것 \n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem, DataStructs\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#setting the seed for reproducibility\n",
    "#seed = 10110\n",
    "seed = 12061204\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "#load the dataset\n",
    "dataframe = pandas.read_csv(\"./pubchem_data/processed/input/ATG_NF_kB_CIS_dn(Input).txt\", sep=\"\\t\")\n",
    "\n",
    "mols = []\n",
    "fps = []\n",
    "\n",
    "#get molecules and then get fingerprints from those\n",
    "for index, row in dataframe.iterrows():\n",
    "    mol = Chem.MolFromSmiles(row['Smiles'])\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2)\n",
    "    mols.append(mol)\n",
    "    fps.append(fp)\n",
    "\n",
    "#Convert the RDKit vectors into numpy arrays\n",
    "#Based on: http://www.rdkit.org/docs/Cookbook.html#using-scikit-learn-with-rdkit\n",
    "np_fps = []\n",
    "for fp in fps:\n",
    "    arr = numpy.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    np_fps.append(arr)\n",
    "\n",
    "np_fps_array = numpy.array(np_fps)\n",
    "\n",
    "#Need to encode my classes\n",
    "#Ligand = 0, not_ligand = 1\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(dataframe['Type'])\n",
    "enc_y = encoder.transform(dataframe['Type'])\n",
    "\n",
    "#Create the machine learning model\n",
    "\n",
    "def create_deep_learning_model():\n",
    "    model = Sequential()\n",
    "    #첫번째 인자 : 출력 뉴런의 수 , input_dim : 입력 뉴런의 수, activation : 활성화 함수.\n",
    "    model.add(Dense(2048, input_dim=2048, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "sm = SMOTE(random_state=12, ratio = 'minority')\n",
    "x_train_res, y_train_res = sm.fit_sample(np_fps_array, enc_y) #결과데이터\n",
    " \n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "#estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5, verbose=0)\n",
    "estimator = KerasClassifier(build_fn=create_deep_learning_model, nb_epoch=100, batch_size=5)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "#results = cross_val_score(estimator, np_fps_array, enc_y, cv=kfold)\n",
    "results = cross_val_score(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "y_pred = cross_val_predict(estimator, x_train_res, y_train_res, cv=kfold)\n",
    "conf_mat = confusion_matrix(y_train_res, y_pred)\n",
    "conf_mat\n",
    "\n",
    "\n",
    "model = create_deep_learning_model()\n",
    "model.fit(x_train_res, y_train_res, epochs=5, batch_size=5)\n",
    "model.save('ATG_NF_kB_CIS_dn(Input)_model.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
